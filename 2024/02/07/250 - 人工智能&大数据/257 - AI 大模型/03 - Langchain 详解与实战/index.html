<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Langchain 详解与实战 | 梦之痕</title><meta name="author" content="梦之痕"><meta name="copyright" content="梦之痕"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="0 参考资料0.1 网站 LangChain 中文网：https:&#x2F;&#x2F;www.langchain.asia&#x2F; LangChain Github：https:&#x2F;&#x2F;github.com&#x2F;langchain-ai&#x2F;langchain LangChain API文档：https:&#x2F;&#x2F;python.langchain.com&#x2F;docs&#x2F;get_started 大语言模型实践：https:&#x2F;&#x2F;wangwei1">
<meta property="og:type" content="article">
<meta property="og:title" content="Langchain 详解与实战">
<meta property="og:url" content="https://baihlup.github.io/2024/02/07/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/03%20-%20Langchain%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="梦之痕">
<meta property="og:description" content="0 参考资料0.1 网站 LangChain 中文网：https:&#x2F;&#x2F;www.langchain.asia&#x2F; LangChain Github：https:&#x2F;&#x2F;github.com&#x2F;langchain-ai&#x2F;langchain LangChain API文档：https:&#x2F;&#x2F;python.langchain.com&#x2F;docs&#x2F;get_started 大语言模型实践：https:&#x2F;&#x2F;wangwei1">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg">
<meta property="article:published_time" content="2024-02-07T00:00:00.000Z">
<meta property="article:modified_time" content="2024-08-05T06:45:26.189Z">
<meta property="article:author" content="梦之痕">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://baihlup.github.io/2024/02/07/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/03%20-%20Langchain%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Langchain 详解与实战',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-05 06:45:26'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="梦之痕"><span class="site-name">梦之痕</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Langchain 详解与实战</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-02-07T00:00:00.000Z" title="Created 2024-02-07 00:00:00">2024-02-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-08-05T06:45:26.189Z" title="Updated 2024-08-05 06:45:26">2024-08-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E5%A4%A7%E6%95%B0%E6%8D%AE/">人工智能&amp;大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Langchain 详解与实战"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="0-参考资料"><a href="#0-参考资料" class="headerlink" title="0 参考资料"></a>0 参考资料</h1><h2 id="0-1-网站"><a href="#0-1-网站" class="headerlink" title="0.1 网站"></a>0.1 网站</h2><ul>
<li>LangChain 中文网：<a target="_blank" rel="noopener" href="https://www.langchain.asia/">https://www.langchain.asia/</a></li>
<li>LangChain Github：<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></li>
<li>LangChain API文档：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/get_started">https://python.langchain.com/docs/get_started</a></li>
<li>大语言模型实践：<a target="_blank" rel="noopener" href="https://wangwei1237.github.io/LLM_in_Action/">https://wangwei1237.github.io/LLM_in_Action&#x2F;</a></li>
</ul>
<h2 id="0-2-课程"><a href="#0-2-课程" class="headerlink" title="0.2 课程"></a>0.2 课程</h2><ul>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/655">《LangChain 实战课》</a></li>
</ul>
<h2 id="0-3-开源项目"><a href="#0-3-开源项目" class="headerlink" title="0.3 开源项目"></a>0.3 开源项目</h2><ol>
<li>AutoGPT：<a target="_blank" rel="noopener" href="https://github.com/Significant-Gravitas/AutoGPT">https://github.com/Significant-Gravitas/AutoGPT</a></li>
<li>AgentBench：<a target="_blank" rel="noopener" href="https://github.com/THUDM/AgentBench">https://github.com/THUDM/AgentBench</a> （测试 Agent 性能）</li>
<li>ChatALL：<a target="_blank" rel="noopener" href="https://github.com/sunner/ChatALL">https://github.com/sunner/ChatALL</a> （对多个大模型进行整合输出）</li>
</ol>
<h1 id="1-LangChain-安装和使用"><a href="#1-LangChain-安装和使用" class="headerlink" title="1 LangChain 安装和使用"></a>1 LangChain 安装和使用</h1><h2 id="1-1-LangChain-安装"><a href="#1-1-LangChain-安装" class="headerlink" title="1.1 LangChain 安装"></a>1.1 LangChain 安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain[llms]</span><br><span class="line"><span class="comment"># 升级到最新版本</span></span><br><span class="line">pip install --upgrade langchain</span><br></pre></td></tr></table></figure>
<h2 id="1-2-OpenAI-API"><a href="#1-2-OpenAI-API" class="headerlink" title="1.2 OpenAI API"></a>1.2 OpenAI API</h2><p>OpenAI API文档：<a target="_blank" rel="noopener" href="https://platform.openai.com/docs/introduction">https://platform.openai.com/docs/introduction</a></p>
<h3 id="1-2-1-调用-Text-模型"><a href="#1-2-1-调用-Text-模型" class="headerlink" title="1.2.1 调用 Text 模型"></a>1.2.1 调用 Text 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI  </span><br><span class="line">client = OpenAI()  </span><br><span class="line">  </span><br><span class="line">response = client.completions.create(  </span><br><span class="line">  model=<span class="string">&quot;gpt-3.5-turbo-instruct&quot;</span>,  </span><br><span class="line">  temperature=<span class="number">0.5</span>,  </span><br><span class="line">  max_tokens=<span class="number">1000</span>,  </span><br><span class="line">  prompt=<span class="string">&quot;请给我的花店起个名&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(response.choices[<span class="number">0</span>].text.strip())</span><br></pre></td></tr></table></figure>

<p>在使用OpenAI的文本生成模型时，可以通过一些参数来控制输出的内容和样式。这里我总结为了一些常见的参数。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240305153824.png"></p>
<p>调用 Text 模型后，响应对象的主要字段包括：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240305154036.png"></p>
<p>choices字段是一个列表，因为在某些情况下，你可以要求模型生成多个可能的输出。每个选择都是一个字典，其中包含以下字段：</p>
<ul>
<li>text：模型生成的文本。</li>
<li>finish_reason：模型停止生成的原因，可能的值包括 stop（遇到了停止标记）、length（达到了最大长度）或 temperature（根据设定的温度参数决定停止）。<br>所以， <code>response.choices[0].text.strip()</code> 这行代码的含义是：从响应中获取第一个（如果在调用大模型时，没有指定n参数，那么就只有唯一的一个响应）选择，然后获取该选择的文本，并移除其前后的空白字符。这通常是你想要的模型的输出。</li>
</ul>
<h3 id="1-2-2-调用-Chat-模型"><a href="#1-2-2-调用-Chat-模型" class="headerlink" title="1.2.2 调用 Chat 模型"></a>1.2.2 调用 Chat 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line">client = OpenAI()</span><br><span class="line"></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">  model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">  messages=[</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Who won the world series in 2020?&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;The Los Angeles Dodgers won the World Series in 2020.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Where was it played?&quot;</span>&#125;</span><br><span class="line">  ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在OpenAI的Chat模型中，system、user和assistant都是消息的角色。每一种角色都有不同的含义和作用。</p>
<ul>
<li>system：系统消息主要用于设定对话的背景或上下文。这可以帮助模型理解它在对话中的角色和任务。例如，你可以通过系统消息来设定一个场景，让模型知道它是在扮演一个医生、律师或者一个知识丰富的AI助手。系统消息通常在对话开始时给出。</li>
<li>user：用户消息是从用户或人类角色发出的。它们通常包含了用户想要模型回答或完成的请求。用户消息可以是一个问题、一段话，或者任何其他用户希望模型响应的内容。</li>
<li>assistant：助手消息是模型的回复。例如，在你使用API发送多轮对话中新的对话请求时，可以通过助手消息提供先前对话的上下文。然而，请注意在对话的最后一条消息应始终为用户消息，因为模型总是要回应最后这条用户消息。</li>
</ul>
<p>在使用Chat模型生成内容后，返回的 <strong>响应</strong>，也就是response会包含一个或多个choices，每个choices都包含一个message。每个message也都包含一个role和content。role可以是system、user或assistant，表示该消息的发送者，content则包含了消息的实际内容。响应内容格式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;choices&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;finish_reason&quot;</span>: <span class="string">&quot;stop&quot;</span>,</span><br><span class="line">      <span class="string">&quot;index&quot;</span>: 0,</span><br><span class="line">      <span class="string">&quot;message&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;The 2020 World Series was played in Texas at Globe Life Field in Arlington.&quot;</span>,</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">&quot;logprobs&quot;</span>: null</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;created&quot;</span>: 1677664795,</span><br><span class="line">  <span class="string">&quot;id&quot;</span>: <span class="string">&quot;chatcmpl-7QyqpwdfhqwajicIEznoc6Q47XAyW&quot;</span>,</span><br><span class="line">  <span class="string">&quot;model&quot;</span>: <span class="string">&quot;gpt-3.5-turbo-0613&quot;</span>,</span><br><span class="line">  <span class="string">&quot;object&quot;</span>: <span class="string">&quot;chat.completion&quot;</span>,</span><br><span class="line">  <span class="string">&quot;usage&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;completion_tokens&quot;</span>: 17,</span><br><span class="line">    <span class="string">&quot;prompt_tokens&quot;</span>: 57,</span><br><span class="line">    <span class="string">&quot;total_tokens&quot;</span>: 74</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以下是个字段的含义：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240305154545.png"></p>
<h2 id="1-3-通过-LangChain-调用-Text-模型和-Chat模型"><a href="#1-3-通过-LangChain-调用-Text-模型和-Chat模型" class="headerlink" title="1.3 通过 LangChain 调用 Text 模型和 Chat模型"></a>1.3 通过 LangChain 调用 Text 模型和 Chat模型</h2><h3 id="1-3-1-调用-Text-模型"><a href="#1-3-1-调用-Text-模型" class="headerlink" title="1.3.1 调用 Text 模型"></a>1.3.1 调用 Text 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI  </span><br><span class="line">llm = OpenAI(    </span><br><span class="line">    model=<span class="string">&quot;gpt-3.5-turbo-instruct&quot;</span>,  </span><br><span class="line">    temperature=<span class="number">0.8</span>,  </span><br><span class="line">    max_tokens=<span class="number">60</span>,)  </span><br><span class="line">response = llm.predict(<span class="string">&quot;请给我的花店起个名&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<h3 id="1-3-2-调用-Chat-模型"><a href="#1-3-2-调用-Chat-模型" class="headerlink" title="1.3.2 调用 Chat 模型"></a>1.3.2 调用 Chat 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI  </span><br><span class="line">chat = ChatOpenAI(model=<span class="string">&quot;gpt-4&quot;</span>,  </span><br><span class="line">                    temperature=<span class="number">0.8</span>,  </span><br><span class="line">                    max_tokens=<span class="number">60</span>)  </span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (  </span><br><span class="line">    HumanMessage,  </span><br><span class="line">    SystemMessage  </span><br><span class="line">)  </span><br><span class="line">messages = [  </span><br><span class="line">    SystemMessage(content=<span class="string">&quot;你是一个很棒的智能助手&quot;</span>),  </span><br><span class="line">    HumanMessage(content=<span class="string">&quot;请给我的花店起个名&quot;</span>)  </span><br><span class="line">]  </span><br><span class="line">response = chat(messages)  </span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content=<span class="string">&#x27;为您的花店起名时，我们可以考虑一些富有创意和意义的选项，同时也要易于记忆。这里有几个建议：\n\n1. **花语轩**：这个名字简洁优雅，寓意每一朵花都有其独特的语言和意义，适合一个提供精致花艺设计的花店。\n2. **绽放轨迹**：暗示着花朵从含苞待放到绽放的美丽过程，也象征着人生中美好瞬间的捕捉和珍藏。\n3. **彩云间花舍**：给人一种梦幻而温馨的感觉，像是在彩云之间开设的一家花店，充满了浪漫和想象空间。\n4. **时光花语**：这个名字传达了花朵与时间的关系，每一朵花都代表着一个特定的时刻或记忆。&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>LangChain 不止支持 OpenAI模型，可以试试 HuggingFace 开源社区的其他模型</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> HuggingFaceHub</span><br><span class="line">llm = HuggingFaceHub(model_id=<span class="string">&quot;bigscience/bloom-1b7&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="1-4-LangChain-构建问答系统"><a href="#1-4-LangChain-构建问答系统" class="headerlink" title="1.4 LangChain 构建问答系统"></a>1.4 LangChain 构建问答系统</h1><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/huangjia2019/langchain/tree/main/02_%E6%96%87%E6%A1%A3QA%E7%B3%BB%E7%BB%9F">文档QA系统</a></li>
</ul>
<h1 id="2-LangChain-核心组件"><a href="#2-LangChain-核心组件" class="headerlink" title="2 LangChain 核心组件"></a>2 LangChain 核心组件</h1><h2 id="2-1-模型-I-O"><a href="#2-1-模型-I-O" class="headerlink" title="2.1 模型 I&#x2F;O"></a>2.1 模型 I&#x2F;O</h2><p>Model I&#x2F;O 文档：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/model_io/">https://python.langchain.com/docs/modules/model_io&#x2F;</a></p>
<h3 id="2-1-1-Model-I-O"><a href="#2-1-1-Model-I-O" class="headerlink" title="2.1.1 Model I&#x2F;O"></a>2.1.1 Model I&#x2F;O</h3><p>可以把对模型的使用过程拆解成三块，分别是 <strong>输入提示</strong>（对应图中的Format）、 <strong>调用模型</strong>（对应图中的Predict）和 <strong>输出解析</strong>（对应图中的Parse）。这三块形成了一个整体，因此在LangChain中这个过程被统称为 <strong>Model I&#x2F;O</strong>（Input&#x2F;Output）。</p>
<p>在模型 I&#x2F;O的每个环节，LangChain都为咱们提供了模板和工具，快捷地形成调用各种语言模型的接口。</p>
<ol>
<li><strong>提示模板</strong>：使用模型的第一个环节是把提示信息输入到模型中，你可以创建LangChain模板，根据实际需求动态选择不同的输入，针对特定的任务和应用调整输入。</li>
<li><strong>语言模型</strong>：LangChain允许你通过通用接口来调用语言模型。这意味着无论你要使用的是哪种语言模型，都可以通过同一种方式进行调用，这样就提高了灵活性和便利性。</li>
<li><strong>输出解析</strong>：LangChain还提供了从模型输出中提取信息的功能。通过输出解析器，你可以精确地从模型的输出中获取需要的信息，而不需要处理冗余或不相关的数据，更重要的是还可以把大模型给回的非结构化文本，转换成程序可以处理的结构化数据。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240305165848.png"></li>
</ol>
<h3 id="2-1-2-提示模板"><a href="#2-1-2-提示模板" class="headerlink" title="2.1.2 提示模板"></a>2.1.2 提示模板</h3><p>提示框架包括如下部分：</p>
<ul>
<li><strong>指令</strong>（Instuction）告诉模型这个任务大概要做什么、怎么做，比如如何使用提供的外部信息、如何处理查询以及如何构造输出。这通常是一个提示模板中比较固定的部分。一个常见用例是告诉模型“你是一个有用的XX助手”，这会让他更认真地对待自己的角色。</li>
<li><strong>上下文</strong>（Context）则充当模型的额外知识来源。这些信息可以手动插入到提示中，通过矢量数据库检索得来，或通过其他方式（如调用API、计算器等工具）拉入。一个常见的用例时是把从向量数据库查询到的知识作为上下文传递给模型。</li>
<li><strong>提示输入</strong>（Prompt Input）通常就是具体的问题或者需要大模型做的具体事情，这个部分和“指令”部分其实也可以合二为一。但是拆分出来成为一个独立的组件，就更加结构化，便于复用模板。这通常是作为变量，在调用模型之前传递给提示模板，以形成具体的提示。</li>
<li><strong>输出指示器</strong>（Output Indicator）标记​​要生成的文本的开始。这就像我们小时候的数学考卷，先写一个“解”，就代表你要开始答题了。如果生成 Python 代码，可以使用 “import” 向模型表明它必须开始编写 Python 代码（因为大多数 Python 脚本以import开头）。这部分在我们和ChatGPT对话时往往是可有可无的，当然LangChain中的代理在构建提示模板时，经常性的会用一个“Thought：”（思考）作为引导词，指示模型开始输出自己的推理（Reasoning）。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/login?redirect_course=chatgpt-prompt-eng">提示工程课程</a></p>
<p><strong>LangChain 提示模板的类型：</strong><br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240306092557.png"></p>
<h4 id="2-1-2-1-PromptTemplate"><a href="#2-1-2-1-PromptTemplate" class="headerlink" title="2.1.2.1 PromptTemplate"></a>2.1.2.1 PromptTemplate</h4><p>通过 PromptTemplate 构建提示模板，第一种方式，通过占位符的方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入LangChain中的提示模板  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate  </span><br><span class="line"><span class="comment"># 创建原始模板  </span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;您是一位专业的鲜花店文案撰写员。\n  </span></span><br><span class="line"><span class="string">对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line"><span class="comment"># 根据原始模板创建LangChain提示模板  </span></span><br><span class="line">prompt = PromptTemplate.from_template(template)  </span><br><span class="line"><span class="comment"># 打印LangChain提示模板的内容  </span></span><br><span class="line"><span class="built_in">print</span>(prompt)  </span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(flower_name=<span class="string">&#x27;鲜花&#x27;</span>, price=<span class="string">&#x27;50&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>提示模板的具体内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_variables=[<span class="string">&#x27;flower_name&#x27;</span>, <span class="string">&#x27;price&#x27;</span>] </span><br><span class="line">template=<span class="string">&#x27;您是一位专业的鲜花店文案撰写员。\n\n对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？\n&#x27;</span></span><br><span class="line">您是一位专业的鲜花店文案撰写员。</span><br><span class="line"></span><br><span class="line">对于售价为 50 元的 鲜花 ，您能提供一个吸引人的简短描述吗？</span><br></pre></td></tr></table></figure>
<p>另一种方式，通过 PromptTemplate 类的构造函数，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(  </span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>, <span class="string">&quot;market&quot;</span>],  </span><br><span class="line">    template=<span class="string">&quot;你是业务咨询顾问。对于一个面向 &#123;market&#125; 市场的，专注于销售 &#123;product&#125; 的公司，你会推荐哪个名字？&quot;</span>  </span><br><span class="line">)  </span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(product=<span class="string">&quot;鲜花&quot;</span>, market=<span class="string">&quot;高端&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>输出的提示内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你是业务咨询顾问。对于一个面向 高端 市场的，专注于销售 鲜花 的公司，你会推荐哪个名字？</span><br></pre></td></tr></table></figure>

<p>LangChain 提供了多个类和函数，也 <strong>为各种应用场景设计了很多内置模板，使构建和使用提示变得容易</strong>。</p>
<h4 id="2-1-2-2-ChatPromptTemplate"><a href="#2-1-2-2-ChatPromptTemplate" class="headerlink" title="2.1.2.2 ChatPromptTemplate"></a>2.1.2.2 ChatPromptTemplate</h4><p>ChatPromptTemplate 对应聊天模型的模板，提供一系列角色设计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入聊天消息类模板  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (  </span><br><span class="line">    ChatPromptTemplate,  </span><br><span class="line">    SystemMessagePromptTemplate,  </span><br><span class="line">    HumanMessagePromptTemplate,  </span><br><span class="line">)  </span><br><span class="line"><span class="comment"># 模板的构建  </span></span><br><span class="line">template=<span class="string">&quot;你是一位专业顾问，负责为专注于&#123;product&#125;的公司起名。&quot;</span>  </span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)  </span><br><span class="line">human_template=<span class="string">&quot;公司主打产品是&#123;product_detail&#125;。&quot;</span>  </span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)  </span><br><span class="line">prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 格式化提示消息生成提示  </span></span><br><span class="line">prompt = prompt_template.format_prompt(product=<span class="string">&quot;鲜花装饰&quot;</span>, product_detail=<span class="string">&quot;创新的鲜花设计。&quot;</span>).to_messages()  </span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>
<p>输出的提示内容是一个列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[SystemMessage(content=<span class="string">&#x27;你是一位专业顾问，负责为专注于鲜花装饰的公司起名。&#x27;</span>), HumanMessage(content=<span class="string">&#x27;公司主打产品是创新的鲜花设计。。&#x27;</span>)]</span><br></pre></td></tr></table></figure>

<h4 id="2-1-2-3-FewShotPromptTemplate"><a href="#2-1-2-3-FewShotPromptTemplate" class="headerlink" title="2.1.2.3 FewShotPromptTemplate"></a>2.1.2.3 FewShotPromptTemplate</h4><ul>
<li>FewShot 思想<br>Few-Shot（少样本）、One-Shot（单样本）和与之对应的 Zero-Shot（零样本）的概念都起源于机器学习。如何让机器学习模型在极少量甚至没有示例的情况下学习到新的概念或类别，对于许多现实世界的问题是非常有价值的，因为我们往往无法获取到大量的标签化数据。</li>
</ul>
<p>FewShotPromptTemplate 的使用分为以下几步：</p>
<ol>
<li>创建示例样本</li>
<li>创建一个提示模板：会根据指定的输入变量和模板产生提示</li>
<li>创建 FewShotPromptTemplate 对象</li>
<li>调用大模型创建新文案<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 创建一些示例  </span></span><br><span class="line">samples = [  </span><br><span class="line">  </span><br><span class="line">  &#123;  </span><br><span class="line">    <span class="string">&quot;flower_type&quot;</span>: <span class="string">&quot;玫瑰&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;occasion&quot;</span>: <span class="string">&quot;爱情&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;ad_copy&quot;</span>: <span class="string">&quot;玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。&quot;</span>  </span><br><span class="line">  &#125;,  </span><br><span class="line">  &#123;  </span><br><span class="line">    <span class="string">&quot;flower_type&quot;</span>: <span class="string">&quot;康乃馨&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;occasion&quot;</span>: <span class="string">&quot;母亲节&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;ad_copy&quot;</span>: <span class="string">&quot;康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。&quot;</span>  </span><br><span class="line">  &#125;,  </span><br><span class="line">  &#123;  </span><br><span class="line">    <span class="string">&quot;flower_type&quot;</span>: <span class="string">&quot;百合&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;occasion&quot;</span>: <span class="string">&quot;庆祝&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;ad_copy&quot;</span>: <span class="string">&quot;百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。&quot;</span>  </span><br><span class="line">  &#125;,  </span><br><span class="line">  &#123;  </span><br><span class="line">    <span class="string">&quot;flower_type&quot;</span>: <span class="string">&quot;向日葵&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;occasion&quot;</span>: <span class="string">&quot;鼓励&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;ad_copy&quot;</span>: <span class="string">&quot;向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。&quot;</span>  </span><br><span class="line">  &#125;  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2. 创建一个提示模板  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts.prompt <span class="keyword">import</span> PromptTemplate  </span><br><span class="line">prompt_sample = PromptTemplate(input_variables=[<span class="string">&quot;flower_type&quot;</span>, <span class="string">&quot;occasion&quot;</span>, <span class="string">&quot;ad_copy&quot;</span>],   </span><br><span class="line">                               template=<span class="string">&quot;鲜花类型: &#123;flower_type&#125;\n场合: &#123;occasion&#125;\n文案: &#123;ad_copy&#125;&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(prompt_sample.<span class="built_in">format</span>(**samples[<span class="number">0</span>]))  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3. 创建一个FewShotPromptTemplate对象  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate  </span><br><span class="line">prompt = FewShotPromptTemplate(  </span><br><span class="line">    examples=samples,  </span><br><span class="line">    example_prompt=prompt_sample,  </span><br><span class="line">    suffix=<span class="string">&quot;鲜花类型: &#123;flower_type&#125;\n场合: &#123;occasion&#125;&quot;</span>,  </span><br><span class="line">    input_variables=[<span class="string">&quot;flower_type&quot;</span>, <span class="string">&quot;occasion&quot;</span>]  </span><br><span class="line">)  </span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(flower_type=<span class="string">&quot;野玫瑰&quot;</span>, occasion=<span class="string">&quot;爱情&quot;</span>))  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4. 把提示传递给大模型  </span></span><br><span class="line"><span class="comment"># import os  </span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;你的OpenAI API Key&#x27;  </span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAI  </span><br><span class="line">model = OpenAI(model_name=<span class="string">&#x27; gpt-3.5-turbo-0613&#x27;</span>)  </span><br><span class="line">result = model(prompt.<span class="built_in">format</span>(flower_type=<span class="string">&quot;野玫瑰&quot;</span>, occasion=<span class="string">&quot;爱情&quot;</span>))  </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
生成的 prompt 如下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">鲜花类型: 玫瑰</span><br><span class="line">场合: 爱情</span><br><span class="line">文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。</span><br><span class="line">鲜花类型: 玫瑰</span><br><span class="line">场合: 爱情</span><br><span class="line">文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。</span><br><span class="line"></span><br><span class="line">鲜花类型: 康乃馨</span><br><span class="line">场合: 母亲节</span><br><span class="line">文案: 康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。</span><br><span class="line"></span><br><span class="line">鲜花类型: 百合</span><br><span class="line">场合: 庆祝</span><br><span class="line">文案: 百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。</span><br><span class="line"></span><br><span class="line">鲜花类型: 向日葵</span><br><span class="line">场合: 鼓励</span><br><span class="line">文案: 向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。</span><br><span class="line"></span><br><span class="line">鲜花类型: 野玫瑰</span><br><span class="line">场合: 爱情</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="2-1-2-4-示例选择器SemanticSimilarityExampleSelector"><a href="#2-1-2-4-示例选择器SemanticSimilarityExampleSelector" class="headerlink" title="2.1.2.4 示例选择器SemanticSimilarityExampleSelector"></a>2.1.2.4 示例选择器SemanticSimilarityExampleSelector</h4><p>如果示例很多，那么一次性把所有示例发送给模型是不现实而且低效的。另外，每次都包含太多的Token也会浪费流量。<br>LangChain提供了示例选择器，来选择最合适的样本。（注意，因为示例选择器使用向量相似度比较的功能，此处需要安装向量数据库，这里使用的是开源的Chroma，也可以选择其他如 Qdrant 等。）<br>先安装 Chroma 向量数据库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install chromadb</span><br></pre></td></tr></table></figure>
<p>使用示例选择器的示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用示例选择器  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector <span class="keyword">import</span> SemanticSimilarityExampleSelector  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化示例选择器  </span></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(  </span><br><span class="line">    samples,  </span><br><span class="line">    OpenAIEmbeddings(),  </span><br><span class="line">    Chroma,  </span><br><span class="line">    k=<span class="number">1</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建一个使用示例选择器的FewShotPromptTemplate对象  </span></span><br><span class="line">prompt = FewShotPromptTemplate(  </span><br><span class="line">    example_selector=example_selector,  </span><br><span class="line">    example_prompt=prompt_sample,  </span><br><span class="line">    suffix=<span class="string">&quot;鲜花类型: &#123;flower_type&#125;\n场合: &#123;occasion&#125;&quot;</span>,  </span><br><span class="line">    input_variables=[<span class="string">&quot;flower_type&quot;</span>, <span class="string">&quot;occasion&quot;</span>]  </span><br><span class="line">)  </span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(flower_type=<span class="string">&quot;红玫瑰&quot;</span>, occasion=<span class="string">&quot;爱情&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">鲜花类型: 玫瑰</span><br><span class="line">场合: 爱情</span><br><span class="line">文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。</span><br><span class="line"></span><br><span class="line">鲜花类型: 红玫瑰</span><br><span class="line">场合: 爱情</span><br></pre></td></tr></table></figure>
<ol>
<li>首先创建了SemanticSimilarityExampleSelector对象，这个对象可以根据语义相似性选择最相关的示例。</li>
<li>创建了一个新的FewShotPromptTemplate对象，这个对象使用了上一步创建的选择器来选择最相关的示例生成提示。</li>
<li>用这个模板生成了一个新的提示，提示中需要创建的是红玫瑰的文案，所以，示例选择器example_selector会根据语义的相似度（余弦相似度）找到最相似的示例，也就是“玫瑰”，并用这个示例构建一个FewShot模板。</li>
</ol>
<h4 id="2-1-2-5-思维链-和-思维树"><a href="#2-1-2-5-思维链-和-思维树" class="headerlink" title="2.1.2.5 思维链 和 思维树"></a>2.1.2.5 思维链 和 思维树</h4><ol>
<li>思维链</li>
</ol>
<p>Chain of Thought（CoT，即“思维链”）的核心思想是通过生成一系列中间推理步骤来增强模型的推理能力。在Few-Shot CoT 中通过提供链式思考示例传递给模型，根据示例模型可以生成正确的答案。Zero-Shot CoT 是需要告诉模型“ <strong>让我们一步步的思考（Let’s think step by step）</strong>”，模型就能够给出更好的答案。</p>
<p><strong>思维链 实战示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建聊天模型  </span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI  </span><br><span class="line">llm = ChatOpenAI(temperature=<span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设定 AI 的角色和目标  </span></span><br><span class="line">role_template = <span class="string">&quot;你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）  </span></span><br><span class="line">cot_template = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。   </span></span><br><span class="line"><span class="string">我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。  </span></span><br><span class="line"><span class="string">同时，我也会向客户解释我这样推荐的原因。  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">示例 1:  人类：我想找一种象征爱情的花。  </span></span><br><span class="line"><span class="string">  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">示例 2:  人类：我想要一些独特和奇特的花。  </span></span><br><span class="line"><span class="string">  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate  </span><br><span class="line">system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)  </span><br><span class="line">system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 用户的询问  </span></span><br><span class="line">human_template = <span class="string">&quot;&#123;human_input&#125;&quot;</span>  </span><br><span class="line">human_prompt = HumanMessagePromptTemplate.from_template(human_template)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 将以上所有信息结合为一个聊天提示  </span></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])  </span><br><span class="line">  </span><br><span class="line">prompt = chat_prompt.format_prompt(human_input=<span class="string">&quot;我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?&quot;</span>).to_messages()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 接收用户的询问，返回回答结果  </span></span><br><span class="line">response = llm(prompt)  </span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content=<span class="string">&#x27;根据你女朋友喜欢粉色和紫色的喜好，我会推荐以下几种花给你：\n\n1. **粉色康乃馨（Carnation）**：康乃馨是一种美丽且经典的花朵，粉色的康乃馨通常象征着母爱、友谊和善良。它们的花语也包括关怀和感激之情，是一种很适合送给女朋友的花。\n\n2. **紫色勿忘我（Forget-Me-Not）**：勿忘我是一种小巧可爱的花朵，紫色的勿忘我通常象征着真爱和忠诚。这种花也代表着永恒的爱情和美好的回忆，是表达对女朋友真挚感情的不错选择。\n\n3. **粉色玫瑰（Pink Rose）**：粉色玫瑰是一种温柔和浪漫的花朵，通常代表着感恩、喜悦和甜蜜的情感。送粉色玫瑰给女朋友可以表达你对她的爱意和关怀。\n\n希望这些建议能帮助你选择合适的花束来表达对女朋友的感情。&#x27;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>思维树（Tree of Thoughts，ToT）</li>
</ol>
<p>ToT是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240306144833.png"><br>ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为3个思维步骤，并为每个步骤提出多个方案，并保留最优的5个候选方案。然后在多条思维路径中搜寻最优的解决方案。<br>这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。</p>
<p>思维树（ToT）的应用方法和示例：<a target="_blank" rel="noopener" href="https://github.com/kyegomez/tree-of-thoughts">https://github.com/kyegomez/tree-of-thoughts</a></p>
<h3 id="2-1-3-语言模型"><a href="#2-1-3-语言模型" class="headerlink" title="2.1.3 语言模型"></a>2.1.3 语言模型</h3><p>LangChain中支持的模型有三大类。</p>
<ol>
<li>大语言模型（LLM） ，也叫Text Model，这些模型将文本字符串作为输入，并返回文本字符串作为输出。Open AI的text-davinci-003、Facebook的LLaMA、ANTHROPIC的Claude，都是典型的LLM。</li>
<li>聊天模型（Chat Model），主要代表Open AI的ChatGPT系列模型。这些模型通常由语言模型支持，但它们的 API 更加结构化。具体来说，这些模型将聊天消息列表作为输入，并返回聊天消息。</li>
<li>文本嵌入模型（Embedding Model），这些模型将文本作为输入并返回浮点数列表，也就是Embedding。而文本嵌入模型如OpenAI的text-embedding-ada-002，我们之前已经见过了。文本嵌入模型负责把文档存入向量数据库，和我们这里探讨的提示工程关系不大。</li>
</ol>
<p><strong>预训练+微调的模式：</strong></p>
<ul>
<li><strong>预训练</strong>：在大规模无标注文本数据上进行模型的训练，目标是让模型学习自然语言的基础表达、上下文信息和语义知识，为后续任务提供一个通用的、丰富的语言表示基础。</li>
<li><strong>微调</strong>：在预训练模型的基础上，可以根据特定的下游任务对模型进行微调。现在你经常会听到各行各业的人说： _我们的优势就是领域知识嘛！我们比不过国内外大模型，我们可以拿开源模型做垂直领域嘛！做垂类模型！_—— 啥叫垂类？指的其实就是根据领域数据微调开源模型这件事儿。<br>预训练+微调的大模型应用模式优势明显。首先，预训练模型能够将大量的通用语言知识迁移到各种下游任务上，作为应用人员，我们不需要自己寻找语料库，从头开始训练大模型，这减少了训练时间和数据需求；其次，微调过程可以快速地根据特定任务进行优化，简化了模型部署的难度；最后，预训练+微调的架构具有很强的可扩展性，可以方便地应用于各种自然语言处理任务，大大提高了NLP技术在实际应用中的可用性和普及程度，给我们带来了巨大的便利。</li>
</ul>
<h4 id="2-1-3-1-用-HuggingFace-跑开源模型"><a href="#2-1-3-1-用-HuggingFace-跑开源模型" class="headerlink" title="2.1.3.1 用 HuggingFace 跑开源模型"></a>2.1.3.1 用 HuggingFace 跑开源模型</h4><ul>
<li>注册并安装 HuggingFace</li>
</ul>
<p>第一步，还是要登录 <a target="_blank" rel="noopener" href="https://huggingface.co/">HuggingFace</a> 网站，并拿到专属于你的Token。（如果你做了前面几节课的实战案例，那么你应该已经有这个API Token了）<br>第二步，用 <code>pip install transformers</code> 安装HuggingFace Library。详见 <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/installation">这里</a>。<br>第三步，在命令行中运行 <code>huggingface-cli login</code>，设置API Token，或者在程序中设置环境变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入HuggingFace API Token</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;HUGGINGFACEHUB_API_TOKEN&#x27;</span>] = <span class="string">&#x27;你的HuggingFace API Token&#x27;</span></span><br></pre></td></tr></table></figure>



<h4 id="2-1-3-2-LangChain-和-HuggingFace-的接口"><a href="#2-1-3-2-LangChain-和-HuggingFace-的接口" class="headerlink" title="2.1.3.2 LangChain 和 HuggingFace 的接口"></a>2.1.3.2 LangChain 和 HuggingFace 的接口</h4><h4 id="2-1-3-3-用-LangChain-调用自定义语言模型"><a href="#2-1-3-3-用-LangChain-调用自定义语言模型" class="headerlink" title="2.1.3.3 用 LangChain 调用自定义语言模型"></a>2.1.3.3 用 LangChain 调用自定义语言模型</h4><h3 id="2-1-4-输出解析"><a href="#2-1-4-输出解析" class="headerlink" title="2.1.4 输出解析"></a>2.1.4 输出解析</h3><p>增加输出解析的完整示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, OpenAI  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入OpenAI Key  </span></span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;你的OpenAI API Key&#x27;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建提示模板  </span></span><br><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;您是一位专业的鲜花店文案撰写员。  </span></span><br><span class="line"><span class="string">对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？  </span></span><br><span class="line"><span class="string">&#123;format_instructions&#125;&quot;&quot;&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建模型实例  </span></span><br><span class="line">model = OpenAI(model_name=<span class="string">&#x27;text-davinci-003&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入结构化输出解析器和ResponseSchema  </span></span><br><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> StructuredOutputParser, ResponseSchema  </span><br><span class="line"><span class="comment"># 定义我们想要接收的响应模式  </span></span><br><span class="line">response_schemas = [  </span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;description&quot;</span>, description=<span class="string">&quot;鲜花的描述文案&quot;</span>),  </span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;reason&quot;</span>, description=<span class="string">&quot;问什么要这样写这个文案&quot;</span>)  </span><br><span class="line">]  </span><br><span class="line"><span class="comment"># 创建输出解析器  </span></span><br><span class="line">output_parser = StructuredOutputParser.from_response_schemas(response_schemas)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 获取格式指示  </span></span><br><span class="line">format_instructions = output_parser.get_format_instructions()  </span><br><span class="line"><span class="comment"># 根据模板创建提示，同时在提示中加入输出解析器的说明  </span></span><br><span class="line">prompt = PromptTemplate.from_template(prompt_template,   </span><br><span class="line">                partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;)   </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 数据准备  </span></span><br><span class="line">flowers = [<span class="string">&quot;玫瑰&quot;</span>, <span class="string">&quot;百合&quot;</span>, <span class="string">&quot;康乃馨&quot;</span>]  </span><br><span class="line">prices = [<span class="string">&quot;50&quot;</span>, <span class="string">&quot;30&quot;</span>, <span class="string">&quot;20&quot;</span>]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建一个空的DataFrame用于存储结果  </span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">df = pd.DataFrame(columns=[<span class="string">&quot;flower&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;description&quot;</span>, <span class="string">&quot;reason&quot;</span>]) <span class="comment"># 先声明列名  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> flower, price <span class="keyword">in</span> <span class="built_in">zip</span>(flowers, prices):  </span><br><span class="line">    <span class="comment"># 根据提示准备模型的输入  </span></span><br><span class="line">    <span class="built_in">input</span> = prompt.<span class="built_in">format</span>(flower_name=flower, price=price)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 获取模型的输出  </span></span><br><span class="line">    output = model(<span class="built_in">input</span>)  </span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 解析模型的输出（这是一个字典结构）  </span></span><br><span class="line">    parsed_output = output_parser.parse(output)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 在解析后的输出中添加“flower”和“price”  </span></span><br><span class="line">    parsed_output[<span class="string">&#x27;flower&#x27;</span>] = flower  </span><br><span class="line">    parsed_output[<span class="string">&#x27;price&#x27;</span>] = price  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 将解析后的输出添加到DataFrame中  </span></span><br><span class="line">    df.loc[<span class="built_in">len</span>(df)] = parsed_output    </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 打印字典  </span></span><br><span class="line"><span class="built_in">print</span>(df.to_dict(orient=<span class="string">&#x27;records&#x27;</span>))  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 保存DataFrame到CSV文件  </span></span><br><span class="line">df.to_csv(<span class="string">&quot;flowers_with_descriptions.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>以上增加输出解析后，处理的 prompt 如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">您是一位专业的鲜花店文案撰写员。</span><br><span class="line">对于售价为 50 元的 玫瑰 ，您能提供一个吸引人的简短描述吗？</span><br><span class="line">The output should be a markdown code snippet formatted <span class="keyword">in</span> the following schema, including the leading and trailing <span class="string">&quot;```json&quot;</span> and <span class="string">&quot;```&quot;</span>:</span><br><span class="line"></span><br><span class="line">//```json</span><br><span class="line">&#123;</span><br><span class="line">	<span class="string">&quot;description&quot;</span>: string  // 鲜花的描述文案</span><br><span class="line">	<span class="string">&quot;reason&quot;</span>: string  // 问什么要这样写这个文案</span><br><span class="line">&#125;</span><br><span class="line">//```</span><br></pre></td></tr></table></figure>
<p>LangChain的输出解析对 prompt 增加特定处理。</p>
<h2 id="2-2-链（Chain）"><a href="#2-2-链（Chain）" class="headerlink" title="2.2 链（Chain）"></a>2.2 链（Chain）</h2><p>如果想开发更复杂的应用程序，那么就需要通过 “Chain” 来链接LangChain的各个组件和功能——模型之间彼此链接，或模型与其他组件链接。<br><strong>说到链的实现和使用，也简单。</strong></p>
<ul>
<li>首先LangChain通过设计好的接口，实现一个具体的链的功能。例如，LLM链（LLMChain）能够接受用户输入，使用 PromptTemplate 对其进行格式化，然后将格式化的响应传递给 LLM。这就相当于把整个Model I&#x2F;O的流程封装到链里面。</li>
<li>实现了链的具体功能之后，我们可以通过将多个链组合在一起，或者将链与其他组件组合来构建更复杂的链。<br>所以你看，链在内部把一系列的功能进行封装，而链的外部则又可以组合串联。 <strong>链其实可以被视为LangChain中的一种基本功能单元。</strong><br>LangChain中提供了很多种类型的预置链，目的是使各种各样的任务实现起来更加方便、规范。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240311151037.png"></p>
<p>LangChain中各种各样的链：<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chains">https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chains</a></p>
<h3 id="2-2-1-Sequential-Chain：顺序链"><a href="#2-2-1-Sequential-Chain：顺序链" class="headerlink" title="2.2.1 Sequential Chain：顺序链"></a>2.2.1 Sequential Chain：顺序链</h3><p>使用示例，我们的目标是这样的：</p>
<ul>
<li>第一步，我们假设大模型是一个植物学家，让他给出某种特定鲜花的知识和介绍。</li>
<li>第二步，我们假设大模型是一个鲜花评论者，让他参考上面植物学家的文字输出，对鲜花进行评论。</li>
<li>第三步，我们假设大模型是易速鲜花的社交媒体运营经理，让他参考上面植物学家和鲜花评论者的文字输出，来写一篇鲜花运营文案。</li>
</ul>
<p>首先，导入所有需要的库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;你的OpenAI API Key&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SequentialChain</span><br></pre></td></tr></table></figure>
<p>然后，添加第一个LLMChain，生成鲜花的知识性说明。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是第一个LLMChain，用于生成鲜花的介绍，输入为花的名称和种类</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">.7</span>)</span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个植物学家。给定花的名称和类型，你需要为这种花写一个200字左右的介绍。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">花名: &#123;name&#125;</span></span><br><span class="line"><span class="string">颜色: &#123;color&#125;</span></span><br><span class="line"><span class="string">植物学家: 这是关于上述花的介绍:&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate(input_variables=[<span class="string">&quot;name&quot;</span>, <span class="string">&quot;color&quot;</span>], template=template)</span><br><span class="line">introduction_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=<span class="string">&quot;introduction&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接着，添加第二个LLMChain，根据鲜花的知识性说明生成评论。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是第二个LLMChain，用于根据鲜花的介绍写出鲜花的评论</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">.7</span>)</span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一位鲜花评论家。给定一种花的介绍，你需要为这种花写一篇200字左右的评论。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">鲜花介绍:</span></span><br><span class="line"><span class="string">&#123;introduction&#125;</span></span><br><span class="line"><span class="string">花评人对上述花的评论:&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate(input_variables=[<span class="string">&quot;introduction&quot;</span>], template=template)</span><br><span class="line">review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=<span class="string">&quot;review&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>接着，添加第三个LLMChain，根据鲜花的介绍和评论写出一篇自媒体的文案。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是第三个LLMChain，用于根据鲜花的介绍和评论写出一篇自媒体的文案</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一家花店的社交媒体经理。给定一种花的介绍和评论，你需要为这种花写一篇社交媒体的帖子，300字左右。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">鲜花介绍:</span></span><br><span class="line"><span class="string">&#123;introduction&#125;</span></span><br><span class="line"><span class="string">花评人对上述花的评论:</span></span><br><span class="line"><span class="string">&#123;review&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">社交媒体帖子:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate(input_variables=[<span class="string">&quot;introduction&quot;</span>, <span class="string">&quot;review&quot;</span>], template=template)</span><br><span class="line">social_post_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=<span class="string">&quot;social_post_text&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>最后，添加SequentialChain，把前面三个链串起来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是总的链，我们按顺序运行这三个链</span></span><br><span class="line">overall_chain = SequentialChain(</span><br><span class="line">    chains=[introduction_chain, review_chain, social_post_chain],</span><br><span class="line">    input_variables=[<span class="string">&quot;name&quot;</span>, <span class="string">&quot;color&quot;</span>],</span><br><span class="line">    output_variables=[<span class="string">&quot;introduction&quot;</span>,<span class="string">&quot;review&quot;</span>,<span class="string">&quot;social_post_text&quot;</span>],</span><br><span class="line">    verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行链，并打印结果</span></span><br><span class="line">result = overall_chain(&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;玫瑰&quot;</span>, <span class="string">&quot;color&quot;</span>: <span class="string">&quot;黑色&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最终的输出如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new  chain...</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"><span class="punctuation">&#123;</span>&#x27;name&#x27;<span class="punctuation">:</span> &#x27;玫瑰&#x27;<span class="punctuation">,</span> &#x27;color&#x27;<span class="punctuation">:</span> &#x27;黑色&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;introduction&#x27;<span class="punctuation">:</span> &#x27;\n\n黑色玫瑰，这是一种对传统玫瑰花的独特颠覆，它的出现挑战了我们对玫瑰颜色的固有认知。它的花瓣如煤炭般黑亮，反射出独特的微光，而花蕊则是金黄色的，宛如夜空中的一颗星，强烈的颜色对比营造出一种前所未有的视觉效果。在植物学中，黑色玫瑰的出现无疑提供了一种新的研究方向，对于我们理解花朵色彩形成的机制有着重要的科学价值。&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;review&#x27;<span class="punctuation">:</span> &#x27;\n\n黑色玫瑰，这不仅仅是一种花朵，更是一种完全颠覆传统的艺术表现形式。黑色的花瓣仿佛在诉说一种不可言喻的悲伤与神秘，而黄色的蕊瓣犹如漆黑夜空中的一抹亮色，给人带来无尽的想象。它将悲伤与欢乐，神秘与明亮完美地结合在一起，这是一种全新的视觉享受，也是一种对生活理解的深度表达。&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;social_post_text&#x27;<span class="punctuation">:</span> &#x27;\n欢迎来到我们的自媒体平台，今天，我们要向您展示的是我们的全新产品——黑色玫瑰。这不仅仅是一种花，这是一种对传统观念的挑战，一种视觉艺术的革新，更是一种生活态度的象征。</span><br><span class="line">这种别样的玫瑰花，其黑色花瓣宛如漆黑夜空中闪烁的繁星，富有神秘的深度感，给人一种前所未有的视觉冲击力。这种黑色，它不是冷酷、不是绝望，而是充满着独特的魅力和力量。而位于黑色花瓣之中的金黄色花蕊，则犹如星星中的灵魂，默默闪烁，给人带来无尽的遐想，充满活力与生机。</span><br><span class="line">黑色玫瑰的存在，不仅挑战了我们对于玫瑰传统颜色的认知，它更是一种生动的生命象征，象征着那些坚韧、独特、勇敢面对生活的人们。黑色的花瓣中透露出一种坚韧的力量，而金黄的花蕊则是生活中的希望，二者的结合恰好象征了生活中的喜怒哀乐，体现了人生的百态。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>至此，就通过两个LLM链和一个顺序链，生成了一篇完美的文案。</p>
<h3 id="2-2-2-RouterChain：路由链"><a href="#2-2-2-RouterChain：路由链" class="headerlink" title="2.2.2 RouterChain：路由链"></a>2.2.2 RouterChain：路由链</h3><p>RouterChain，也叫路由链，能动态选择用于给定输入的下一个链。我们会根据用户的问题内容，首先使用路由器链确定问题更适合哪个处理模板，然后将问题发送到该处理模板进行回答。如果问题不适合任何已定义的处理模板，它会被发送到默认链。<br>在这里，我们会用LLMRouterChain和MultiPromptChain（也是一种路由链）组合实现路由功能，该MultiPromptChain会调用LLMRouterChain选择与给定问题最相关的提示，然后使用该提示回答问题。<br><strong>具体步骤如下：</strong></p>
<ol>
<li>构建处理模板：为鲜花护理和鲜花装饰分别定义两个字符串模板。</li>
<li>提示信息：使用一个列表来组织和存储这两个处理模板的关键信息，如模板的键、描述和实际内容。</li>
<li>初始化语言模型：导入并实例化语言模型。</li>
<li>构建目标链：根据提示信息中的每个模板构建了对应的LLMChain，并存储在一个字典中。</li>
<li>构建LLM路由链：这是决策的核心部分。首先，它根据提示信息构建了一个路由模板，然后使用这个模板创建了一个LLMRouterChain。</li>
<li>构建默认链：如果输入不适合任何已定义的处理模板，这个默认链会被触发。</li>
<li>构建多提示链：使用MultiPromptChain将LLM路由链、目标链和默认链组合在一起，形成一个完整的决策系统。</li>
</ol>
<h4 id="2-2-2-1-构建提示信息的模板"><a href="#2-2-2-1-构建提示信息的模板" class="headerlink" title="2.2.2.1 构建提示信息的模板"></a>2.2.2.1 构建提示信息的模板</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建两个场景的模板</span></span><br><span class="line">flower_care_template = <span class="string">&quot;&quot;&quot;你是一个经验丰富的园丁，擅长解答关于养花育花的问题。</span></span><br><span class="line"><span class="string">                        下面是需要你来回答的问题:</span></span><br><span class="line"><span class="string">                        &#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">flower_deco_template = <span class="string">&quot;&quot;&quot;你是一位网红插花大师，擅长解答关于鲜花装饰的问题。</span></span><br><span class="line"><span class="string">                        下面是需要你来回答的问题:</span></span><br><span class="line"><span class="string">                        &#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 构建提示信息</span></span><br><span class="line">prompt_infos = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;key&quot;</span>: <span class="string">&quot;flower_care&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;适合回答关于鲜花护理的问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;template&quot;</span>: flower_care_template,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;key&quot;</span>: <span class="string">&quot;flower_decoration&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;适合回答关于鲜花装饰的问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;template&quot;</span>: flower_deco_template,</span><br><span class="line">    &#125;]</span><br></pre></td></tr></table></figure>
<p>循环prompt_infos这个列表，构建出两个目标链，分别负责处理不同的问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建目标链</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.llm <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">chain_map = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> info <span class="keyword">in</span> prompt_infos:</span><br><span class="line">    prompt = PromptTemplate(template=info[<span class="string">&#x27;template&#x27;</span>],</span><br><span class="line">                            input_variables=[<span class="string">&quot;input&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;目标提示:\n&quot;</span>,prompt)</span><br><span class="line">    chain = LLMChain(llm=llm, prompt=prompt,verbose=<span class="literal">True</span>)</span><br><span class="line">    chain_map[info[<span class="string">&quot;key&quot;</span>]] = chain</span><br></pre></td></tr></table></figure>
<p>目标链提示是这样的：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">目标提示<span class="punctuation">:</span></span><br><span class="line">input_variables=<span class="punctuation">[</span>&#x27;input&#x27;<span class="punctuation">]</span></span><br><span class="line">output_parser=None partial_variables=<span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">template=&#x27;你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\n                        下面是需要你来回答的问题<span class="punctuation">:</span>\n</span><br><span class="line"><span class="punctuation">&#123;</span>input<span class="punctuation">&#125;</span>&#x27; template_format=&#x27;f-string&#x27;</span><br><span class="line">validate_template=True</span><br><span class="line"></span><br><span class="line">目标提示<span class="punctuation">:</span></span><br><span class="line">input_variables=<span class="punctuation">[</span>&#x27;input&#x27;<span class="punctuation">]</span></span><br><span class="line">output_parser=None partial_variables=<span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">template=&#x27;你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\n                        下面是需要你来回答的问题<span class="punctuation">:</span>\n</span><br><span class="line"><span class="punctuation">&#123;</span>input<span class="punctuation">&#125;</span>&#x27; template_format=&#x27;f-string&#x27;</span><br><span class="line">validate_template=True</span><br></pre></td></tr></table></figure>
<p>对于每个场景，创建一个 LLMChain（语言模型链）。每个链会根据其场景模板生成对应的提示，然后将这个提示送入语言模型获取答案。</p>
<h4 id="2-2-2-2-构建路由链"><a href="#2-2-2-2-构建路由链" class="headerlink" title="2.2.2.2 构建路由链"></a>2.2.2.2 构建路由链</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建路由链</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.llm_router <span class="keyword">import</span> LLMRouterChain, RouterOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.multi_prompt_prompt <span class="keyword">import</span> MULTI_PROMPT_ROUTER_TEMPLATE <span class="keyword">as</span> RounterTemplate</span><br><span class="line">destinations = [<span class="string">f&quot;<span class="subst">&#123;p[<span class="string">&#x27;key&#x27;</span>]&#125;</span>: <span class="subst">&#123;p[<span class="string">&#x27;description&#x27;</span>]&#125;</span>&quot;</span> <span class="keyword">for</span> p <span class="keyword">in</span> prompt_infos]</span><br><span class="line">router_template = RounterTemplate.<span class="built_in">format</span>(destinations=<span class="string">&quot;\n&quot;</span>.join(destinations))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;路由模板:\n&quot;</span>,router_template)</span><br><span class="line">router_prompt = PromptTemplate(</span><br><span class="line">    template=router_template,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_parser=RouterOutputParser(),)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;路由提示:\n&quot;</span>,router_prompt)</span><br><span class="line">router_chain = LLMRouterChain.from_llm(llm,</span><br><span class="line">                                       router_prompt,</span><br><span class="line">                                       verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">路由模板:</span><br><span class="line"> Given a raw text input to a language model <span class="keyword">select</span> the model prompt best suited <span class="keyword">for</span> the input. You will be given the names of the available prompts and a description of what the prompt is best suited <span class="keyword">for</span>. You may also revise the original input <span class="keyword">if</span> you think that revising it will ultimately lead to a better response from the language model.</span><br><span class="line"></span><br><span class="line">&lt;&lt; <span class="string">FORMATTING &gt;&gt;</span></span><br><span class="line"><span class="string">Return a markdown code snippet with a JSON object formatted to look like:</span></span><br><span class="line"><span class="string">```json</span></span><br><span class="line"><span class="string">&#123;&#123;</span></span><br><span class="line"><span class="string">    &quot;destination&quot;: string \ name of the prompt to use or &quot;DEFAULT&quot;</span></span><br><span class="line"><span class="string">    &quot;next_inputs&quot;: string \ a potentially modified version of the original input</span></span><br><span class="line"><span class="string">&#125;&#125;</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">REMEMBER: &quot;destination&quot; MUST be one of the candidate prompt names specified below OR it can be &quot;DEFAULT&quot; if the input is not well suited for any of the candidate prompts.</span></span><br><span class="line"><span class="string">REMEMBER: &quot;next_inputs&quot; can just be the original input if you don&#x27;t think any modifications are needed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;&lt; CANDIDATE PROMPTS &gt;&gt;</span></span><br><span class="line"><span class="string">flower_care: 适合回答关于鲜花护理的问题</span></span><br><span class="line"><span class="string">flower_decoration: 适合回答关于鲜花装饰的问题</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;&lt; INPUT &gt;&gt;</span></span><br><span class="line"><span class="string">&#123;input&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;&lt; OUTPUT &gt;&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">路由提示:</span></span><br><span class="line"><span class="string">input_variables=[&#x27;input&#x27;] output_parser=RouterOutputParser(default_destination=&#x27;DEFAULT&#x27;, next_inputs_type=&lt;class &#x27;str&#x27;&gt;, next_inputs_inner_key=&#x27;input&#x27;)</span></span><br><span class="line"><span class="string">partial_variables=&#123;&#125;</span></span><br><span class="line"><span class="string">template=&#x27;Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n\n</span></span><br><span class="line"><span class="string">&lt;&lt; FORMATTING</span> &gt;&gt;\n</span><br><span class="line">Return a markdown code snippet with a JSON object formatted to look like:\n```json\n&#123;&#123;\n <span class="string">&quot;destination&quot;</span>: string \\ name of the prompt to use or <span class="string">&quot;DEFAULT&quot;</span>\n    <span class="string">&quot;next_inputs&quot;</span>: string \\ a potentially modified version of the original input\n&#125;&#125;\n```\n\n</span><br><span class="line">REMEMBER: <span class="string">&quot;destination&quot;</span> MUST be one of the candidate prompt names specified below OR it can be <span class="string">&quot;DEFAULT&quot;</span> <span class="keyword">if</span> the input is not well suited <span class="keyword">for</span> any of the candidate prompts.\n</span><br><span class="line">REMEMBER: <span class="string">&quot;next_inputs&quot;</span> can just be the original input <span class="keyword">if</span> you don\<span class="string">&#x27;t think any modifications are needed.\n\n&lt;&lt; CANDIDATE PROMPTS &gt;&gt;\n</span></span><br><span class="line"><span class="string">flower_care: 适合回答关于鲜花护理的问题\n</span></span><br><span class="line"><span class="string">flower_decoration: 适合回答关于鲜花装饰的问题\n\n</span></span><br><span class="line"><span class="string">&lt;&lt; INPUT &gt;&gt;\n&#123;input&#125;\n\n&lt;&lt; OUTPUT &gt;&gt;\n&#x27;</span></span><br><span class="line">template_format=<span class="string">&#x27;f-string&#x27;</span></span><br><span class="line">validate_template=True</span><br></pre></td></tr></table></figure>
<ol>
<li>路由模板的解释</li>
</ol>
<p>路由模板是路由功能得以实现的核心。</p>
<ol start="2">
<li>路由提示的解释</li>
</ol>
<p>路由提示 (router_prompt）则根据路由模板，生成了具体传递给LLM的路由提示信息。</p>
<ul>
<li>其中input_variables 指定模板接收的输入变量名，这里只有 <code>&quot;input&quot;</code>。</li>
<li>output_parser 是一个用于解析模型输出的对象，它有一个默认的目的地和一个指向下一输入的键。</li>
<li>template 是实际的路由模板，用于给模型提供指示。这就是刚才详细解释的模板内容。</li>
<li>template_format 指定模板的格式，这里是 <code>&quot;f-string&quot;</code>。</li>
<li>validate_template 是一个布尔值，如果为 True，则会在使用模板前验证其有效性。</li>
</ul>
<p>这个构造允许你将用户的原始输入送入路由器，然后路由器会决定将该输入发送到哪个具体的模型提示，或者是否需要对输入进行修订以获得最佳的响应。</p>
<h4 id="2-2-2-3-构建默认链"><a href="#2-2-2-3-构建默认链" class="headerlink" title="2.2.2.3 构建默认链"></a>2.2.2.3 构建默认链</h4><p>除了处理目标链和路由链之外，还需要准备一个默认链。如果路由链没有找到适合的链，那么，就以默认链进行处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建默认链</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line">default_chain = ConversationChain(llm=llm,</span><br><span class="line">                                  output_key=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">                                  verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-4-构建多提示链"><a href="#2-2-2-4-构建多提示链" class="headerlink" title="2.2.2.4 构建多提示链"></a>2.2.2.4 构建多提示链</h4><p>使用MultiPromptChain类把前几个链整合在一起，实现路由功能。这个MultiPromptChain类是一个多路选择链，它使用一个LLM路由器链在多个提示之间进行选择。<strong>MultiPromptChain中有三个关键元素。</strong></p>
<ul>
<li>router_chain（类型RouterChain）：这是用于决定目标链和其输入的链。当给定某个输入时，这个router_chain决定哪一个destination_chain应该被选中，以及传给它的具体输入是什么。</li>
<li>destination_chains（类型Mapping[str, LLMChain]）：这是一个映射，将名称映射到可以将输入路由到的候选链。例如，你可能有多种处理文本输入的方法（或“链”），每种方法针对特定类型的问题。destination_chains可以是这样一个字典： <code>&#123;&#39;weather&#39;: weather_chain, &#39;news&#39;: news_chain&#125;</code>。在这里，weather_chain可能专门处理与天气相关的问题，而news_chain处理与新闻相关的问题。</li>
<li>default_chain（类型LLMChain）：当 router_chain 无法将输入映射到destination_chains中的任何一个链时，LLMChain 将使用此默认链。这是一个备选方案，确保即使路由器不能决定正确的链，也总有一个链可以处理输入。</li>
</ul>
<p><strong>它的工作流程如下：</strong></p>
<ol>
<li>输入首先传递给router_chain。</li>
<li>router_chain根据某些标准或逻辑决定应该使用哪一个destination_chain。</li>
<li>输入随后被路由到选定的destination_chain，该链进行处理并返回结果。</li>
<li>如果router_chain不能决定正确的destination_chain，则输入会被传递给default_chain。</li>
</ol>
<p>这样，MultiPromptChain就提供了一个在多个处理链之间动态路由输入的机制，以得到最相关或最优的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建多提示链</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.router <span class="keyword">import</span> MultiPromptChain</span><br><span class="line">chain = MultiPromptChain(</span><br><span class="line">    router_chain=router_chain,</span><br><span class="line">    destination_chains=chain_map,</span><br><span class="line">    default_chain=default_chain,</span><br><span class="line">    verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="2-2-2-5-运行路由链"><a href="#2-2-2-5-运行路由链" class="headerlink" title="2.2.2.5 运行路由链"></a>2.2.2.5 运行路由链</h4><p>通过下边的方式运行路由链：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(chain.run(“如何为玫瑰浇水？”))</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240311155929.png"></p>
<p><strong>完整代码：</strong> <a target="_blank" rel="noopener" href="https://github.com/huangjia2019/langchain/blob/main/09_%E9%93%BE%E4%B8%8B/Rounter_Chain.py">https://github.com/huangjia2019/langchain/blob/main/09_%E9%93%BE%E4%B8%8B&#x2F;Rounter_Chain.py</a></p>
<h2 id="2-3-记忆（Memory）"><a href="#2-3-记忆（Memory）" class="headerlink" title="2.3 记忆（Memory）"></a>2.3 记忆（Memory）</h2><p>在默认情况下，无论是LLM还是代理都是无状态的，每次模型的调用都是独立于其他交互的。但是在聊天中，为了对话的连贯性，是需要让大模型记住之前的内容，具体的实现方式有如下几种。</p>
<ol>
<li>ConversationBufferMemory的 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/memory/buffer.py">实现细节</a></li>
<li>ConversationSummaryMemory的 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/memory/summary.py">实现细节</a></li>
</ol>
<h3 id="2-3-1-ConversationChain"><a href="#2-3-1-ConversationChain" class="headerlink" title="2.3.1 ConversationChain"></a>2.3.1 ConversationChain</h3><p>这个Chain最主要的特点是，它提供了包含AI 前缀和人类前缀的对话摘要格式，这个对话格式和记忆机制结合得非常紧密。使用示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥  </span></span><br><span class="line"><span class="comment"># import os  </span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;Your Key&#x27;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大语言模型  </span></span><br><span class="line">llm = OpenAI(  </span><br><span class="line">    temperature=<span class="number">0.5</span>,  </span><br><span class="line">    model_name=<span class="string">&quot;text-davinci-003&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化对话链  </span></span><br><span class="line">conv_chain = ConversationChain(llm=llm)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 打印对话的模板  </span></span><br><span class="line"><span class="built_in">print</span>(conv_chain.prompt.template)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The following <span class="keyword">is</span> a friendly conversation between a human <span class="keyword">and</span> an AI. The AI <span class="keyword">is</span> talkative <span class="keyword">and</span> provides lots of specific details <span class="keyword">from</span> its context. If the AI does <span class="keyword">not</span> know the answer to a question, it truthfully says it does <span class="keyword">not</span> know.</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line">&#123;history&#125;</span><br><span class="line">Human: &#123;<span class="built_in">input</span>&#125;</span><br><span class="line">AI:</span><br></pre></td></tr></table></figure>
<p>这里的提示为人类（我们）和人工智能（ text-davinci-003 ）之间的对话设置了一个基本对话框架：这是 <strong>人类和</strong> <strong>AI</strong> <strong>之间的友好对话。AI</strong> <strong>非常健谈并从其上下文中提供了大量的具体细节。</strong> (The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. )<br>同时，这个提示试图通过说明以下内容来减少幻觉，也就是尽量减少模型编造的信息：<br><strong>“如果</strong> <strong>AI</strong> <strong>不知道问题的答案，它就会如实说它不知道。”</strong>（If the AI does not know the answer to a question, it truthfully says it does not know.）之后，我们看到两个参数 {history} 和 {input}。</p>
<ul>
<li><strong>{history}</strong> 是存储会话记忆的地方，也就是人类和人工智能之间对话历史的信息。</li>
<li><strong>{input}</strong> 是新输入的地方，你可以把它看成是和ChatGPT对话时，文本框中的输入。</li>
</ul>
<blockquote>
<p>当有了 {history} 参数，以及 Human 和 AI 这两个前缀，我们就能够把历史对话信息存储在提示模板中，并作为新的提示内容在新一轮的对话过程中传递给模型。—— 这就是记忆机制的原理。</p>
</blockquote>
<h3 id="2-3-2-ConversationBufferMemory"><a href="#2-3-2-ConversationBufferMemory" class="headerlink" title="2.3.2 ConversationBufferMemory"></a>2.3.2 ConversationBufferMemory</h3><p>在LangChain中，通过ConversationBufferMemory（ <strong>缓冲记忆</strong>）可以实现最简单的记忆机制。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥  </span></span><br><span class="line"><span class="comment"># import os  </span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;Your Key&#x27;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain  </span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationBufferMemory  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大语言模型  </span></span><br><span class="line">llm = OpenAI(  </span><br><span class="line">    temperature=<span class="number">0.5</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化对话链  </span></span><br><span class="line">conversation = ConversationChain(  </span><br><span class="line">    llm=llm,  </span><br><span class="line">    memory=ConversationBufferMemory()  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第一天的对话  </span></span><br><span class="line"><span class="comment"># 回合1  </span></span><br><span class="line">conversation(<span class="string">&quot;我姐姐明天要过生日，我需要一束生日花束。&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一次对话后的记忆:&quot;</span>, conversation.memory.buffer)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 回合2  </span></span><br><span class="line">conversation(<span class="string">&quot;她喜欢粉色玫瑰，颜色是粉色的。&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第二次对话后的记忆:&quot;</span>, conversation.memory.buffer)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 回合3 （第二天的对话）  </span></span><br><span class="line">conversation(<span class="string">&quot;我又来了，还记得我昨天为什么要来买花吗？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;/n第三次对话后时提示:/n&quot;</span>,conversation.prompt.template)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;/n第三次对话后的记忆:/n&quot;</span>, conversation.memory.buffer)</span><br></pre></td></tr></table></figure>
<p>在第三回合中模型的输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Human: 我姐姐明天要过生日，我需要一束生日花束。</span><br><span class="line">AI:  哦，你姐姐明天要过生日，那太棒了！我可以帮你推荐一些生日花束，你想要什么样的？我知道有很多种，比如玫瑰、康乃馨、郁金香等等。</span><br><span class="line">Human: 她喜欢粉色玫瑰，颜色是粉色的。</span><br><span class="line">AI:  好的，那我可以推荐一束粉色玫瑰的生日花束给你，你想要多少朵？</span><br><span class="line">Human: 我又来了，还记得我昨天为什么要来买花吗？</span><br><span class="line">AI:  是的，我记得你昨天来买花是因为你姐姐明天要过生日，你想要买一束粉色玫瑰的生日花束给她。</span><br></pre></td></tr></table></figure>
<p>实际上，这些聊天历史信息，都被传入了ConversationChain的提示模板中的 {history} 参数，构建出了包含聊天记录的新的提示输入。这样简单的存储之前的对话内容，新输入中也包含了更多的Token（所有的聊天历史记录），这意味着响应时间变慢和更高的成本。而且，当达到LLM的令牌数（上下文窗口）限制时，太长的对话无法被记住（对于text-davinci-003和gpt-3.5-turbo，每次的最大输入限制是4096个Token）。</p>
<h3 id="2-3-3-ConversationBufferWindowMemory"><a href="#2-3-3-ConversationBufferWindowMemory" class="headerlink" title="2.3.3 ConversationBufferWindowMemory"></a>2.3.3 ConversationBufferWindowMemory</h3><p>ConversationBufferWindowMemory 是 <strong>缓冲窗口记忆</strong>，它的思路就是只保存最新最近的几次人类和AI的互动。因此，它在之前的“缓冲记忆”基础上增加了一个窗口值 k。这意味着我们只保留一定数量的过去互动，然后“忘记”之前的互动。使用示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥  </span></span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;Your Key&#x27;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain  </span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationBufferWindowMemory  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大语言模型  </span></span><br><span class="line">llm = OpenAI(  </span><br><span class="line">    temperature=<span class="number">0.5</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化对话链  </span></span><br><span class="line">conversation = ConversationChain(  </span><br><span class="line">    llm=llm,  </span><br><span class="line">    memory=ConversationBufferWindowMemory(k=<span class="number">1</span>)  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第一天的对话  </span></span><br><span class="line"><span class="comment"># 回合1  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我姐姐明天要过生日，我需要一束生日花束。&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line"><span class="comment"># 回合2  </span></span><br><span class="line">result = conversation(<span class="string">&quot;她喜欢粉色玫瑰，颜色是粉色的。&quot;</span>)  </span><br><span class="line"><span class="comment"># print(&quot;\n第二次对话后的记忆:\n&quot;, conversation.memory.buffer)  </span></span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第二天的对话  </span></span><br><span class="line"><span class="comment"># 回合3  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我又来了，还记得我昨天为什么要来买花吗？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>第二回合输出：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;她喜欢粉色玫瑰，颜色是粉色的。&#x27;<span class="punctuation">,</span> &#x27;history&#x27;<span class="punctuation">:</span> &#x27;Human<span class="punctuation">:</span> 我姐姐明天要过生日，我需要一束生日花束。\nAI<span class="punctuation">:</span>  好的，让我来帮助你选择一束生日花束吧！根据我所知，生日花束通常会选择一些鲜艳的颜色，比如红色、粉色或橙色的花朵。也可以根据你姐姐的喜好来选择，比如她喜欢什么样的花或颜色。另外，你可以选择一束混合花束，里面包含多种不同的花朵，这样会更加丰富多彩。你还有其他要求吗？&#x27;<span class="punctuation">,</span> &#x27;response&#x27;<span class="punctuation">:</span> &#x27; 好的，我会为你选择一束粉色玫瑰的花束。你姐姐一定会喜欢的！另外，你还可以选择一些附加的小礼物，比如巧克力或贺卡，来让这份礼物更加特别。我可以帮你一起挑选，如果你需要的话。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>第三回合的输出：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;我又来了，还记得我昨天为什么要来买花吗？&#x27;<span class="punctuation">,</span> &#x27;history&#x27;<span class="punctuation">:</span> &#x27;Human<span class="punctuation">:</span> 她喜欢粉色玫瑰，颜色是粉色的。\nAI<span class="punctuation">:</span>  好的，我会为你选择一束粉色玫瑰的花束。你姐姐一定会喜欢的！另外，你还可以选择一些附加的小礼物，比如巧克力或贺卡，来让这份礼物更加特别。我可以帮你一起挑选，如果你需要的话。&#x27;<span class="punctuation">,</span> &#x27;response&#x27;<span class="punctuation">:</span> &#x27; 是的，你昨天来买花是为了给你的母亲庆祝她的生日。你选择了一束红色康乃馨和一张生日贺卡。我希望你的母亲喜欢这份礼物。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>在第三个回合，当我们询问“还记得我昨天为什么要来买花吗？”，由于我们只保留了最近的互动（k&#x3D;1），模型已经忘记了正确的答案，回答也是错误的了。</p>
<h3 id="2-3-4-ConversationSummaryMemory"><a href="#2-3-4-ConversationSummaryMemory" class="headerlink" title="2.3.4  ConversationSummaryMemory"></a>2.3.4  ConversationSummaryMemory</h3><p>ConversationSummaryMemory（ <strong>对话总结记忆</strong>）的思路就是将对话历史进行汇总，然后再传递给 {history} 参数。这种方法旨在通过对之前的对话进行汇总来避免过度使用 Token。<br>ConversationSummaryMemory有这么几个核心特点。</p>
<ol>
<li>汇总对话：此方法不是保存整个对话历史，而是每次新的互动发生时对其进行汇总，然后将其添加到之前所有互动的“运行汇总”中。</li>
<li>使用LLM进行汇总：该汇总功能由另一个LLM驱动，这意味着对话的汇总实际上是由AI自己进行的。</li>
<li>适合长对话：对于长对话，此方法的优势尤为明显。虽然最初使用的 Token 数量较多，但随着对话的进展，汇总方法的增长速度会减慢。与此同时，常规的缓冲内存模型会继续线性增长。</li>
</ol>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥  </span></span><br><span class="line"><span class="comment"># import os  </span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;Your Key&#x27;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain  </span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationSummaryMemory  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大语言模型  </span></span><br><span class="line">llm = OpenAI(  </span><br><span class="line">    temperature=<span class="number">0.5</span>,  </span><br><span class="line">    <span class="comment"># model_name=&quot;text-davinci-003&quot;  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化对话链  </span></span><br><span class="line">conversation = ConversationChain(  </span><br><span class="line">    llm=llm,  </span><br><span class="line">    memory=ConversationSummaryMemory(llm=llm)  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第一天的对话  </span></span><br><span class="line"><span class="comment"># 回合1  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我姐姐明天要过生日，我需要一束生日花束。&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line"><span class="comment"># 回合2  </span></span><br><span class="line">result = conversation(<span class="string">&quot;她喜欢粉色玫瑰，颜色是粉色的。&quot;</span>)  </span><br><span class="line"><span class="comment"># print(&quot;\n第二次对话后的记忆:\n&quot;, conversation.memory.buffer)  </span></span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第二天的对话  </span></span><br><span class="line"><span class="comment"># 回合3  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我又来了，还记得我昨天为什么要来买花吗？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>第二回合的输出：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;她喜欢粉色玫瑰，颜色是粉色的。&#x27;<span class="punctuation">,</span> &#x27;history&#x27;<span class="punctuation">:</span> &#x27;\nThe human asks the AI for help in choosing a birthday bouquet for their sister. The AI suggests a bouquet of pink roses and white daisies<span class="punctuation">,</span> symbolizing gentleness and purity<span class="punctuation">,</span> and recommends adding some green leaves for decoration. The AI also asks for the desired number of flowers to help select the appropriate size.&#x27;<span class="punctuation">,</span> &#x27;response&#x27;<span class="punctuation">:</span> &#x27; 那么我建议您选择一束粉红色的玫瑰和白色的雏菊，这象征着温柔和纯洁。您也可以在花束中加入一些绿叶作为装饰。请问您想要多少朵花呢？这样我可以帮您选择合适的大小。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>第三回合的输出：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;我又来了，还记得我昨天为什么要来买花吗？&#x27;<span class="punctuation">,</span> &#x27;history&#x27;<span class="punctuation">:</span> &#x27;\nThe human asks the AI for help in choosing a birthday bouquet for their sister. The AI suggests a bouquet of pink roses and white daisies<span class="punctuation">,</span> symbolizing gentleness and purity<span class="punctuation">,</span> and recommends adding green leaves for decoration. The AI also asks for the desired number of flowers to help select the appropriate size. The human clarifies that their sister prefers pink roses and the AI suggests adding them to the bouquet. The AI also asks for the desired number of flowers to ensure the right size.&#x27;<span class="punctuation">,</span> &#x27;response&#x27;<span class="punctuation">:</span> &#x27; 当然记得！昨天您说您的妹妹生日快到了，想要给她一个特别的生日花束。您想要为她挑选什么样的花束呢？我可以帮您选择最合适的花束。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>看得出来，这里的 <code>&#39;history&#39;</code>，不再是之前人类和AI对话的简单复制粘贴，而是经过了总结和整理之后的一个综述信息。<br>ConversationSummaryMemory的优点是对于长对话，可以减少使用的 Token 数量，因此可以记录更多轮的对话信息，使用起来也直观易懂。不过，它的缺点是，对于较短的对话，可能会导致更高的 Token 使用。另外，对话历史的记忆完全依赖于中间汇总LLM的能力，还需要为汇总LLM使用 Token，这增加了成本，且并不限制对话长度。</p>
<h3 id="2-3-5-ConversationSummaryBufferMemory"><a href="#2-3-5-ConversationSummaryBufferMemory" class="headerlink" title="2.3.5 ConversationSummaryBufferMemory"></a>2.3.5 ConversationSummaryBufferMemory</h3><p>ConversationSummaryBufferMemory，即 <strong>对话总结缓冲记忆</strong>，它是一种 <strong>混合记忆</strong> 模型，结合了上述各种记忆机制，包括ConversationSummaryMemory 和 ConversationBufferWindowMemory的特点。这种模型旨在在对话中总结早期的互动，同时尽量保留最近互动中的原始内容。<br>是通过max_token_limit这个参数做到这一点的。当最新的对话文字长度在300字之内的时候，LangChain会记忆原始对话内容；当对话文字超出了这个参数的长度，那么模型就会把所有超过预设长度的内容进行总结，以节省Token数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI API密钥  </span></span><br><span class="line"><span class="comment"># import os  </span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;Your Key&#x27;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 导入所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain  </span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationSummaryBufferMemory  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大语言模型  </span></span><br><span class="line">llm = OpenAI(  </span><br><span class="line">    temperature=<span class="number">0.5</span>,  </span><br><span class="line">    <span class="comment"># model_name=&quot;gpt-4&quot;  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化对话链  </span></span><br><span class="line">conversation = ConversationChain(  </span><br><span class="line">    llm=llm,  </span><br><span class="line">    memory=ConversationSummaryBufferMemory(  </span><br><span class="line">        llm=llm,  </span><br><span class="line">        max_token_limit=<span class="number">300</span>  </span><br><span class="line">    )  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第一天的对话  </span></span><br><span class="line"><span class="comment"># 回合1  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我姐姐明天要过生日，我需要一束生日花束。&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line"><span class="comment"># 回合2  </span></span><br><span class="line">result = conversation(<span class="string">&quot;她喜欢粉色玫瑰，颜色是粉色的。&quot;</span>)  </span><br><span class="line"><span class="comment"># print(&quot;\n第二次对话后的记忆:\n&quot;, conversation.memory.buffer)  </span></span><br><span class="line"><span class="built_in">print</span>(result)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第二天的对话  </span></span><br><span class="line"><span class="comment"># 回合3  </span></span><br><span class="line">result = conversation(<span class="string">&quot;我又来了，还记得我昨天为什么要来买花吗？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>第三回合输出：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;我又来了，还记得我昨天为什么要来买花吗？&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;history&#x27;<span class="punctuation">:</span> <span class="string">&quot;System: \nThe human asked the AI for advice on buying a bouquet for their sister&#x27;s birthday. The AI suggested buying a vibrant bouquet as a representation of their wishes and blessings, and recommended looking for special bouquets like colorful roses or lilies for something more unique.\nHuman: 她喜欢粉色玫瑰，颜色是粉色的。\nAI:  好的，那粉色玫瑰就是一个很好的选择！你可以买一束粉色玫瑰花束，这样你姐姐会很开心的！你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品&quot;</span><span class="punctuation">,</span></span><br><span class="line">&#x27;response&#x27;<span class="punctuation">:</span> &#x27; 是的，我记得你昨天来买花是为了给你姐姐的生日。你想买一束粉色玫瑰花束来表达你的祝福和祝愿，你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>在第三回合，它察觉出前两轮的对话已经超出了300个字节，就把早期的对话加以总结，以节省Token资源。</p>
<h3 id="2-3-6-四种记忆机制的比较"><a href="#2-3-6-四种记忆机制的比较" class="headerlink" title="2.3.6 四种记忆机制的比较"></a>2.3.6 四种记忆机制的比较</h3><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240311150350.png"></p>
<p>在经过 K 轮对话后，对Token的消耗对比：ConversationSummaryBufferMemory和ConversationSummaryMemory，在对话轮次较少的时候可能会浪费一些Token，但是多轮对话过后，Token的节省就逐渐体现出来了。ConversationBufferWindowMemory对于Token的节省最为直接，但是它会完全遗忘掉K轮之前的对话内容，因此对于某些场景也不是最佳选择。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240311150409.png"></p>
<h2 id="2-4-代理（Agents）"><a href="#2-4-代理（Agents）" class="headerlink" title="2.4 代理（Agents）"></a>2.4 代理（Agents）</h2><h3 id="2-4-1-代理的作用"><a href="#2-4-1-代理的作用" class="headerlink" title="2.4.1 代理的作用"></a>2.4.1 代理的作用</h3><p>如果需要模型做自主判断、自行调用工具、自行决定下一步行动的时候，可以使用Agent（也就是代理）。代理就像一个多功能的接口，它能够接触并使用一套工具。根据用户的输入，代理会决定调用哪些工具。它不仅可以同时使用多种工具，而且可以将一个工具的输出数据作为另一个工具的输入数据。<br>在LangChain中使用代理，需要理解下面三个元素。</p>
<ul>
<li><strong>大模型</strong>：提供逻辑的引擎，负责生成预测和处理输入。</li>
<li>与之交互的 <strong>外部工具</strong>：可能包括数据清洗工具、搜索引擎、应用程序等。</li>
<li>控制交互的 <strong>代理</strong>：调用适当的外部工具，并管理整个交互过程的流程。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240312090544.png"></p>
<p>这个过程有很多地方需要大模型自主判断下一步行为（也就是操作）要做什么，如果不加引导，那大模型本身是不具备这个能力的。比如下面这一系列的操作：</p>
<ul>
<li>什么时候开始在本地知识库中搜索（这个比较简单，毕竟是第一个步骤，可以预设）？</li>
<li>怎么确定本地知识库的检索已经完成，可以开始下一步？</li>
<li>调用哪一种外部搜索工具（比如Google引擎）？</li>
<li>如何确定外部搜索工具返回了想要找的内容？</li>
<li>如何确定信息真实性的检索已经全部完成，可以开始下一步？</li>
</ul>
<h3 id="2-4-2-ReAct-框架"><a href="#2-4-2-ReAct-框架" class="headerlink" title="2.4.2 ReAct 框架"></a>2.4.2 ReAct 框架</h3><p>ReAct 框架的灵感来自“行动”和“推理”之间的协同作用，这种协同作用使得咱们人类能够学习新任务并做出决策或推理。如每天早上想知道如何为鲜花定价？我会去Google上面查一查今天的鲜花成本价啊（ <strong>行动</strong>），也就是我预计的进货的价格，然后我会根据这个价格的高低（ <strong>观察</strong>），来确定我要加价多少（ <strong>思考</strong>），最后计算出一个售价（ <strong>行动</strong>）！<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240312091016.png"></p>
<p>这个例子中有观察、有思考，然后才会具体行动。这里的观察和思考，我们统称为推理（Reasoning）过程，推理指导着你的行动（Acting）。<br>ReAct 指如何指导大语言模型推理和行动的一种思维框架。这个思维框架是Shunyu Yao等人在ICLR 2023会议论文《 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.03629.pdf">ReAct: Synergizing Reasoning and Acting in Language Models</a>》（ReAct：在语言模型中协同推理和行动）中提出的。</p>
<h3 id="2-4-3-通过代理实现ReAct框架"><a href="#2-4-3-通过代理实现ReAct框架" class="headerlink" title="2.4.3 通过代理实现ReAct框架"></a>2.4.3 通过代理实现ReAct框架</h3><p>下边使用LangChain中最为常用的 <strong>ZERO_SHOT_REACT_DESCRIPTION</strong> ——这种常用代理类型，看下LLM是如何在ReAct框架的指导下进行推理的。<br>要给代理一个任务，这个任务是找到玫瑰的当前市场价格，然后计算出加价15%后的新价格。</p>
<p>在开始之前，有一个准备工作，需要在 <a target="_blank" rel="noopener" href="https://serpapi.com/">serpapi.com</a> 注册一个账号，并且拿到你的 SERPAPI_API_KEY，这个就是我们要为大模型提供的 Google 搜索工具。安装 SerpAPI 的包：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install google-search-results</span><br></pre></td></tr></table></figure>

<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置OpenAI和SERPAPI的API密钥  </span></span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;Your OpenAI API Key&#x27;</span>  </span><br><span class="line">os.environ[<span class="string">&quot;SERPAPI_API_KEY&quot;</span>] = <span class="string">&#x27;Your SerpAPI API Key&#x27;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 加载所需的库  </span></span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> load_tools  </span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> initialize_agent  </span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentType  </span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化大模型  </span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置工具  </span></span><br><span class="line">tools = load_tools([<span class="string">&quot;serpapi&quot;</span>, <span class="string">&quot;llm-math&quot;</span>], llm=llm)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化Agent  </span></span><br><span class="line">agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 跑起来  </span></span><br><span class="line">agent.run(<span class="string">&quot;目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>输出：</strong><br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240312092314.png"></p>
<p>ZERO_SHOT_REACT_DESCRIPTION类型的智能代理在LangChain中，自动形成了一个完善的思考与行动链条，而且给出了正确的答案。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240312092332.png"></p>
<p>通过ReAct框架，大模型将被引导生成一个任务解决轨迹，即观察环境-进行思考-采取行动。观察和思考阶段被统称为推理（Reasoning），而实施下一步行动的阶段被称为行动（Acting）。在每一步推理过程中，都会详细记录下来，这也改善了大模型解决问题时的可解释性和可信度。</p>
<ul>
<li>在推理阶段，模型对当前环境和状态进行观察，并生成推理轨迹，从而使模型能够诱导、跟踪和更新操作计划，甚至处理异常情况。</li>
<li>在行动阶段，模型会采取下一步的行动，如与外部源（如知识库或环境）进行交互并收集信息，或给出最终答案。</li>
</ul>
<h3 id="2-4-4-AgentExecutor-驱动模型和工具完成任务"><a href="#2-4-4-AgentExecutor-驱动模型和工具完成任务" class="headerlink" title="2.4.4 AgentExecutor 驱动模型和工具完成任务"></a>2.4.4 AgentExecutor 驱动模型和工具完成任务</h3><p>在链中，一系列操作被硬编码（在代码中）。在代理中，语言模型被用作推理引擎来确定要采取哪些操作以及按什么顺序执行这些操作。<br>下面这个图，就展现出了Agent接到任务之后，自动进行推理，然后自主调用工具完成任务的过程。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240312092610.png"></p>
<p>AgentExecutor中最重要的方法是步骤处理方法，<code>_take_next_step</code>方法。它用于在思考-行动-观察的循环中采取单步行动。先调用代理的计划，查找代理选择的工具，然后使用选定的工具执行该计划（此时把输入传给工具），从而获得观察结果，然后继续思考，直到输出是 AgentFinish 类型，循环才会结束。</p>
<h3 id="2-4-5-Agent-的关键组件"><a href="#2-4-5-Agent-的关键组件" class="headerlink" title="2.4.5 Agent 的关键组件"></a>2.4.5 Agent 的关键组件</h3><p>在LangChain的代理中，有这样几个关键组件。</p>
<ol>
<li><strong>代理</strong>（Agent）：这个类决定下一步执行什么操作。它由一个语言模型和一个提示（prompt）驱动。提示可能包含代理的性格（也就是给它分配角色，让它以特定方式进行响应）、任务的背景（用于给它提供更多任务类型的上下文）以及用于激发更好推理能力的提示策略（例如ReAct）。LangChain中包含很多种不同类型的代理。</li>
<li><strong>工具</strong>（Tools）：工具是代理调用的函数。这里有两个重要的考虑因素：一是让代理能访问到正确的工具，二是以最有帮助的方式描述这些工具。如果你没有给代理提供正确的工具，它将无法完成任务。如果你没有正确地描述工具，代理将不知道如何使用它们。LangChain提供了一系列的工具，同时你也可以定义自己的工具。</li>
<li><strong>工具包</strong>（Toolkits）：工具包是一组用于完成特定目标的彼此相关的工具，每个工具包中包含多个工具。比如LangChain的Office365工具包中就包含连接Outlook、读取邮件列表、发送邮件等一系列工具。当然LangChain中还有很多其他工具包供你使用。</li>
<li><strong>代理执行器</strong>（AgentExecutor）：代理执行器是代理的运行环境，它调用代理并执行代理选择的操作。执行器也负责处理多种复杂情况，包括处理代理选择了不存在的工具的情况、处理工具出错的情况、处理代理产生的无法解析成工具调用的输出的情况，以及在代理决策和工具调用进行观察和日志记录。</li>
</ol>
<p>总的来说，代理就是一种用语言模型做出决策、调用工具来执行具体操作的系统。通过设定代理的性格、背景以及工具的描述，你可以定制代理的行为，使其能够根据输入的文本做出理解和推理，从而实现自动化的任务处理。而代理执行器（AgentExecutor）就是上述机制得以实现的引擎。</p>
<h3 id="2-4-6-其他-Agent-类型"><a href="#2-4-6-其他-Agent-类型" class="headerlink" title="2.4.6 其他 Agent 类型"></a>2.4.6 其他 Agent 类型</h3><h4 id="2-4-6-1-结构化工具"><a href="#2-4-6-1-结构化工具" class="headerlink" title="2.4.6.1 结构化工具"></a>2.4.6.1 结构化工具</h4><p>通过指定AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION 这个代理类型，代理能够调用包含一系列复杂工具的“ <strong>结构化工具箱</strong>”，组合调用其中的多个工具，完成批次相关的任务集合。<br>结构化工具的示例包括：</p>
<ol>
<li>文件管理工具集：支持所有文件系统操作，如写入、搜索、移动、复制、列目录和查找。</li>
<li>Web 浏览器工具集：官方的 PlayWright 浏览器工具包，允许代理访问网站、点击、提交表单和查询数据。</li>
</ol>
<p>下边以 PlayWright 工具包为例，来实现一个结构化工具对话代理。<br>Playwright是一个开源的自动化框架，它可以让你模拟真实用户操作网页，帮助开发者和测试者自动化网页交互和测试。用简单的话说，它就像一个“机器人”，可以按照你给的指令去浏览网页、点击按钮、填写表单、读取页面内容等等，就像一个真实的用户在使用浏览器一样。<br>Playwright支持多种浏览器，比如Chrome、Firefox、Safari等，这意味着可以用它来测试你的网站或测试应用在不同的浏览器上的表现是否一致。<br>先用 <code>pip install playwright</code> 安装Playwright工具。然后还需要通过 <code>playwright install</code> 命令来安装三种常用的浏览器工具。<br>通过Playwright浏览器工具来访问一个测试网页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> playwright.sync_api <span class="keyword">import</span> sync_playwright</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    <span class="comment"># 使用Playwright上下文管理器</span></span><br><span class="line">    <span class="keyword">with</span> sync_playwright() <span class="keyword">as</span> p:</span><br><span class="line">        <span class="comment"># 使用Chromium，但你也可以选择firefox或webkit</span></span><br><span class="line">        browser = p.chromium.launch()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建一个新的页面</span></span><br><span class="line">        page = browser.new_page()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 导航到指定的URL</span></span><br><span class="line">        page.goto(<span class="string">&#x27;https://langchain.com/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取并打印页面标题</span></span><br><span class="line">        title = page.title()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Page title is: <span class="subst">&#123;title&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 关闭浏览器</span></span><br><span class="line">        browser.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Page title is: LangChain</span><br></pre></td></tr></table></figure>

<p><strong>使用结构化工具对话代理：</strong><br>使用的Agent类型是STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION。要使用的工具则是PlayWrightBrowserToolkit，这是LangChain中基于PlayWrightBrowser包封装的工具箱，它继承自 BaseToolkit类。<br>PlayWrightBrowserToolkit 为 PlayWright 浏览器提供了一系列交互的工具，可以在同步或异步模式下操作。<br>其中具体的工具就包括：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20240313102748.png"></p>
<h4 id="2-4-6-2-Self-Ask-with-Search-代理"><a href="#2-4-6-2-Self-Ask-with-Search-代理" class="headerlink" title="2.4.6.2 Self-Ask with Search 代理"></a>2.4.6.2 Self-Ask with Search 代理</h4><p>Self-Ask with Search 也是LangChain中的一个有用的代理类型（SELF_ASK_WITH_SEARCH）。它利用一种叫做 “Follow-up Question（追问）”加“Intermediate Answer（中间答案）”的技巧，来辅助大模型寻找事实性问题的过渡性答案，从而引出最终答案。<br>如下使用SerpAPIWrapper作为工具，用OpenAI作为语言模型，创建Self-Ask with Search代理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="2-4-6-3-Plan-and-execute-代理"><a href="#2-4-6-3-Plan-and-execute-代理" class="headerlink" title="2.4.6.3 Plan and execute 代理"></a>2.4.6.3 Plan and execute 代理</h4></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://baihlup.github.io">梦之痕</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://baihlup.github.io/2024/02/07/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/03%20-%20Langchain%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/">https://baihlup.github.io/2024/02/07/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/03%20-%20Langchain%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LangChain/">LangChain</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/28/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/271%20-%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/01%20-%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%EF%BC%9A%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BD%91%E5%85%B3%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="负载均衡：高并发网关设计原理与实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">负载均衡：高并发网关设计原理与实践</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/05/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/279%20-%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/01%20-%20REUSEADDR%20%E5%92%8CREUSEPORT%20%E5%AF%B9TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E6%8E%A7%E5%88%B6/" title="REUSEADDR 和REUSEPORT 对TCP连接的控制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">REUSEADDR 和REUSEPORT 对TCP连接的控制</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">梦之痕</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/BaihlUp"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">个人笔记迁移中ing....</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">1.</span> <span class="toc-text">0 参考资料</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-1-%E7%BD%91%E7%AB%99"><span class="toc-number">1.1.</span> <span class="toc-text">0.1 网站</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-2-%E8%AF%BE%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">0.2 课程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-3-%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.3.</span> <span class="toc-text">0.3 开源项目</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-LangChain-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">1 LangChain 安装和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-LangChain-%E5%AE%89%E8%A3%85"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 LangChain 安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-OpenAI-API"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 OpenAI API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-%E8%B0%83%E7%94%A8-Text-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">1.2.1 调用 Text 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-%E8%B0%83%E7%94%A8-Chat-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.2.</span> <span class="toc-text">1.2.2 调用 Chat 模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E9%80%9A%E8%BF%87-LangChain-%E8%B0%83%E7%94%A8-Text-%E6%A8%A1%E5%9E%8B%E5%92%8C-Chat%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 通过 LangChain 调用 Text 模型和 Chat模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-1-%E8%B0%83%E7%94%A8-Text-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.1.</span> <span class="toc-text">1.3.1 调用 Text 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-2-%E8%B0%83%E7%94%A8-Chat-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.2.</span> <span class="toc-text">1.3.2 调用 Chat 模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-4-LangChain-%E6%9E%84%E5%BB%BA%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F"><span class="toc-number">3.</span> <span class="toc-text">1.4 LangChain 构建问答系统</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-LangChain-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number">4.</span> <span class="toc-text">2 LangChain 核心组件</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E6%A8%A1%E5%9E%8B-I-O"><span class="toc-number">4.1.</span> <span class="toc-text">2.1 模型 I&#x2F;O</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-Model-I-O"><span class="toc-number">4.1.1.</span> <span class="toc-text">2.1.1 Model I&#x2F;O</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF"><span class="toc-number">4.1.2.</span> <span class="toc-text">2.1.2 提示模板</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-1-PromptTemplate"><span class="toc-number">4.1.2.1.</span> <span class="toc-text">2.1.2.1 PromptTemplate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-2-ChatPromptTemplate"><span class="toc-number">4.1.2.2.</span> <span class="toc-text">2.1.2.2 ChatPromptTemplate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-3-FewShotPromptTemplate"><span class="toc-number">4.1.2.3.</span> <span class="toc-text">2.1.2.3 FewShotPromptTemplate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-4-%E7%A4%BA%E4%BE%8B%E9%80%89%E6%8B%A9%E5%99%A8SemanticSimilarityExampleSelector"><span class="toc-number">4.1.2.4.</span> <span class="toc-text">2.1.2.4 示例选择器SemanticSimilarityExampleSelector</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-5-%E6%80%9D%E7%BB%B4%E9%93%BE-%E5%92%8C-%E6%80%9D%E7%BB%B4%E6%A0%91"><span class="toc-number">4.1.2.5.</span> <span class="toc-text">2.1.2.5 思维链 和 思维树</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-3-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.3.</span> <span class="toc-text">2.1.3 语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-1-%E7%94%A8-HuggingFace-%E8%B7%91%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.3.1.</span> <span class="toc-text">2.1.3.1 用 HuggingFace 跑开源模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-2-LangChain-%E5%92%8C-HuggingFace-%E7%9A%84%E6%8E%A5%E5%8F%A3"><span class="toc-number">4.1.3.2.</span> <span class="toc-text">2.1.3.2 LangChain 和 HuggingFace 的接口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-3-%E7%94%A8-LangChain-%E8%B0%83%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.3.3.</span> <span class="toc-text">2.1.3.3 用 LangChain 调用自定义语言模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-4-%E8%BE%93%E5%87%BA%E8%A7%A3%E6%9E%90"><span class="toc-number">4.1.4.</span> <span class="toc-text">2.1.4 输出解析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E9%93%BE%EF%BC%88Chain%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">2.2 链（Chain）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-Sequential-Chain%EF%BC%9A%E9%A1%BA%E5%BA%8F%E9%93%BE"><span class="toc-number">4.2.1.</span> <span class="toc-text">2.2.1 Sequential Chain：顺序链</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-RouterChain%EF%BC%9A%E8%B7%AF%E7%94%B1%E9%93%BE"><span class="toc-number">4.2.2.</span> <span class="toc-text">2.2.2 RouterChain：路由链</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-1-%E6%9E%84%E5%BB%BA%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF%E7%9A%84%E6%A8%A1%E6%9D%BF"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">2.2.2.1 构建提示信息的模板</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-2-%E6%9E%84%E5%BB%BA%E8%B7%AF%E7%94%B1%E9%93%BE"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">2.2.2.2 构建路由链</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-3-%E6%9E%84%E5%BB%BA%E9%BB%98%E8%AE%A4%E9%93%BE"><span class="toc-number">4.2.2.3.</span> <span class="toc-text">2.2.2.3 构建默认链</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-4-%E6%9E%84%E5%BB%BA%E5%A4%9A%E6%8F%90%E7%A4%BA%E9%93%BE"><span class="toc-number">4.2.2.4.</span> <span class="toc-text">2.2.2.4 构建多提示链</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-5-%E8%BF%90%E8%A1%8C%E8%B7%AF%E7%94%B1%E9%93%BE"><span class="toc-number">4.2.2.5.</span> <span class="toc-text">2.2.2.5 运行路由链</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E8%AE%B0%E5%BF%86%EF%BC%88Memory%EF%BC%89"><span class="toc-number">4.3.</span> <span class="toc-text">2.3 记忆（Memory）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-ConversationChain"><span class="toc-number">4.3.1.</span> <span class="toc-text">2.3.1 ConversationChain</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-ConversationBufferMemory"><span class="toc-number">4.3.2.</span> <span class="toc-text">2.3.2 ConversationBufferMemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-3-ConversationBufferWindowMemory"><span class="toc-number">4.3.3.</span> <span class="toc-text">2.3.3 ConversationBufferWindowMemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-4-ConversationSummaryMemory"><span class="toc-number">4.3.4.</span> <span class="toc-text">2.3.4  ConversationSummaryMemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-5-ConversationSummaryBufferMemory"><span class="toc-number">4.3.5.</span> <span class="toc-text">2.3.5 ConversationSummaryBufferMemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-6-%E5%9B%9B%E7%A7%8D%E8%AE%B0%E5%BF%86%E6%9C%BA%E5%88%B6%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">4.3.6.</span> <span class="toc-text">2.3.6 四种记忆机制的比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-%E4%BB%A3%E7%90%86%EF%BC%88Agents%EF%BC%89"><span class="toc-number">4.4.</span> <span class="toc-text">2.4 代理（Agents）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1-%E4%BB%A3%E7%90%86%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">4.4.1.</span> <span class="toc-text">2.4.1 代理的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2-ReAct-%E6%A1%86%E6%9E%B6"><span class="toc-number">4.4.2.</span> <span class="toc-text">2.4.2 ReAct 框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-3-%E9%80%9A%E8%BF%87%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0ReAct%E6%A1%86%E6%9E%B6"><span class="toc-number">4.4.3.</span> <span class="toc-text">2.4.3 通过代理实现ReAct框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-4-AgentExecutor-%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%B7%A5%E5%85%B7%E5%AE%8C%E6%88%90%E4%BB%BB%E5%8A%A1"><span class="toc-number">4.4.4.</span> <span class="toc-text">2.4.4 AgentExecutor 驱动模型和工具完成任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-5-Agent-%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6"><span class="toc-number">4.4.5.</span> <span class="toc-text">2.4.5 Agent 的关键组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-6-%E5%85%B6%E4%BB%96-Agent-%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.4.6.</span> <span class="toc-text">2.4.6 其他 Agent 类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-6-1-%E7%BB%93%E6%9E%84%E5%8C%96%E5%B7%A5%E5%85%B7"><span class="toc-number">4.4.6.1.</span> <span class="toc-text">2.4.6.1 结构化工具</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-6-2-Self-Ask-with-Search-%E4%BB%A3%E7%90%86"><span class="toc-number">4.4.6.2.</span> <span class="toc-text">2.4.6.2 Self-Ask with Search 代理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-6-3-Plan-and-execute-%E4%BB%A3%E7%90%86"><span class="toc-number">4.4.6.3.</span> <span class="toc-text">2.4.6.3 Plan and execute 代理</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/05/260%20-%20%E5%90%8E%E7%AB%AF&amp;%E6%9E%B6%E6%9E%84/261%20-%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/02%20-%20%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98/" title="Untitled">Untitled</a><time datetime="2024-08-05T06:45:26.189Z" title="Created 2024-08-05 06:45:26">2024-08-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/05/000%20-%20Inbox/%E7%81%AB%E5%B1%B1%E4%BA%91waf/" title="Untitled">Untitled</a><time datetime="2024-08-05T06:45:26.093Z" title="Created 2024-08-05 06:45:26">2024-08-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/24/240%20-%20%E8%99%9A%E6%8B%9F%E5%8C%96&amp;%E4%BA%91%E8%AE%A1%E7%AE%97/244%20-%20%E4%BA%91%E5%8E%9F%E7%94%9F/01%20-%20Kuberbetes%20%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%EF%BC%88%E4%B8%80%EF%BC%89/" title="Kuberbetes 核心组件（一）">Kuberbetes 核心组件（一）</a><time datetime="2024-07-24T00:00:00.000Z" title="Created 2024-07-24 00:00:00">2024-07-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/07/210%20-%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/214%20-%20Java%20&amp;%20Lua/09%20-%20Java--File%E7%B1%BB%E4%B8%8EIO%E6%B5%81/" title="Java--File类与IO流">Java--File类与IO流</a><time datetime="2024-07-07T00:00:00.000Z" title="Created 2024-07-07 00:00:00">2024-07-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/05/210%20-%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/214%20-%20Java%20&amp;%20Lua/05%20-%20Java--%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%92%8C%E5%9F%BA%E7%A1%80API/" title="Java--常用类和基础API">Java--常用类和基础API</a><time datetime="2024-07-05T00:00:00.000Z" title="Created 2024-07-05 00:00:00">2024-07-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 梦之痕</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>