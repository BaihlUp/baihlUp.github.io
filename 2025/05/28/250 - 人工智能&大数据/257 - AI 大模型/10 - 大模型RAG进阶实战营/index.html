<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>10 - 大模型RAG进阶实战营 | 梦之痕</title><meta name="author" content="梦之痕"><meta name="copyright" content="梦之痕"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="0 参考资料代码仓库：https:&#x2F;&#x2F;github.com&#x2F;huangjia2019&#x2F;rag-in-action 13 评估RAG系统13.1 RAG系统评估RAG 的系统评估分为检索评估和响应评估：  对检索器的评估 包含一定的主观因素，但仍可以采用信息检索领域的一些指标来进行衡量，例如 准确率（Precision）、召回率（Recall）和  排名准确度等。 生成器的评估（也称为“响应评估”，">
<meta property="og:type" content="article">
<meta property="og:title" content="10 - 大模型RAG进阶实战营">
<meta property="og:url" content="https://baihlup.github.io/2025/05/28/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/10%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8BRAG%E8%BF%9B%E9%98%B6%E5%AE%9E%E6%88%98%E8%90%A5/index.html">
<meta property="og:site_name" content="梦之痕">
<meta property="og:description" content="0 参考资料代码仓库：https:&#x2F;&#x2F;github.com&#x2F;huangjia2019&#x2F;rag-in-action 13 评估RAG系统13.1 RAG系统评估RAG 的系统评估分为检索评估和响应评估：  对检索器的评估 包含一定的主观因素，但仍可以采用信息检索领域的一些指标来进行衡量，例如 准确率（Precision）、召回率（Recall）和  排名准确度等。 生成器的评估（也称为“响应评估”，">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg">
<meta property="article:published_time" content="2025-05-28T00:00:00.000Z">
<meta property="article:modified_time" content="2025-07-25T15:32:05.140Z">
<meta property="article:author" content="梦之痕">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://baihlup.github.io/2025/05/28/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/10%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8BRAG%E8%BF%9B%E9%98%B6%E5%AE%9E%E6%88%98%E8%90%A5/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '10 - 大模型RAG进阶实战营',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-07-25 15:32:05'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="梦之痕"><span class="site-name">梦之痕</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">10 - 大模型RAG进阶实战营</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-05-28T00:00:00.000Z" title="Created 2025-05-28 00:00:00">2025-05-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-07-25T15:32:05.140Z" title="Updated 2025-07-25 15:32:05">2025-07-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B/">AI大模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="10 - 大模型RAG进阶实战营"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="0-参考资料"><a href="#0-参考资料" class="headerlink" title="0 参考资料"></a>0 参考资料</h1><p><strong>代码仓库</strong>：<a target="_blank" rel="noopener" href="https://github.com/huangjia2019/rag-in-action">https://github.com/huangjia2019/rag-in-action</a></p>
<h1 id="13-评估RAG系统"><a href="#13-评估RAG系统" class="headerlink" title="13 评估RAG系统"></a>13 评估RAG系统</h1><h2 id="13-1-RAG系统评估"><a href="#13-1-RAG系统评估" class="headerlink" title="13.1 RAG系统评估"></a>13.1 RAG系统评估</h2><p><strong>RAG 的系统评估分为检索评估和响应评估：</strong></p>
<ul>
<li>对检索器的评估 包含一定的主观因素，但仍可以采用信息检索领域的一些指标来进行衡量，例如 准确率（Precision）、召回率（Recall）和  排名准确度等。</li>
<li>生成器的评估（也称为“响应评估”，实际上是针对RAG系统给出的最终结果进行的整体评估）则更加复杂。它不仅要求验证生成的答案是否基于事实（即与上下文相关），以及是否有效地回答了用户的问题（即与查询相关），还需要判断答案是否流畅、安全且符合人类价值观。为了评估生成内容的质量，会结合使用定量指标（如 BLEU 或 ROUGE）和定性指标（如 回答的相关性、语义一致性、语境契合度、扎实性及忠实度）。鉴于这些因素的复杂性，还需要依赖人类的主观评价来辅助完成整个评估过程。</li>
</ul>
<p><strong>RAG 的评估三角：</strong><br>上下文关联：针对 Query 进行检索，评估检索后结果的准确性<br>响应忠实度：LLM 基于 检索出的 Context 进行回答，回答的内容与 Context 的相关性<br>回答关联性：最终回答的内容 与 Query 的相关性。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528163807.png" alt="image.png"></p>
<h2 id="13-2-检索器的评估指标"><a href="#13-2-检索器的评估指标" class="headerlink" title="13.2 检索器的评估指标"></a>13.2 检索器的评估指标</h2><h3 id="13-2-1-精确率-Precision"><a href="#13-2-1-精确率-Precision" class="headerlink" title="13.2.1 精确率 Precision"></a>13.2.1 精确率 Precision</h3><p>精确率 衡量 检索到的文本块中有多少与查询相关，即检索到的相关文本块数量占总检索文本块数量的比例。精确度旨在回答：“在所有被检索出的文本块中，有多少是真正相关的？”<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528164538.png" alt="image.png"></p>
<p>高精确率也意味着检索内容更加精准，有效减少了不必要的信息展示。这一指标在避 免无关信息的呈现方面尤为重要，尤其在医疗、法律等专业领域，高精确率能够有效防止 误导性信息的传播。</p>
<h3 id="13-2-2-召回率-Recall"><a href="#13-2-2-召回率-Recall" class="headerlink" title="13.2.2 召回率 Recall"></a>13.2.2 召回率 Recall</h3><p>召回率 衡量系统检索到的相关文本块的全面性，即检索到的相关文本块数量占数据库中所有相关文本块数量的比例。召回率旨在回答：“在所有相关的文本块中，系统成功检索出了多少？”</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528164800.png" alt="image.png"><br>高召回率对避免遗漏关键信息至关重要。若召回率低，模型可能由于缺乏关键信息而 生成不完整的回答或产生错误。例如，在法律文档检索中，遗漏相关信息可能会影响到案 例分析的完整性。</p>
<h3 id="13-2-3-F1-分数"><a href="#13-2-3-F1-分数" class="headerlink" title="13.2.3 F1 分数"></a>13.2.3 F1 分数</h3><p>在 RAG 系统中，提高精确率往往会导致召回率的降低，反之亦然。因此，为了获得 最佳的检索性能，通常需要在精确率和召回率之间找到平衡。这一平衡通常使用 F1 分数 来量化，它是精确率与召回率的调和平均数，用于在两者之间找到适合具体应用需求的最 优点。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528164942.png" alt="image.png"></p>
<h3 id="13-2-4-平均倒数排名"><a href="#13-2-4-平均倒数排名" class="headerlink" title="13.2.4 平均倒数排名"></a>13.2.4 平均倒数排名</h3><p>平均倒数排名（MRR）是一项评估检索系统效率的指标，它特别关注第一个相关文 本块的排名。MRR 可以帮助我们衡量 RAG 系统能否快速返回第一个相关文本块，它的 值对用户体验有直接影响。MRR 值越高，表示系统能越快地找到第一个符合需求的答案。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528165127.png" alt="image.png"><br>Q 表示总查询数。rankq 表示查询 q 的第一个相关文本块的排名。该公式需要 取第一个相关文本块排名的倒数，这意味着 MRR 只关注每个查询返回的第一个相关文本 块的位置。根据这种计算方式，文本块排名越靠前，rankq 的倒数越大，MRR 也会越大。</p>
<h3 id="13-2-5-平均精确率"><a href="#13-2-5-平均精确率" class="headerlink" title="13.2.5 平均精确率"></a>13.2.5 平均精确率</h3><p>平均精确率（MAP）是一项跨多个查询评估的精确率衡量指标，它不仅考虑了检索 结果的精确率，还强调了文档排序的重要性。MAP 通过计算每个查询在不同排名的精确 率来评估检索效果，确保重要的相关文档较为靠前，从而优化用户的搜索体验。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528165242.png" alt="image.png"><br>其中，Q 表示总查询数。而 Average Precision 是针对每个查询计算的平均精确度， 考虑了相关文档的顺序。MAP 在搜索引擎等注重排名质量的系统中很实用，常用于电商平台的产品推荐系统 等场景。</p>
<h3 id="13-2-6-P-K"><a href="#13-2-6-P-K" class="headerlink" title="13.2.6 P@K"></a>13.2.6 P@K</h3><p>P@K 衡量的是前 K 个检索结果的精确率，确保在展示的前几项结果中尽可能多地包含相关信息。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528165340.png" alt="image.png"><br>其中，分子表示前 K 个结果中相关文档的数量，分母中的 K 是固定的返回数量。P@K 在用户特别关注前几项结果的场景中非常有用。例如，在新闻搜索系统中， P@K 可以确保用户在进行搜索时，查到的前几条新闻与查询主题高度相关，从而提升阅 读效率。</p>
<h3 id="13-2-7-总结"><a href="#13-2-7-总结" class="headerlink" title="13.2.7 总结"></a>13.2.7 总结</h3><table>
<thead>
<tr>
<th>指标</th>
<th>衡量内容</th>
<th>计算方法</th>
<th>回答的问题</th>
</tr>
</thead>
<tbody><tr>
<td>精确率</td>
<td>检索结果的准确性</td>
<td>相关文档块数 &#x2F; 检索到的总文档块数</td>
<td>在系统检索的所有文档块中，有多少是真正相关的？</td>
</tr>
<tr>
<td>召回率</td>
<td>检索结果的完整性</td>
<td>检索到的相关文档块数 &#x2F; 数据库中所有相关文档块数</td>
<td>在数据库中所有的相关文档块中，系统成功检索到了多少？</td>
</tr>
<tr>
<td>F1分数</td>
<td>精确率与召回率的平衡</td>
<td><code>2 * (精确率 * 召回率) / (精确率 + 召回率)</code></td>
<td>系统的精确性和完整性如何均衡？</td>
</tr>
<tr>
<td>平均倒数排名</td>
<td>系统快速检索到第一个相关文档块的能力</td>
<td>对多个查询的倒数排名取平均值</td>
<td>平均而言，系统多快能检索到第一个相关文档块？</td>
</tr>
<tr>
<td>平均精确率</td>
<td>精确性和相关文档块排序的综合评估</td>
<td>对多个查询的平均精确率取平均值</td>
<td>平均而言，系统检索的排名靠前的文档块有多精确？</td>
</tr>
<tr>
<td>P@K</td>
<td>前K个检索结果的精确度</td>
<td>前K个结果中的相关文档块数量 &#x2F; K</td>
<td>在前K个检索结果中，有多少是相关的？</td>
</tr>
</tbody></table>
<h2 id="13-3-生成器的评估指标"><a href="#13-3-生成器的评估指标" class="headerlink" title="13.3 生成器的评估指标"></a>13.3 生成器的评估指标</h2><p>响应评估：语义相似度、忠实度等</p>
<h3 id="13-3-1-基于n-gram匹配程度的指标：BLEU"><a href="#13-3-1-基于n-gram匹配程度的指标：BLEU" class="headerlink" title="13.3.1 基于n-gram匹配程度的指标：BLEU"></a>13.3.1 基于n-gram匹配程度的指标：BLEU</h3><p>BLEU（Bilingual Evaluation Understudy，可译为“双语评估替代工具”）用于评 估生成的回答与参考答案之间 n-gram 的重叠情况，强调精确率。它通过 n-gram（即连 续的 n 个 token 构成的序列，n 可以为 1、2、3、4 等）的精确匹配来计算分数。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528165906.png" alt="image.png"><br>其中，BP 是长度惩罚（Brevity Penalty），用于防止生成的回答过短。若生成的回 答比参考答案短，则 BP 小于 1；否则，BP 等于 1。P n 是 n -gram 的精确率。w n 是每 个 n-gram 的权重，通常 w 1、w 2、w 3 和 w 4 的值相等。<br>例如，假设参考答案为“the cat is on mat”，而生成的回答为“the cat on mat”。 对 于BLEU-1（1-gram 精 确 度 ），1-gram（ 单 词 ） 匹 配 项 包 括 “the”“cat”“on”“mat”4 个。生成的回答中有 4 个 1-gram。因此，1-gram 精确率 1。</p>
<h3 id="13-3-2-基于n-gram匹配程度的指标：ROUGE"><a href="#13-3-2-基于n-gram匹配程度的指标：ROUGE" class="headerlink" title="13.3.2 基于n-gram匹配程度的指标：ROUGE"></a>13.3.2 基于n-gram匹配程度的指标：ROUGE</h3><p>ROUGE（Recall-Oriented Understudy for Gisting Evaluation，一般译为“面 向召回的摘要评估替代工具”）用于计算生成的回答与参考答案之间 n-g ram 的重叠量， 并同时考虑了精确率和召回率，提供了较为平衡的评价方式。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528170036.png" alt="image.png"><br>继续使用前面的示例，假设参考答案为“the cat is on mat” ，而生成回答为“the cat on mat”。 对于 ROUGE-1（即 1-gram），匹配项包括“the”“cat”“on”和“mat”4 个。参考答案中有 5 个 1-gram。因此，ROUGE-1 为 0.8。 对于 ROUGE-2（即 2-gram），匹配项包括“the cat”和“on mat”2 个。参考 答案中有 4 个 2-gram。因此，ROUGE-2 为 0.5。</p>
<h3 id="13-3-3-基于n-gram匹配程度的指标：METEOR"><a href="#13-3-3-基于n-gram匹配程度的指标：METEOR" class="headerlink" title="13.3.3 基于n-gram匹配程度的指标：METEOR"></a>13.3.3 基于n-gram匹配程度的指标：METEOR</h3><p>METEOR（Metric for Evaluation of Translation with Explicit Ordering，一般 译为“具有显式排序的翻译评估指标”）通过考量同义词、词干和词序等因素，提供了对 生成的回答与参考答案之间相似度更细致的评估。它不仅计算精确率和召回率的调和平均 值（F mean），还结合了一个惩罚机制来处理词序错误和其他不匹配的情况。METEOR 能 够比 BLEU 和 ROUGE 更好地捕捉语义特性。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528170206.png" alt="image.png"><br>其中，F mean 是精确度和召回率的调和平均值，用于综合衡量生成的回答与参考答案 的匹配程度。P penalty 是一个惩罚项，用于惩罚词序错误及其他类型的错误。</p>
<p>对于精确率，生成的回答包含 4 个单词，其中包含 4 个匹配项。因此，精确度为 1。 对于召回率，参考答案包含 5 个单词，其中包含 4 个匹配项。因此，召回率为 0.8。 对于调和平均值，F mean&#x3D; 2×1×0.8 1+0.8 &#x3D; 1.6 1.8 ≈ 0.89。 对于惩罚项，由于生成的回答中缺少了“is”这个单词，METEOR 会应用一个惩罚 项 P penalty。这个惩罚项的具体数值取决于具体的实现细节，但在本例中我们可以假定它为 0.1。 最终，METEOR 为 0.801。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528170335.png" alt="image.png"></p>
<h3 id="13-3-4-基于语义相似性的指标"><a href="#13-3-4-基于语义相似性的指标" class="headerlink" title="13.3.4 基于语义相似性的指标"></a>13.3.4 基于语义相似性的指标</h3><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2025/20250528170413.png" alt="image.png"></p>
<p>将生成的回答和参考答案转化为向量，使用余弦相似度等方法来计算生成的内容与参考答案之间的语义相似性。</p>
<h3 id="13-3-5-基于忠实度或扎实性的指标"><a href="#13-3-5-基于忠实度或扎实性的指标" class="headerlink" title="13.3.5 基于忠实度或扎实性的指标"></a>13.3.5 基于忠实度或扎实性的指标</h3><p><strong>文档精确率和页面精确率</strong>：这些指标用于衡量大模型引用的文档和具体页面的准 确性。这要求大模型在生成回答时，必须清晰地标注其信息来源，以减少虚构信息的发生。<br><strong>幻觉检测 &#x2F; 一致性检查</strong>：这些指标旨在判断大模型生成的回答是否基于提供的上下文信息，或在不同查询中提供的事实信息是否一 致。在评估过程中，将采用二进制评估（0&#x2F;1），如果生成的回答无法从给定的文档推导出，即便回答本身正确，也视为幻觉。<br><strong>大模型评分量表</strong>：利用更强大的大模型对生成的回答进行评分，例如采用 0 到 5 分的评分标准。具体的评分标准可以根据业务需求进行定制，以便更灵活地适应不同的应用场景。<br><strong>人工评估</strong>：由领域专家手动检查大模型生成的回答是否准确，并验证其是否合理引用了检索到的文档。</p>
<h2 id="13-4-RAG-评估框架-工具"><a href="#13-4-RAG-评估框架-工具" class="headerlink" title="13.4 RAG 评估框架&#x2F;工具"></a>13.4 RAG 评估框架&#x2F;工具</h2><p>工具使用代码示例：<a target="_blank" rel="noopener" href="https://github.com/huangjia2019/rag-in-action/tree/master/09-%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0-Evaluation">https://github.com/huangjia2019/rag-in-action/tree/master/09-系统评估-Evaluation</a></p>
<h3 id="13-4-1-RAGAS"><a href="#13-4-1-RAGAS" class="headerlink" title="13.4.1 RAGAS"></a>13.4.1 RAGAS</h3><p>🎯 <strong>客观指标</strong>：使用基于LLM和传统方式的评估指标，精确评估你的LLM应用效果。<br>🧪 <strong>测试数据生成</strong>：自动创建覆盖多种场景的全面测试数据集。<br>🔗 <strong>无缝集成</strong>：可与LangChain等主流LLM框架及主要可观测性工具无缝协作。<br>📊 <strong>构建反馈闭环</strong>：利用生产数据持续优化你的LLM应用。</p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/explodinggradients/ragas">https://github.com/explodinggradients/ragas</a></p>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv  </span><br><span class="line">load_dotenv()  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset  </span><br><span class="line"><span class="keyword">from</span> ragas.metrics <span class="keyword">import</span> Faithfulness, AnswerRelevancy  </span><br><span class="line"><span class="keyword">from</span> ragas.llms <span class="keyword">import</span> LangchainLLMWrapper  </span><br><span class="line"><span class="keyword">from</span> ragas.embeddings <span class="keyword">import</span> LangchainEmbeddingsWrapper  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings, ChatOpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings  </span><br><span class="line"><span class="keyword">from</span> ragas <span class="keyword">import</span> evaluate  </span><br><span class="line"><span class="keyword">from</span> langchain_deepseek <span class="keyword">import</span> ChatDeepSeek  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 准备评估用的LLM（使用GPT-3.5）  </span></span><br><span class="line">llm_deepseek = ChatDeepSeek(model=<span class="string">&quot;Pro/deepseek-ai/DeepSeek-V3&quot;</span>, api_key=os.getenv(<span class="string">&quot;LLM_API_KEY&quot;</span>), api_base=os.getenv(<span class="string">&quot;LLM_BASE_URL&quot;</span>))  </span><br><span class="line">llm = LangchainLLMWrapper(llm_deepseek)  </span><br><span class="line"><span class="comment"># llm = LangchainLLMWrapper(ChatOpenAI(model_name=&quot;gpt-3.5-turbo&quot;))  </span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 准备数据集  </span></span><br><span class="line">data = &#123;  </span><br><span class="line">    <span class="string">&quot;question&quot;</span>: [  </span><br><span class="line">        <span class="string">&quot;Who is the main character in Black Myth: Wukong?&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;What are the special features of the combat system in Black Myth: Wukong?&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;How is the visual quality of Black Myth: Wukong?&quot;</span>,  </span><br><span class="line">    ],  </span><br><span class="line">    <span class="string">&quot;answer&quot;</span>: [  </span><br><span class="line">        <span class="string">&quot;The main character in Black Myth: Wukong is Sun Wukong, based on the Chinese classic &#x27;Journey to the West&#x27; but with a new interpretation. This version of Sun Wukong is more mature and brooding, showing a different personality from the traditional character.&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;Black Myth: Wukong&#x27;s combat system combines Chinese martial arts with Soulslike game features, including light and heavy attack combinations, technique transformations, and magic systems. Notably, Wukong can transform between different weapon forms during combat, such as his iconic staff and nunchucks, and use various mystical abilities.&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;Black Myth: Wukong is developed using Unreal Engine 5, showcasing stunning visual quality. The game&#x27;s scene modeling, lighting effects, and character details are all top-tier, particularly in its detailed recreation of traditional Chinese architecture and mythological settings.&quot;</span>,  </span><br><span class="line">    ],  </span><br><span class="line">    <span class="string">&quot;contexts&quot;</span>: [  </span><br><span class="line">        [  </span><br><span class="line">            <span class="string">&quot;Black Myth: Wukong is an action RPG developed by Game Science, featuring Sun Wukong as the protagonist based on &#x27;Journey to the West&#x27; but with innovative interpretations. In the game, Wukong has a more composed personality and carries a special mission.&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;The game is set in a mythological world, telling a new story that presents a different take on the traditional Sun Wukong character.&quot;</span>  </span><br><span class="line">        ],  </span><br><span class="line">        [  </span><br><span class="line">            <span class="string">&quot;The game&#x27;s combat system is heavily influenced by Soulslike games while incorporating traditional Chinese martial arts elements. Players can utilize different weapon forms, including the iconic staff and other transforming weapons.&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;During combat, players can unleash various mystical abilities, combined with light and heavy attacks and combo systems, creating a fluid and distinctive combat experience. The game also features a unique transformation system.&quot;</span>  </span><br><span class="line">        ],  </span><br><span class="line">        [  </span><br><span class="line">            <span class="string">&quot;Black Myth: Wukong demonstrates exceptional visual quality, built with Unreal Engine 5, achieving extremely high graphical fidelity. The game&#x27;s environments and character models are meticulously crafted.&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;The lighting effects, material rendering, and environmental details all reach AAA-level standards, perfectly capturing the atmosphere of an Eastern mythological world.&quot;</span>  </span><br><span class="line">        ]  </span><br><span class="line">    ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">dataset = Dataset.from_dict(data)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== Ragas评估指标说明 ===&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n1. Faithfulness（忠实度）&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;- 评估生成的答案是否忠实于上下文内容&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;- 通过将答案分解为简单陈述，然后验证每个陈述是否可以从上下文中推断得出&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;- 该指标仅依赖LLM，不需要embedding模型&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 评估Faithfulness  </span></span><br><span class="line">faithfulness_metric = [Faithfulness(llm=llm)] <span class="comment"># 只需要提供生成模型  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n正在评估忠实度...&quot;</span>)  </span><br><span class="line">faithfulness_result = evaluate(dataset, faithfulness_metric)  </span><br><span class="line">scores = faithfulness_result[<span class="string">&#x27;faithfulness&#x27;</span>]  </span><br><span class="line">mean_score = np.mean(scores) <span class="keyword">if</span> <span class="built_in">isinstance</span>(scores, (<span class="built_in">list</span>, np.ndarray)) <span class="keyword">else</span> scores  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;忠实度评分: <span class="subst">&#123;mean_score:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># print(&quot;\n2. AnswerRelevancy（答案相关性）&quot;)  </span></span><br><span class="line"><span class="comment"># print(&quot;- 评估生成的答案与问题的相关程度&quot;)  </span></span><br><span class="line"><span class="comment"># print(&quot;- 使用embedding模型计算语义相似度&quot;)  </span></span><br><span class="line"><span class="comment"># print(&quot;- 我们将比较开源embedding模型和OpenAI的embedding模型&quot;)  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置两种embedding模型  </span></span><br><span class="line">opensource_embedding = LangchainEmbeddingsWrapper(  </span><br><span class="line">    HuggingFaceEmbeddings(model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>)  </span><br><span class="line">)  </span><br><span class="line">openai_embedding = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-ada-002&quot;</span>))  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建答案相关性评估指标  </span></span><br><span class="line">opensource_relevancy = [AnswerRelevancy(llm=llm, embeddings=opensource_embedding)]  </span><br><span class="line">openai_relevancy = [AnswerRelevancy(llm=llm, embeddings=openai_embedding)]  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n正在评估答案相关性...&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用开源Embedding模型评估:&quot;</span>)  </span><br><span class="line">opensource_result = evaluate(dataset, opensource_relevancy)  </span><br><span class="line">scores = opensource_result[<span class="string">&#x27;answer_relevancy&#x27;</span>]  </span><br><span class="line">opensource_mean = np.mean(scores) <span class="keyword">if</span> <span class="built_in">isinstance</span>(scores, (<span class="built_in">list</span>, np.ndarray)) <span class="keyword">else</span> scores  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相关性评分: <span class="subst">&#123;opensource_mean:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用OpenAI Embedding模型评估:&quot;</span>)  </span><br><span class="line">openai_result = evaluate(dataset, openai_relevancy)  </span><br><span class="line">scores = openai_result[<span class="string">&#x27;answer_relevancy&#x27;</span>]  </span><br><span class="line">openai_mean = np.mean(scores) <span class="keyword">if</span> <span class="built_in">isinstance</span>(scores, (<span class="built_in">list</span>, np.ndarray)) <span class="keyword">else</span> scores  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相关性评分: <span class="subst">&#123;openai_mean:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 比较两种embedding模型的结果  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== Embedding模型比较 ===&quot;</span>)  </span><br><span class="line">diff = openai_mean - opensource_mean  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;开源模型评分: <span class="subst">&#123;opensource_mean:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;OpenAI模型评分: <span class="subst">&#123;openai_mean:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;差异: <span class="subst">&#123;diff:<span class="number">.4</span>f&#125;</span> (<span class="subst">&#123;<span class="string">&#x27;OpenAI更好&#x27;</span> <span class="keyword">if</span> diff &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;开源模型更好&#x27;</span> <span class="keyword">if</span> diff &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;相当&#x27;</span>&#125;</span>)&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="string">我做了以下修改：  </span></span><br><span class="line"><span class="string">移除了 ragas.embeddings.base 中的 HuggingfaceEmbeddings 导入  </span></span><br><span class="line"><span class="string">改为导入 LangChain 的 HuggingFaceEmbeddings使用 LangchainEmbeddingsWrapper 来包装 LangChain 的 HuggingFaceEmbeddings这样做的原因是：  </span></span><br><span class="line"><span class="string">LangChain 的 HuggingFaceEmbeddings 是一个完整的实现，包含了所有必要的方法  </span></span><br><span class="line"><span class="string">LangchainEmbeddingsWrapper 会将 LangChain 的嵌入模型适配到 RAGAS 的接口  </span></span><br><span class="line"><span class="string">这个包装器会自动处理同步和异步方法的转换  </span></span><br><span class="line"><span class="string">1. Faithfulness（忠实度）  </span></span><br><span class="line"><span class="string">- 评估生成的答案是否忠实于上下文内容  </span></span><br><span class="line"><span class="string">- 通过将答案分解为简单陈述，然后验证每个陈述是否可以从上下文中推断得出  </span></span><br><span class="line"><span class="string">- 该指标仅依赖LLM，不需要embedding模型  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">正在评估忠实度...  </span></span><br><span class="line"><span class="string">Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05&lt;00:00,  1.87s/it]  </span></span><br><span class="line"><span class="string">忠实度评分: 0.6071  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">正在评估答案相关性...  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">使用开源Embedding模型评估:  </span></span><br><span class="line"><span class="string">Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01&lt;00:00,  1.54it/s]  </span></span><br><span class="line"><span class="string">相关性评分: 0.8565  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">使用OpenAI Embedding模型评估:  </span></span><br><span class="line"><span class="string">Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06&lt;00:00,  2.11s/it]  </span></span><br><span class="line"><span class="string">相关性评分: 0.9426  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">=== Embedding模型比较 ===开源模型评分: 0.8565  </span></span><br><span class="line"><span class="string">OpenAI模型评分: 0.9426  </span></span><br><span class="line"><span class="string">差异: 0.0861 (OpenAI更好)  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="13-4-2-Trulens"><a href="#13-4-2-Trulens" class="headerlink" title="13.4.2 Trulens"></a>13.4.2 Trulens</h3><p>使用 <strong>TruLens</strong> 对你的 LLM 实验进行系统化评估与追踪。在你开发应用的过程中，包括提示词、模型、检索器、知识源等，TruLens 都是你理解其性能表现的关键工具。<br>TruLens 提供细粒度、与技术栈无关的埋点机制和全面的评估体系，帮助你识别失败模式，并进行系统性迭代，持续优化应用。<br>深入了解 TruLens 背后的核心概念，包括 <strong>反馈函数（Feedback Functions）</strong>、<strong>RAG 三要素（The RAG Triad）</strong>，以及 <strong>诚实、无害、有用评估法（Honest, Harmless and Helpful Evals）</strong>。</p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/truera/trulens">https://github.com/truera/trulens</a></p>
<h3 id="13-4-3-DeepEval"><a href="#13-4-3-DeepEval" class="headerlink" title="13.4.3 DeepEval"></a>13.4.3 DeepEval</h3><p>DeepEval 是一个易于使用的开源 LLM 评估框架，专为大语言模型系统的评估与测试而设计。它类似于 Pytest，但专注于对 LLM 输出结果进行单元测试。</p>
<p>DeepEval 融合了最新的研究成果，支持基于多种指标评估 LLM 输出，包括 G-Eval、幻觉检测（Hallucination）、答案相关性（Answer Relevancy）、RAGAS 等。这些指标利用本地运行的 LLM 和各种 NLP 模型进行评估，无需依赖云端服务。</p>
<p>无论你的 LLM 应用是 RAG（检索增强生成）流程、聊天机器人、AI 智能体，还是通过 LangChain 或 LlamaIndex 实现的，DeepEval 都能为你提供支持。借助 DeepEval，你可以轻松确定最优的模型、提示词和架构，以优化 RAG 流程和智能体工作流，防止提示词漂移，甚至自信地从 OpenAI 平滑迁移到自部署的 Deepseek R1。</p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/confident-ai/deepeval">https://github.com/confident-ai/deepeval</a></p>
<h3 id="13-4-4-Phoenix"><a href="#13-4-4-Phoenix" class="headerlink" title="13.4.4 Phoenix"></a>13.4.4 Phoenix</h3><p>Phoenix 是一个开源的 AI 可观测性平台，专为实验、评估和故障排查而设计。它提供以下功能：<br>•   追踪（Tracing）：使用基于 OpenTelemetry 的埋点机制，追踪你的 LLM 应用运行时的行为。<br>•   评估（Evaluation）：借助 LLM 对应用的响应质量和检索效果进行基准评估。<br>•   数据集（Datasets）：创建可版本管理的示例数据集，用于实验、评估和微调。<br>•   实验（Experiments）：跟踪并评估提示词、LLM模型和检索方式的变化效果。<br>•   沙盒（Playground）：优化提示词、对比模型、调整参数，并回放已追踪的 LLM 调用。<br>•   提示词管理（Prompt Management）：通过版本控制、标签和实验机制，系统化地管理和测试提示词的变更。</p>
<p>Phoenix 不依赖特定厂商或编程语言，开箱即用地支持多个主流框架（如 🦙LlamaIndex、🦜⛓LangChain、Haystack、🧩DSPy、🤗smolagents）以及主流 LLM 提供商（如 OpenAI、Bedrock、MistralAI、VertexAI、LiteLLM、Google GenAI 等）。<br>关于自动化埋点的更多信息，请参考 OpenInference 项目。</p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/Arize-ai/phoenix">https://github.com/Arize-ai/phoenix</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://baihlup.github.io">梦之痕</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://baihlup.github.io/2025/05/28/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/10%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8BRAG%E8%BF%9B%E9%98%B6%E5%AE%9E%E6%88%98%E8%90%A5/">https://baihlup.github.io/2025/05/28/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/10%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8BRAG%E8%BF%9B%E9%98%B6%E5%AE%9E%E6%88%98%E8%90%A5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/RAG/">RAG</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/" title="大模型 RAG 的应用和开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">大模型 RAG 的应用和开发</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/" title="大模型 RAG 的应用和开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-29</div><div class="title">大模型 RAG 的应用和开发</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">梦之痕</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/BaihlUp"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">个人笔记迁移中ing....</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">1.</span> <span class="toc-text">0 参考资料</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#13-%E8%AF%84%E4%BC%B0RAG%E7%B3%BB%E7%BB%9F"><span class="toc-number">2.</span> <span class="toc-text">13 评估RAG系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#13-1-RAG%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0"><span class="toc-number">2.1.</span> <span class="toc-text">13.1 RAG系统评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-2-%E6%A3%80%E7%B4%A2%E5%99%A8%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">2.2.</span> <span class="toc-text">13.2 检索器的评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-1-%E7%B2%BE%E7%A1%AE%E7%8E%87-Precision"><span class="toc-number">2.2.1.</span> <span class="toc-text">13.2.1 精确率 Precision</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-2-%E5%8F%AC%E5%9B%9E%E7%8E%87-Recall"><span class="toc-number">2.2.2.</span> <span class="toc-text">13.2.2 召回率 Recall</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-3-F1-%E5%88%86%E6%95%B0"><span class="toc-number">2.2.3.</span> <span class="toc-text">13.2.3 F1 分数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-4-%E5%B9%B3%E5%9D%87%E5%80%92%E6%95%B0%E6%8E%92%E5%90%8D"><span class="toc-number">2.2.4.</span> <span class="toc-text">13.2.4 平均倒数排名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-5-%E5%B9%B3%E5%9D%87%E7%B2%BE%E7%A1%AE%E7%8E%87"><span class="toc-number">2.2.5.</span> <span class="toc-text">13.2.5 平均精确率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-6-P-K"><span class="toc-number">2.2.6.</span> <span class="toc-text">13.2.6 P@K</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-2-7-%E6%80%BB%E7%BB%93"><span class="toc-number">2.2.7.</span> <span class="toc-text">13.2.7 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-3-%E7%94%9F%E6%88%90%E5%99%A8%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.</span> <span class="toc-text">13.3 生成器的评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-1-%E5%9F%BA%E4%BA%8En-gram%E5%8C%B9%E9%85%8D%E7%A8%8B%E5%BA%A6%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%9ABLEU"><span class="toc-number">2.3.1.</span> <span class="toc-text">13.3.1 基于n-gram匹配程度的指标：BLEU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-2-%E5%9F%BA%E4%BA%8En-gram%E5%8C%B9%E9%85%8D%E7%A8%8B%E5%BA%A6%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%9AROUGE"><span class="toc-number">2.3.2.</span> <span class="toc-text">13.3.2 基于n-gram匹配程度的指标：ROUGE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-3-%E5%9F%BA%E4%BA%8En-gram%E5%8C%B9%E9%85%8D%E7%A8%8B%E5%BA%A6%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%9AMETEOR"><span class="toc-number">2.3.3.</span> <span class="toc-text">13.3.3 基于n-gram匹配程度的指标：METEOR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-4-%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E6%80%A7%E7%9A%84%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.4.</span> <span class="toc-text">13.3.4 基于语义相似性的指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-3-5-%E5%9F%BA%E4%BA%8E%E5%BF%A0%E5%AE%9E%E5%BA%A6%E6%88%96%E6%89%8E%E5%AE%9E%E6%80%A7%E7%9A%84%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.5.</span> <span class="toc-text">13.3.5 基于忠实度或扎实性的指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-4-RAG-%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6-%E5%B7%A5%E5%85%B7"><span class="toc-number">2.4.</span> <span class="toc-text">13.4 RAG 评估框架&#x2F;工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-4-1-RAGAS"><span class="toc-number">2.4.1.</span> <span class="toc-text">13.4.1 RAGAS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-4-2-Trulens"><span class="toc-number">2.4.2.</span> <span class="toc-text">13.4.2 Trulens</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-4-3-DeepEval"><span class="toc-number">2.4.3.</span> <span class="toc-text">13.4.3 DeepEval</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-4-4-Phoenix"><span class="toc-number">2.4.4.</span> <span class="toc-text">13.4.4 Phoenix</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/28/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/10%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8BRAG%E8%BF%9B%E9%98%B6%E5%AE%9E%E6%88%98%E8%90%A5/" title="10 - 大模型RAG进阶实战营">10 - 大模型RAG进阶实战营</a><time datetime="2025-05-28T00:00:00.000Z" title="Created 2025-05-28 00:00:00">2025-05-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/" title="大模型 RAG 的应用和开发">大模型 RAG 的应用和开发</a><time datetime="2025-04-29T00:00:00.000Z" title="Created 2025-04-29 00:00:00">2025-04-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/12/260%20-%20%E5%90%8E%E7%AB%AF&amp;%E6%9E%B6%E6%9E%84/263%20-%20%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/06%20-%20WASM%20%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" title="06 - WASM 插件开发">06 - WASM 插件开发</a><time datetime="2025-02-12T00:00:00.000Z" title="Created 2025-02-12 00:00:00">2025-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/28/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/279%20-%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/02%20-%20%E8%AE%B0%E5%BD%95%E8%AE%BF%E9%97%AE%20HTTPS%20%E7%BD%91%E7%AB%99%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/" title="记录访问 HTTPS 网站报错问题">记录访问 HTTPS 网站报错问题</a><time datetime="2024-09-28T00:00:00.000Z" title="Created 2024-09-28 00:00:00">2024-09-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/03/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/05%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/" title="AI 大模型微调">AI 大模型微调</a><time datetime="2024-09-03T00:00:00.000Z" title="Created 2024-09-03 00:00:00">2024-09-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 梦之痕</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>