<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大模型 RAG 的应用和开发 | 梦之痕</title><meta name="author" content="梦之痕"><meta name="copyright" content="梦之痕"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1 向量数据库1.1 向量数据库简介向量数据库就是一种专门用于存储和处理向量数据的数据库系统，传统的关系型数据库通常不擅长处理向量数据，因为它们需要将数据映射为结构化的表格形式，而向量数据的维度较高、结构复杂，导致传统数据库存储和查询效率低下，所以向量数据库应运而生。 1.2 传统数据库与向量数据库的差异传统数据库采用基于行的存储方式，传统数据库将数据存储为行记录，每一行包含多个字段，并且每个字段">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型 RAG 的应用和开发">
<meta property="og:url" content="https://baihlup.github.io/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/index.html">
<meta property="og:site_name" content="梦之痕">
<meta property="og:description" content="1 向量数据库1.1 向量数据库简介向量数据库就是一种专门用于存储和处理向量数据的数据库系统，传统的关系型数据库通常不擅长处理向量数据，因为它们需要将数据映射为结构化的表格形式，而向量数据的维度较高、结构复杂，导致传统数据库存储和查询效率低下，所以向量数据库应运而生。 1.2 传统数据库与向量数据库的差异传统数据库采用基于行的存储方式，传统数据库将数据存储为行记录，每一行包含多个字段，并且每个字段">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg">
<meta property="article:published_time" content="2025-04-29T00:00:00.000Z">
<meta property="article:modified_time" content="2025-04-30T09:27:28.536Z">
<meta property="article:author" content="梦之痕">
<meta property="article:tag" content="大模型">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://baihlup.github.io/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大模型 RAG 的应用和开发',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-04-30 09:27:28'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">62</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="梦之痕"><span class="site-name">梦之痕</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大模型 RAG 的应用和开发</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-04-29T00:00:00.000Z" title="Created 2025-04-29 00:00:00">2025-04-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-04-30T09:27:28.536Z" title="Updated 2025-04-30 09:27:28">2025-04-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E5%A4%A7%E6%95%B0%E6%8D%AE/">人工智能&amp;大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大模型 RAG 的应用和开发"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="1-向量数据库"><a href="#1-向量数据库" class="headerlink" title="1 向量数据库"></a>1 向量数据库</h1><h2 id="1-1-向量数据库简介"><a href="#1-1-向量数据库简介" class="headerlink" title="1.1 向量数据库简介"></a>1.1 向量数据库简介</h2><p>向量数据库就是一种专门用于存储和处理向量数据的数据库系统，传统的关系型数据库通常不擅长处理向量数据，因为它们需要将数据映射为结构化的表格形式，而<strong>向量数据的维度较高、结构复杂，导致传统数据库存储和查询效率低下</strong>，所以向量数据库应运而生。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163216.png" alt="image.png"></p>
<h2 id="1-2-传统数据库与向量数据库的差异"><a href="#1-2-传统数据库与向量数据库的差异" class="headerlink" title="1.2 传统数据库与向量数据库的差异"></a>1.2 传统数据库与向量数据库的差异</h2><p>传统数据库采用基于行的存储方式，传统数据库将数据存储为行记录，每一行包含多个字段，并且每个字段都有固定的列。传统数据库通常使用索引来提高查询性能，例如下方就是一个典型的传统数据库表格<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163443.png" alt="image.png"></p>
<p>这种方式在处理结构化数据时非常高效，但在处理非结构化或半结构化数据时效率低下。</p>
<p>向量数据库将数据以列形式存储，即每个列都有一个独立的存储空间，这使得向量数据库可以更加灵活地处理复杂的数据结构。向量数据库还可以进行列压缩（<strong>稀疏矩阵</strong>），以减少存储空间和提高数据的访问速度。<br>并且在向量数据库中，将数据表示为<strong>高维向量</strong>，其中<strong>每个向量对应于数据点</strong>。<strong>这些向量之间的距离表示它们之间的相似性</strong>。这种方式使得非结构化或半结构化数据的存储和检索变得更加高效。</p>
<p>以电影数据库为例，我们可以将每部电影表示为一个特征向量。假设我们使用四个特征来描述每部电影：<strong>动作、冒险、爱情、科幻</strong>。每个特征都可以在0到1的范围内进行标准化，表示该电影在该特征上的强度。</p>
<p>例如，电影”阿凡达”的向量表示可以是 <code>[0.9, 0.8, 0.2, 0.9]</code>，其中数字分别表示动作、冒险、爱情、科幻的特征强度。其他电影也可以用类似的方式表示。这些向量可以存储在向量数据库中，如下所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163534.png" alt="image.png"><br>现在，如果我们想要查找与电影”阿凡达”相似的电影，我们可以计算向量之间的距离，找到最接近的向量，从而实现相似性匹配，而无需复杂的SQL查询。这就像使用地图找到两个地点之间的最短路径一样简单。</p>
<h2 id="1-3-传统数据库与向量数据库优缺点"><a href="#1-3-传统数据库与向量数据库优缺点" class="headerlink" title="1.3 传统数据库与向量数据库优缺点"></a>1.3 传统数据库与向量数据库优缺点</h2><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163644.png" alt="image.png"></p>
<h2 id="1-4-相似度搜索算法"><a href="#1-4-相似度搜索算法" class="headerlink" title="1.4 相似度搜索算法"></a>1.4 相似度搜索算法</h2><h3 id="1-4-1-余弦相似度与欧氏距离"><a href="#1-4-1-余弦相似度与欧氏距离" class="headerlink" title="1.4.1 余弦相似度与欧氏距离"></a>1.4.1 余弦相似度与欧氏距离</h3><p>在向量数据库中，支持通过多种方式来计算两个向量的相似度，例如：<strong>余弦相似度、欧式距离、曼哈顿距离、闵可夫斯基距离、汉明距离、Jaccard相似度</strong>等多种。其中最常见的就是 余弦相似度 和 欧式距离。<br>例如下图，左侧就是 欧式距离，右侧就是 余弦相似度：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163817.png" alt="image.png"></p>
<ol>
<li><p>余弦相似度主要用于衡量向量在方向上的相似性，特别适用于文本、图像和高维空间中的向量。它不受向量长度的影响，只考虑方向的相似程度，余弦相似度的计算公式如下（计算两个向量夹角的余弦值，取值范围为<code>[-1, 1]</code>）：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163849.png" alt="image.png"></p>
</li>
<li><p>欧式距离衡量向量之间的直线距离，得到的值可能很大，最小为 0，通常用于低维空间或需要考虑向量各个维度之间差异的情况。欧氏距离较小的向量被认为更相似，欧式距离的计算公式如下：</p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429163918.png" alt="image.png"></p>
<h3 id="1-4-2-相似性搜索加速算法"><a href="#1-4-2-相似性搜索加速算法" class="headerlink" title="1.4.2 相似性搜索加速算法"></a>1.4.2 相似性搜索加速算法</h3><p>在向量数据库中，数据按列进行存储，通常会将多个向量组织成一个 M×N 的矩阵，其中 M 是向量的维度（特征数），N 是向量的数量（数据库中的条目数），这个矩阵可以是稠密或者稀疏的，取决于向量的稀疏性和具体的存储优化策略。</p>
<p>这样计算相似性搜索时，本质上就变成了向量与 M×N 矩阵的每一行进行相似度计算，这里可以用到大量成熟的加速算法：</p>
<p>1. <strong>矩阵分解方法</strong>：</p>
<p>· <strong>SVD（奇异值分解）</strong>：可以通过奇异值分解将原始矩阵转换为更低秩的矩阵表示，从而减少计算量。<br>· <strong>PCA（主成分分析）</strong>：类似地，可以通过主成分分析将高维矩阵映射到低维空间，减少计算复杂度。</p>
<ol start="2">
<li><strong>索引结构和近似算法</strong>：</li>
</ol>
<p>· <strong>LSH（局部敏感哈希）</strong>：LSH 可以在近似相似度匹配中加速计算，特别适用于高维稀疏向量的情况。<br>· <strong>ANN（近似最近邻）算法</strong>：ANN 算法如KD-Tree、Ball-Tree等可以用来加速对最近邻搜索的计算，虽然主要用于向量空间，但也可以部分应用于相似度计算中。</p>
<ol start="3">
<li><strong>GPU 加速</strong>：使用图形处理单元（GPU）进行并行计算可以显著提高相似度计算的速度，尤其是对于大规模数据和高维度向量。</li>
<li><strong>分布式计算</strong>：由于行与行之间独立，所以可以很便捷地支持分布式计算每行与向量的相似度，从而加速整体计算过程。</li>
</ol>
<blockquote>
<p>向量数据库底层除了在算法层面上针对相似性搜索做了大量优化，在存储结构、索引机制等方面均做了大量的优化，这才使得向量数据库在处理高维数据和实现快速相似性搜索上展示出巨大的优势</p>
</blockquote>
<h2 id="1-5-向量数据库的配置和使用"><a href="#1-5-向量数据库的配置和使用" class="headerlink" title="1.5 向量数据库的配置和使用"></a>1.5 向量数据库的配置和使用</h2><p>按照部署方式和提供的服务类型进行划分，向量数据库可以划分成几种：<br>1. <strong>本地文件向量数据库</strong>：用户将向量数据存储到本地文件系统中，通过数据库查询的接口来检索向量数据，例如：<strong>Faiss</strong>。<br>2. <strong>本地部署 API 向量数据库</strong>：这类数据库不仅允许本地部署，而且提供了方便的 API 接口，使用户可以通过网络请求来访问和查询向量数据，这类数据库通常提供了更复杂的功能和管理选项，例如：<strong>Milvus、Annoy、Weaviate</strong> 等。<br>3. <strong>云端 API 向量数据库</strong>：将向量数据存储在云端，通过 API 提供向量数据的访问和管理功能，例如：<strong>TCVectorDB、Pinecone</strong> 等。</p>
<h3 id="1-5-1-Faiss-向量数据库"><a href="#1-5-1-Faiss-向量数据库" class="headerlink" title="1.5.1 Faiss 向量数据库"></a>1.5.1 Faiss 向量数据库</h3><h4 id="1-5-1-1-Faiss-基本使用"><a href="#1-5-1-1-Faiss-基本使用" class="headerlink" title="1.5.1.1 Faiss 基本使用"></a>1.5.1.1 Faiss 基本使用</h4><p>Faiss 是 Facebook 团队开源的向量检索工具，针对高维空间的海量数据，提供高效可靠的相似性检索方式，被广泛用于推荐系统、图片和视频搜索等业务。Faiss 支持 Linux、macOS 和 Windows 操作系统，在百万级向量的相似性检索表现中，Faiss 能实现 &lt; 10ms 的响应（需牺牲搜索准确度）。<br>CPU环境下使用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install faiss-cpu</span><br></pre></td></tr></table></figure>
<p>GPU环境下使用并且已经安装了CUDA，则可以使用GPU版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install faiss-gpu</span><br></pre></td></tr></table></figure>


<p><strong>代码示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="comment"># from langchain_openai import OpenAIEmbeddings  </span></span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># embedding = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)  </span></span><br><span class="line">  </span><br><span class="line">embeddings = HuggingFaceEmbeddings(  </span><br><span class="line">    model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span>,  </span><br><span class="line">    cache_folder=<span class="string">&quot;../22-其他Embedding嵌入模型的配置与使用/embeddings/&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># db = FAISS.from_texts([  </span></span><br><span class="line"><span class="comment">#     &quot;笨笨是一只很喜欢睡觉的猫咪&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;猫咪在窗台上打盹，看起来非常可爱。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;学习新技能是每个人都应该追求的目标。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;我的手机突然关机了，让我有些焦虑。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;阅读是我每天都会做的事情，我觉得很充实。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;,  </span></span><br><span class="line"><span class="comment">#     &quot;我的狗喜欢追逐球，看起来非常开心。&quot;,  </span></span><br><span class="line"><span class="comment"># ], embeddings)  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># print(db.index.ntotal)  </span></span><br><span class="line"><span class="comment"># print(db.save_local(&quot;vector-store/&quot;))  </span></span><br><span class="line">  </span><br><span class="line">db = FAISS.load_local(<span class="string">&quot;vector-store/&quot;</span>, embeddings, allow_dangerous_deserialization=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_score(<span class="string">&quot;我养了一只猫，叫笨笨&quot;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="1-5-1-2-删除指定数据"><a href="#1-5-1-2-删除指定数据" class="headerlink" title="1.5.1.2 删除指定数据"></a>1.5.1.2 删除指定数据</h4><p>在 Faiss 中，支持删除向量数据库中特定的数据，目前仅支持传入数据条目 id 进行删除，并不支持条件筛选（但是可以通过条件筛选找到符合的数据，然后提取 id 列表，然后批量删除）。</p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;删除前数量:&quot;</span>, db.index.ntotal)</span><br><span class="line"><span class="comment"># 获取向量数据库的索引id列表信息</span></span><br><span class="line">db.delete([db.index_to_docstore_id[<span class="number">0</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;删除后数量:&quot;</span>, db.index.ntotal)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">删除前数量: 10</span><br><span class="line">删除后数量: 9</span><br></pre></td></tr></table></figure>

<h4 id="1-5-1-3-带过滤的相似性搜索"><a href="#1-5-1-3-带过滤的相似性搜索" class="headerlink" title="1.5.1.3 带过滤的相似性搜索"></a>1.5.1.3 带过滤的相似性搜索</h4><p>在绝大部分向量数据库中，除了存储向量数据，还支持存储对应的元数据，这里的元数据可以是<strong>文本原文、扩展信息、页码、归属文档id、作者、创建时间</strong>等等任何自定义信息，一般在向量数据库中，会通过元数据来实现对数据的检索。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">向量数据库记录 = 向量(vector)+元数据(metadata)+<span class="built_in">id</span></span><br></pre></td></tr></table></figure>
<p>Faiss 原生并不支持过滤，所以在 LangChain 封装的 FAISS 中对过滤功能进行了相应的处理。首先获取比 k 更多的结果 fetch_k（默认为 20 条），然后先进行搜索，接下来再搜索得到的 fetch_k 条结果上进行过滤，得到 k 条结果，从而实现带过滤的相似性搜索。<br>而且 Faiss 的搜索都是针对 元数据 的，在 Faiss 中执行带过滤的相似性搜索非常简单，只需要在搜索时传递 filter 参数即可，filter 可以传递一个元数据字典，也可以接收一个函数（函数的参数为元数据字典，返回值为布尔值）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="comment"># from langchain_openai import OpenAIEmbeddings  </span></span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># embedding = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)  </span></span><br><span class="line">  </span><br><span class="line">embeddings = HuggingFaceEmbeddings(  </span><br><span class="line">    model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span>,  </span><br><span class="line">    cache_folder=<span class="string">&quot;../22-其他Embedding嵌入模型的配置与使用/embeddings/&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">metadatas: <span class="built_in">list</span> = [  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">2</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">3</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">4</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">5</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">6</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">7</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">8</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">9</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">10</span>&#125;,  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line">db = FAISS.from_texts([  </span><br><span class="line">    <span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>,  </span><br><span class="line">], embeddings, metadatas)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(db.index_to_docstore_id)  </span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_score(<span class="string">&quot;我养了一只猫，叫笨笨&quot;</span>, <span class="built_in">filter</span>=<span class="keyword">lambda</span> x: x[<span class="string">&quot;page&quot;</span>] &gt; <span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<h3 id="1-5-2-Pinecone-向量数据库"><a href="#1-5-2-Pinecone-向量数据库" class="headerlink" title="1.5.2 Pinecone 向量数据库"></a>1.5.2 Pinecone 向量数据库</h3><h4 id="1-5-2-1-Pinecone-配置"><a href="#1-5-2-1-Pinecone-配置" class="headerlink" title="1.5.2.1 Pinecone 配置"></a>1.5.2.1 Pinecone 配置</h4><p>Pinecone 是一个托管的、云原生的向量数据库，具有极简的 API，并且无需在本地部署即可快速使用，Pinecone 服务提供商还为每个账户设置了足够的免费空间，<strong>在开发阶段，可以快速基于 Pinecone 快速开发 AI 应用</strong>。<br>相关资料：<br>1. Pinecone 官网：<a target="_blank" rel="noopener" href="https://www.pinecone.io/">https://www.pinecone.io/</a><br>2. Pinecone 翻译文档：<a target="_blank" rel="noopener" href="https://www.pinecone-io.com/">https://www.pinecone-io.com/</a><br>3. langchain-pinecone 翻译文档：<a target="_blank" rel="noopener" href="http://imooc-langchain.shortvar.com/docs/integrations/vectorstores/pinecone/">http://imooc-langchain.shortvar.com/docs/integrations/vectorstores/pinecone/</a><br>Pinecone 向量数据库的设计架构与 Faiss 差异较大，Pinecone 由于是一个面向商业端的向量数据库，在功能和概念上会更加丰富，有几个核心概念+架构图如下：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429174019.png" alt="image.png"></p>
<p>概念的解释如下：<br>1. <strong>组织</strong>：组织是使用相同结算方式的一个或者多个项目的集合，例如个人账号、公司账号等都算是一个组织。<br>2. <strong>项目</strong>：项目是用来管理向量数据库、索引、硬件资源等内容的整合，可以将不同的项目数据进行区分。<br>3. <strong>索引</strong>：索引是 Pinecone 中数据的最高组织单位，在索引中需要定义向量的存储维度、查询时使用的相似性指标，并且在 Pinecone 中支持两种类型的索引：无服务器索引（根据数据大小自动扩容）和 Pod 索引（预设空间&#x2F;硬件）。<br>4. <strong>命名空间</strong>：命名空间是索引内的分区，用于将索引中的数据区分成不同的组，以便于在不同的组内存储不同的数据，例如知识库、记忆的数据可以存储到不同的组中，类似 Excel 中的 Sheet表。<br>5. <strong>记录</strong>：记录是数据的基本单位，一条记录涵盖了 ID、向量(values)、元数据(metadata) 等。</p>
<p>所以在 Pinecone 中使用向量数据库，要确保 组织、项目、索引、命名空间、记录 等内容均配置好才可以使用，并且由于 Pinecone 是云端向量数据库，使用时还需配置对应的 API 秘钥（可在注册好 Pinecone 后管理页面的 API Key 中设置）。<br>对于 Pinecone，LangChain 团队也封装了响应的包，安装命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U langchain-pinecone</span><br></pre></td></tr></table></figure>

<p>然后在 .env 文件中配置对应的 API 秘钥，如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PINECONE_API_KEY=xxx</span><br></pre></td></tr></table></figure>

<h4 id="1-5-2-2-Pinecone-使用"><a href="#1-5-2-2-Pinecone-使用" class="headerlink" title="1.5.2.2 Pinecone 使用"></a>1.5.2.2 Pinecone 使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="comment"># from langchain_openai import OpenAIEmbeddings  </span></span><br><span class="line"><span class="keyword">from</span> langchain_pinecone <span class="keyword">import</span> PineconeVectorStore  </span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># embedding = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)  </span></span><br><span class="line">  </span><br><span class="line">embeddings = HuggingFaceEmbeddings(  </span><br><span class="line">    model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span>,  </span><br><span class="line">    cache_folder=<span class="string">&quot;../22-其他Embedding嵌入模型的配置与使用/embeddings/&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">texts: <span class="built_in">list</span> = [  </span><br><span class="line">    <span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>,  </span><br><span class="line">]  </span><br><span class="line">metadatas: <span class="built_in">list</span> = [  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">2</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">3</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">4</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">5</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">6</span>, <span class="string">&quot;account_id&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">7</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">8</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">9</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">10</span>&#125;,  </span><br><span class="line">]  </span><br><span class="line">db = PineconeVectorStore(index_name=<span class="string">&quot;llmops&quot;</span>, embedding=embeddings, namespace=<span class="string">&quot;dataset&quot;</span>,  </span><br><span class="line">                         pinecone_api_key=<span class="string">&quot;pcsk_Qz5bt_JMBCg1A6oJPbnceUnhwYf6CA1M57kBTxgVTDda96FkwCECAAhwPYrUvyytinYE2&quot;</span>)  </span><br><span class="line">db.add_texts(texts, metadatas, namespace=<span class="string">&quot;dataset&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">query = <span class="string">&quot;我养了一只猫，叫笨笨&quot;</span>  </span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_relevance_scores(query))</span><br></pre></td></tr></table></figure>

<h3 id="1-5-3-Weaviate-向量数据库"><a href="#1-5-3-Weaviate-向量数据库" class="headerlink" title="1.5.3 Weaviate 向量数据库"></a>1.5.3 Weaviate 向量数据库</h3><h4 id="1-5-3-1-Weaviate-介绍"><a href="#1-5-3-1-Weaviate-介绍" class="headerlink" title="1.5.3.1 Weaviate 介绍"></a>1.5.3.1 Weaviate 介绍</h4><p>Weaviate 是完全使用 Go 语言构建的开源向量数据库，提供了强大的数据存储和检索功能。并且 Weaviate 提供了多种部署方式，以满足不同用户和用例的需求，部署方式如下：<br>1. <strong>Weaviate 云</strong>：使用 Weaviate 官方提供的云服务，支持数据复制、零停机更新、无缝扩容等功能，适用于评估、开发和生产场景。<br>2. <strong>Docker 部署</strong>：使用 Docker 容器部署 Weaviate 向量数据库，适用于评估和开发等场景。<br>3. <strong>K8s 部署</strong>：在 K8s 上部署 Weaviate 向量数据库，适用于开发和生产场景。<br>4. 嵌入式 Weaviate：基于本地文件的方式构建 Weaviate 向量数据库，适用于评估场景，不过嵌入式 Weaviate 只适用于 Linux、macOS 系统，在 Windows 下不支持。</p>
<p>Weaviate 和 Pinecone&#x2F;TCVectorDB 一样，也存在着集合的概念，在 Weaviate 中集合类似传统关系型数据库中的表，负责管理一类数据&#x2F;数据对象，要使用 Weaviate 的流程其实也非常简单：<br>1. 创建部署 Weaviate 数据库（使用 Weaviate 云、Docker 部署）。<br>2. 安装 Python 客户端&#x2F;LangChain 集成包。<br>3. 连接 Weaviate（本地连接、云端连接）。<br>4. 创建数据集&#x2F;集合（代码创建、可视化管理界面创建），在 Weaviate 中，集合的名字必须以大写字母开头，并且只能包含字母、数字和下划线，否则创建的时候会出错，和 Python 的类名规范几乎一致。<br>5. 添加数据&#x2F;向量。<br>6. 相似性搜索&#x2F;带过滤器的相似性搜索。</p>
<p><strong>参考资料：</strong><br>1. Weaviate 官网：<a target="_blank" rel="noopener" href="https://weaviate.io/">https://weaviate.io/</a><br>2. Weaviate 快速上手指南：<a target="_blank" rel="noopener" href="https://weaviate.io/developers/weaviate/quickstart">https://weaviate.io/developers/weaviate/quickstart</a></p>
<p>LangChain Weaviate 集成包翻译文档：<a target="_blank" rel="noopener" href="https://imooc-langchain.shortvar.com/docs/integrations/vectorstores/weaviate">https://imooc-langchain.shortvar.com/docs/integrations/vectorstores/weaviate</a></p>
<h4 id="1-5-3-2-Weaviate-向量数据库的使用"><a href="#1-5-3-2-Weaviate-向量数据库的使用" class="headerlink" title="1.5.3.2 Weaviate 向量数据库的使用"></a>1.5.3.2 Weaviate 向量数据库的使用</h4><p><strong>Docker 部署 Weaviate 向量数据库：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name weaviate-dev -p 8080:8080 -p 50051:50051 cr.weaviate.io/semitechnologies/weaviate:1.24.20</span><br></pre></td></tr></table></figure>
<p>创建好 Weaviate 数据库服务后，接下来就可以安装 Python 客户端&#x2F;LangChain 集成包，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -Uqq langchain-weaviate</span><br></pre></td></tr></table></figure>
<p>如果使用的是 Weaviate 云服务，可以直接从可视化界面创建 Collection，亦或者在使用时 LangChain 自动检测对应的数据集是否存在，如果不存在则直接创建。<br>然后就可以考虑连接 Weaviate 服务了，Weaviate 框架针对不同的部署方式提供的不同的连接方法：<br>1. weaviate.connect_to_local()：连接到本地的部署服务，需配置连接 URL、端口号。<br>2. weaviate.connect_to_wcs()：连接到远程的 Weaviate 服务，需配置连接 URL、连接秘钥。</p>
<p><strong>代码示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> weaviate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接192.168.2.120:8080并创建weaviate客户端</span></span><br><span class="line">client = weaviate.connect_to_local(<span class="string">&quot;192.168.2.120&quot;</span>, <span class="string">&quot;8080&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>连接到远程的 Weaviate 服务代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> weaviate</span><br><span class="line"><span class="keyword">from</span> weaviate.auth <span class="keyword">import</span> AuthApiKey</span><br><span class="line">client = weaviate.connect_to_wcs(</span><br><span class="line">    cluster_url=<span class="string">&quot;https://2j9jgyhprd2yej3c3rwog.c0.us-west3.gcp.weaviate.cloud&quot;</span>,</span><br><span class="line">    auth_credentials=AuthApiKey(<span class="string">&quot;BAn9bGZdZbdGCmUyfdegQoKFctyMmxaQdDFb&quot;</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>创建好客户端后，接下来可以基于客户端创建 LangChain 向量数据库实例，在实例化 LangChain VectorDB 时，需要传递 client（客户端）、 index_name（集合名字）、text（原始文本的存储键）、embedding（文本嵌入模型），如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv</span><br><span class="line"><span class="keyword">import</span> weaviate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_weaviate <span class="keyword">import</span> WeaviateVectorStore</span><br><span class="line"></span><br><span class="line">dotenv.load_dotenv()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.连接weaviate向量数据库</span></span><br><span class="line">client = weaviate.connect_to_local(<span class="string">&quot;192.168.2.120&quot;</span>, <span class="string">&quot;8080&quot;</span>)</span><br><span class="line"><span class="comment"># 2.实例化WeaviateVectorStore</span></span><br><span class="line">embedding = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)</span><br><span class="line">db = WeaviateVectorStore(client=client, index_name=<span class="string">&quot;DatasetTest&quot;</span>, text_key=<span class="string">&quot;text&quot;</span>, embedding=embedding)</span><br></pre></td></tr></table></figure>

<p>实例化 LangChain VectorDB 后，就可以像 Faiss、Pinecone、TCVectorDB 一样去使用了，例如执行新增数据后完成检索示例如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv</span><br><span class="line"><span class="keyword">import</span> weaviate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_weaviate <span class="keyword">import</span> WeaviateVectorStore</span><br><span class="line">dotenv.load_dotenv()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.连接weaviate向量数据库</span></span><br><span class="line">client = weaviate.connect_to_local(<span class="string">&quot;192.168.2.120&quot;</span>, <span class="string">&quot;8080&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.实例化WeaviateVectorStore</span></span><br><span class="line">embedding = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)</span><br><span class="line">db = WeaviateVectorStore(client=client, index_name=<span class="string">&quot;dataset-test&quot;</span>, text_key=<span class="string">&quot;text&quot;</span>, embedding=embedding)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.新增数据</span></span><br><span class="line">ids = db.add_texts([</span><br><span class="line">    <span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>,</span><br><span class="line">    <span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>,</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.检索数据</span></span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_score(<span class="string">&quot;笨笨&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>输出内容：<br>[(Document(page_content&#x3D;’笨笨是一只很喜欢睡觉的猫咪’), 0.699999988079071), (Document(page_content&#x3D;’猫咪在窗台上打盹，看起来非常可爱。’), 0.2090398222208023), (Document(page_content&#x3D;’我的狗喜欢追逐球，看起来非常开心。’), 0.19787956774234772), (Document(page_content&#x3D;’我的手机突然关机了，让我有些焦虑。’), 0.11435992270708084)]</p>
<p>在 Weaviate 中，也支持带过滤器的相似性筛选，并且 LangChain Weaviate 社区包并没有对筛选过滤器进行二次封装，所以直接传递原生的 weaviate 过滤器即可，参考文档：<a target="_blank" rel="noopener" href="https://weaviate.io/developers/weaviate/search/filters">https://weaviate.io/developers/weaviate/search/filters</a></p>
<p>例如需要检索 page 属性大于等于 5 的所有数据，可以构建一个 filters 后传递给检索方法，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> weaviate.classes.query <span class="keyword">import</span> Filter</span><br><span class="line">filters = Filter.by_property(<span class="string">&quot;page&quot;</span>).greater_or_equal(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_score(<span class="string">&quot;笨笨&quot;</span>, filters=filters))</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(Document(page_content=<span class="string">&#x27;我的狗喜欢追逐球，看起来非常开心。&#x27;</span>, metadata=&#123;<span class="string">&#x27;page&#x27;</span>: 10.0, <span class="string">&#x27;account_id&#x27;</span>: None&#125;), 0.699999988079071), (Document(page_content=<span class="string">&#x27;我的手机突然关机了，让我有些焦虑。&#x27;</span>, metadata=&#123;<span class="string">&#x27;page&#x27;</span>: 7.0, <span class="string">&#x27;account_id&#x27;</span>: None&#125;), 0.4045487940311432), (Document(page_content=<span class="string">&#x27;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&#x27;</span>, metadata=&#123;<span class="string">&#x27;page&#x27;</span>: 6.0, <span class="string">&#x27;account_id&#x27;</span>: 1.0&#125;), 0.318904846906662), (Document(page_content=<span class="string">&#x27;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&#x27;</span>, metadata=&#123;<span class="string">&#x27;page&#x27;</span>: 5.0, <span class="string">&#x27;account_id&#x27;</span>: None&#125;), 0.2671944797039032)]</span><br></pre></td></tr></table></figure>

<p>如果想获取 Weaviate 原始集合的实例，可以通过 <code>db._collection</code> 快速获得，从而去执行一些原始操作，例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> weaviate.classes.query <span class="keyword">import</span> MetadataQuery</span><br><span class="line"></span><br><span class="line">collection = db._collection</span><br><span class="line"></span><br><span class="line">response = collection.query.near_text(</span><br><span class="line">    query=<span class="string">&quot;a sweet German white wine&quot;</span>,</span><br><span class="line">    limit=<span class="number">2</span>,</span><br><span class="line">    target_vector=<span class="string">&quot;title_country&quot;</span>,  <span class="comment"># Specify the target vector for named vector collections</span></span><br><span class="line">    return_metadata=MetadataQuery(distance=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> response.objects:</span><br><span class="line">    <span class="built_in">print</span>(o.properties)</span><br><span class="line">    <span class="built_in">print</span>(o.metadata.distance)</span><br></pre></td></tr></table></figure>

<h3 id="1-5-4-自定义向量数据库"><a href="#1-5-4-自定义向量数据库" class="headerlink" title="1.5.4 自定义向量数据库"></a>1.5.4 自定义向量数据库</h3><p>向量数据库的发展非常迅猛，几乎间隔几天就有新的向量数据库发布，LangChain 不可能将所有向量数据库都进行集成，亦或者封装的包存在这一些 bug 或错误，这个时候就需要考虑创建自定义向量数据库，去实现特定的方法。</p>
<p>在 LangChain 实现自定义向量数据库的类有两种模式，一种是继承封装好的数据库类，一种是继承基类 VectorStore。前一种一般继承后重写部分方法进行扩展或者修复 bug，后面一种是对接新的向量数据库。</p>
<p>在 LangChain 中，继承 VectorStore 只需实现最基础的 3 个方法即可正常使用：<br>1. <strong>add_texts</strong>：将对应的数据添加到向量数据库中。<br>2. <strong>similarity_search</strong>：最基础的相似性搜索。<br>3. <strong>from_texts</strong>：从特定的文本列表、元数据列表中构建向量数据库。</p>
<p>其他方法因为使用频率并不高，VectorStore 并没有设置成虚拟方法，但是再没有实现的情况下，直接调用会报错，涵盖：<br>1. delete()：删除向量数据库中的数据。<br>2. <code>_select_relevance_score_fn()</code>：根据距离计算相似性得分函数。<br>3. <code>similarity_search_with_score()</code>：携带得分的相似性搜索函数。<br>4. similarity_search_by_vector()：传递向量进行相似性搜索。<br>5. max_marginal_relevance_search()：最大边界相似性搜索。<br>6. max_marginal_relevance_search_by_vector()：传递向量进行最大边界相关性搜索。</p>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> uuid  </span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span>, <span class="type">Any</span>, Iterable, <span class="type">Type</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line"><span class="keyword">from</span> langchain_core.embeddings <span class="keyword">import</span> Embeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_core.vectorstores <span class="keyword">import</span> VectorStore  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryVectorStore</span>(<span class="title class_ inherited__">VectorStore</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;基于内存+欧几里得距离的向量数据库&quot;&quot;&quot;</span>  </span><br><span class="line">    store: <span class="built_in">dict</span> = &#123;&#125;  <span class="comment"># 存储向量的临时变量  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding: Embeddings</span>):  </span><br><span class="line">        self._embedding = embedding  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_texts</span>(<span class="params">self, texts: Iterable[<span class="built_in">str</span>], metadatas: <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">dict</span>]] = <span class="literal">None</span>, **kwargs: <span class="type">Any</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;将数据添加到向量数据库中&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="comment"># 1.检测metadata的数据格式  </span></span><br><span class="line">        <span class="keyword">if</span> metadatas <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(metadatas) != <span class="built_in">len</span>(texts):  </span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;metadatas格式错误&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.将数据转换成文本嵌入/向量和ids  </span></span><br><span class="line">        embeddings = self._embedding.embed_documents(texts)  </span><br><span class="line">        ids = [<span class="built_in">str</span>(uuid.uuid4()) <span class="keyword">for</span> _ <span class="keyword">in</span> texts]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 3.通过for循环组装数据记录  </span></span><br><span class="line">        <span class="keyword">for</span> idx, text <span class="keyword">in</span> <span class="built_in">enumerate</span>(texts):  </span><br><span class="line">            self.store[ids[idx]] = &#123;  </span><br><span class="line">                <span class="string">&quot;id&quot;</span>: ids[idx],  </span><br><span class="line">                <span class="string">&quot;text&quot;</span>: text,  </span><br><span class="line">                <span class="string">&quot;vector&quot;</span>: embeddings[idx],  </span><br><span class="line">                <span class="string">&quot;metadata&quot;</span>: metadatas[idx] <span class="keyword">if</span> metadatas <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> &#123;&#125;,  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> ids  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">similarity_search</span>(<span class="params">self, query: <span class="built_in">str</span>, k: <span class="built_in">int</span> = <span class="number">4</span>, **kwargs: <span class="type">Any</span></span>) -&gt; <span class="type">List</span>[Document]:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;传入对应的query执行相似性搜索&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="comment"># 1.将query转换成向量  </span></span><br><span class="line">        embedding = self._embedding.embed_query(query)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.循环和store中的每一个向量进行比较，计算欧几里得距离  </span></span><br><span class="line">        result = []  </span><br><span class="line">        <span class="keyword">for</span> key, record <span class="keyword">in</span> self.store.items():  </span><br><span class="line">            distance = self._euclidean_distance(embedding, record[<span class="string">&quot;vector&quot;</span>])  </span><br><span class="line">            result.append(&#123;<span class="string">&quot;distance&quot;</span>: distance, **record&#125;)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 3.排序，欧几里得距离越小越靠前  </span></span><br><span class="line">        sorted_result = <span class="built_in">sorted</span>(result, key=<span class="keyword">lambda</span> x: x[<span class="string">&quot;distance&quot;</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 4.取数据，取k条数据  </span></span><br><span class="line">        result_k = sorted_result[:k]  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> [  </span><br><span class="line">            Document(page_content=item[<span class="string">&quot;text&quot;</span>], metadata=&#123;**item[<span class="string">&quot;metadata&quot;</span>], <span class="string">&quot;score&quot;</span>: item[<span class="string">&quot;distance&quot;</span>]&#125;)  </span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> result_k  </span><br><span class="line">        ]  </span><br><span class="line">  </span><br><span class="line"><span class="meta">    @classmethod  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_texts</span>(<span class="params">cls: <span class="type">Type</span>[<span class="string">&quot;MemoryVectorStore&quot;</span>], texts: <span class="type">List</span>[<span class="built_in">str</span>], embedding: Embeddings,  </span></span><br><span class="line"><span class="params">                   metadatas: <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">dict</span>]] = <span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">                   **kwargs: <span class="type">Any</span></span>) -&gt; <span class="string">&quot;MemoryVectorStore&quot;</span>:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;从文本和元数据中去构建向量数据库&quot;&quot;&quot;</span>  </span><br><span class="line">        memory_vector_store = cls(embedding=embedding)  </span><br><span class="line">        memory_vector_store.add_texts(texts, metadatas, **kwargs)  </span><br><span class="line">        <span class="keyword">return</span> memory_vector_store  </span><br><span class="line">  </span><br><span class="line"><span class="meta">    @classmethod  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_euclidean_distance</span>(<span class="params">cls, vec1: <span class="built_in">list</span>, vec2: <span class="built_in">list</span></span>) -&gt; <span class="built_in">float</span>:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;计算两个向量的欧几里得距离&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="keyword">return</span> np.linalg.norm(np.array(vec1) - np.array(vec2))  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.创建初始数据与嵌入模型  </span></span><br><span class="line">texts = [  </span><br><span class="line">    <span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>,  </span><br><span class="line">]  </span><br><span class="line">metadatas = [  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">2</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">3</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">4</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">5</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">6</span>, <span class="string">&quot;account_id&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">7</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">8</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">9</span>&#125;,  </span><br><span class="line">    &#123;<span class="string">&quot;page&quot;</span>: <span class="number">10</span>&#125;,  </span><br><span class="line">]  </span><br><span class="line">embedding = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.构建自定义向量数据库  </span></span><br><span class="line">db = MemoryVectorStore(embedding=embedding)  </span><br><span class="line">  </span><br><span class="line">ids = db.add_texts(texts, metadatas)  </span><br><span class="line"><span class="built_in">print</span>(ids)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.执行检索  </span></span><br><span class="line"><span class="built_in">print</span>(db.similarity_search(<span class="string">&quot;笨笨是谁？&quot;</span>))</span><br></pre></td></tr></table></figure>

<h1 id="2-嵌入模型介绍和使用"><a href="#2-嵌入模型介绍和使用" class="headerlink" title="2 嵌入模型介绍和使用"></a>2 嵌入模型介绍和使用</h1><h2 id="2-1-嵌入模型介绍"><a href="#2-1-嵌入模型介绍" class="headerlink" title="2.1 嵌入模型介绍"></a>2.1 嵌入模型介绍</h2><p>要想使用向量数据库的相似性搜索，存储的数据必须是向量，那么如何将高维度的文字、图片、视频等非结构化数据转换成向量呢？这个时候就需要使用到 Embedding 嵌入模型了，例如下方就是 Embedding 嵌入模型的运行流程：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250429164235.png" alt="image.png"></p>
<p>Embedding 模型是一种在机器学习和自然语言处理中广泛应用的技术，它旨在将高纬度的数据（如文字、图片、视频）映射到低纬度的空间。Embedding 向量是一个 N 维的实值向量，它将输入的数据表示成一个连续的数值空间中的点。这种嵌入可以是一个词、一个类别特征（如商品、电影、物品等）或时间序列特征等。<br>而且通过学习，<strong>Embedding 向量可以更准确地表示对应特征的内在含义，使几何距离相近的向量对应的物体有相近的含义</strong>，甚至对向量进行加减乘除算法都有意义！<br>一句话理解 Embedding：<strong>一种模型生成方法，可以将非结构化的数据，例如文本&#x2F;图片&#x2F;视频等数据映射成有意义的向量数据</strong>。</p>
<p>目前生成 embedding 方法的模型有以下 4 类：<br>1. <strong>Word2Vec（词嵌入模型）</strong>：这个模型通过学习将单词转化为连续的向量表示，以便计算机更好地理解和处理文本。Word2Vec 模型基于两种主要算法 CBOW 和 Skip-gram。<br>2. <strong>Glove</strong>：一种用于自然语言处理的词嵌入模型，它与其他常见的词嵌入模型（如 Word2Vec 和 FastText）类似，可以将单词转化为连续的向量表示。GloVe 模型的原理是通过观察单词在语料库中的共现关系，学习得到单词之间的语义关系。具体来说，GloVe 模型将共现概率矩阵表示为两个词向量之间的点积和偏差的关系，然后通过迭代优化来训练得到最佳的词向量表示。<br><strong>GloVe</strong> 模型的优点是它能够在大规模语料库上进行有损压缩，得到较小维度的词向量，同时保持了单词之间的语义关系。这些词向量可以被用于多种自然语言处理任务，如词义相似度计算、情感分析、文本分类等。<br>3. <strong>FastText</strong>：一种基于词袋模型的词嵌入技术，与其他常见的词嵌入模型（如 Word2Vec 和 GloVe）不同之处在于，FastText考虑了单词的子词信息。其核心思想是将单词视为字符的 n-grams 的集合，在训练过程中，模型会同时学习单词级别和n-gram级别的表示。这样可以捕捉到单词内部的细粒度信息，从而更好地处理各种形态和变体的单词。<br>4. <strong>大模型 Embeddings（重点）</strong>：和大模型相关的嵌入模型，如 OpenAI 官方发布的第二代模型：text-embedding-ada-002。它最长的输入是 8191 个tokens，输出的维度是 1536。</p>
<h2 id="2-3-Embedding-的价值"><a href="#2-3-Embedding-的价值" class="headerlink" title="2.3 Embedding 的价值"></a>2.3 Embedding 的价值</h2><p>1. <strong>降维</strong>：在许多实际问题中，原始数据的维度往往非常高。例如，在自然语言处理中，如果使用 Token 词表编码来表示词汇，其维度等于词汇表的大小，可能达到数十万甚至更高。通过 Embedding，我们可以将这些高维数据映射到一个低维空间，大大减少了模型的复杂度。<br>2. <strong>捕捉语义信息</strong>：Embedding 不仅仅是降维，更重要的是，它能够捕捉到数据的语义信息。例如，在词嵌入中，语义上相近的词在向量空间中也会相近。这意味着Embedding可以保留并利用原始数据的一些重要信息。<br>3. <strong>适应性</strong>： 与一些传统的特征提取方法相比，Embedding 是通过数据驱动的方式学习的。这意味着它能够自动适应数据的特性，而无需人工设计特征。<br>4. <strong>泛化能力</strong>：在实际问题中，我们经常需要处理一些在训练数据中没有出现过的数据。由于Embedding能够捕捉到数据的一些内在规律，因此对于这些未见过的数据，Embedding仍然能够给出合理的表示。<br>5. <strong>可解释性</strong>：尽管 Embedding 是高维的，但我们可以通过一些可视化工具（如t-SNE）来观察和理解 Embedding 的结构。这对于理解模型的行为，以及发现数据的一些潜在规律是非常有用的。</p>
<h2 id="2-4-CacheBackEmbedding-组件"><a href="#2-4-CacheBackEmbedding-组件" class="headerlink" title="2.4 CacheBackEmbedding 组件"></a>2.4 CacheBackEmbedding 组件</h2><p>通过嵌入模型计算传递数据的向量需要昂贵的算力，对于重复的内容，Embeddings 计算的结果肯定是一致的，如果数据重复仍然二次计算，会导致效率非常低，而且增加无用功。</p>
<p>所以在 LangChain 中提供了一个叫 CacheBackEmbedding 的包装类，一般通过类方法 from_bytes_store 进行实例化，它接受以下参数：<br>1. underlying_embedder：用于嵌入的嵌入模型。<br>2. document_embedding_cache：用于缓存文档嵌入的任何存储库（ByteStore）。<br>3. batch_size：可选参数，默认为 None，在存储更新之间要嵌入的文档数量。<br>4. namespace：可选参数，默认为“”，用于文档缓存的命名空间。此命名空间用于避免与其他缓存发生冲突。例如，将其设置为所使用的嵌入模型的名称。<br>5. query_embedding_cache：可选默认为 None 或者不缓存，用于缓存查询&#x2F;文本嵌入的 ByteStore，或这是为 True 以使用与 document_embedding_cache 相同的存储。</p>
<blockquote>
<p>CacheBackEmbedding 默认不缓存 embed_query 生成的向量，如果要缓存，需要设置 query_embedding_cache 的值，另外请尽可能设置 namespace，以避免使用不同嵌入模型嵌入的相同文本发生冲突。</p>
</blockquote>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> CacheBackedEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain.storage <span class="keyword">import</span> LocalFileStore  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> norm  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">vector1: <span class="built_in">list</span>, vector2: <span class="built_in">list</span></span>) -&gt; <span class="built_in">float</span>:  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算传入两个向量的余弦相似度&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="comment"># 1.计算内积/点积  </span></span><br><span class="line">    dot_product = np.dot(vector1, vector2)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2.计算向量的范数/长度  </span></span><br><span class="line">    norm_vec1 = norm(vector1)  </span><br><span class="line">    norm_vec2 = norm(vector2)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3.计算余弦相似度  </span></span><br><span class="line">    <span class="keyword">return</span> dot_product / (norm_vec1 * norm_vec2)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">embeddings = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)  </span><br><span class="line">embeddings_with_cache = CacheBackedEmbeddings.from_bytes_store(  </span><br><span class="line">    embeddings,  </span><br><span class="line">    LocalFileStore(<span class="string">&quot;./cache/&quot;</span>),  </span><br><span class="line">    namespace=embeddings.model,  </span><br><span class="line">    query_embedding_cache=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">query_vector = embeddings_with_cache.embed_query(<span class="string">&quot;你好，我是慕小课，我喜欢打篮球&quot;</span>)  </span><br><span class="line">documents_vector = embeddings_with_cache.embed_documents([  </span><br><span class="line">    <span class="string">&quot;你好，我是慕小课，我喜欢打篮球&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;这个喜欢打篮球的人叫慕小课&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;求知若渴，虚心若愚&quot;</span>  </span><br><span class="line">])  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(query_vector)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(query_vector))  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;============&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents_vector))  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;vector1与vector2的余弦相似度:&quot;</span>, cosine_similarity(documents_vector[<span class="number">0</span>], documents_vector[<span class="number">1</span>]))  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;vector2与vector3的余弦相似度:&quot;</span>, cosine_similarity(documents_vector[<span class="number">0</span>], documents_vector[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>

<h2 id="2-5-HuggingFace-Embedding-模型的配置和使用"><a href="#2-5-HuggingFace-Embedding-模型的配置和使用" class="headerlink" title="2.5 HuggingFace Embedding 模型的配置和使用"></a>2.5 HuggingFace Embedding 模型的配置和使用</h2><h3 id="2-5-1-HuggingFace-本地模型"><a href="#2-5-1-HuggingFace-本地模型" class="headerlink" title="2.5.1 HuggingFace 本地模型"></a>2.5.1 HuggingFace 本地模型</h3><p>在某些对数据保密要求极高的场合下，数据不允许传递到外网，这个时候就可以考虑使用本地的文本嵌入模型——Hugging Face 本地嵌入模型，安装 langchain-huggingface 与 sentence-transformers 包，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U langchain-huggingface sentence-transformers</span><br></pre></td></tr></table></figure>

<p>其中 langchain-huggingface 是 langchain 团队基于 huggingface 封装的第三方社区包，sentence-transformers 是一个用于生成和使用预训练的文本嵌入，基于 transformer 架构，也是目前使用量最大的本地文本嵌入模型。<br>配置好后，就可以像正常的文本嵌入模型一样使用了，示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings  </span><br><span class="line">  </span><br><span class="line">embeddings = HuggingFaceEmbeddings(  </span><br><span class="line">    model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span>,  </span><br><span class="line">    cache_folder=<span class="string">&quot;./embeddings/&quot;</span>  </span><br><span class="line">)  </span><br><span class="line"></span><br><span class="line">query_vector = embeddings.embed_query(<span class="string">&quot;你好，我是慕小课，我喜欢打篮球游泳&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(query_vector)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(query_vector))</span><br></pre></td></tr></table></figure>

<h3 id="2-5-2-HuggingFace远程嵌入模型"><a href="#2-5-2-HuggingFace远程嵌入模型" class="headerlink" title="2.5.2 HuggingFace远程嵌入模型"></a>2.5.2 HuggingFace远程嵌入模型</h3><p>部分模型的文件比较大，如果只是短期内调试，可以考虑使用 HuggingFace 提供的远程嵌入模型，首先安装对应的依赖</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install huggingface_hub</span><br></pre></td></tr></table></figure>
<p>然后在 Hugging Face 官网（<a target="_blank" rel="noopener" href="https://huggingface.com/">https://huggingface.co/</a>) 的 setting 中添加对应的访问秘钥，并配置到 .env 文件中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HUGGINGFACEHUB_API_TOKEN=xxx</span><br></pre></td></tr></table></figure>
<p>接下来就可以使用 HuggingFace 提供的推理服务，这样在本地服务器上就无需配置对应的文本嵌入模型了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEndpointEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">embeddings = HuggingFaceEndpointEmbeddings(model=<span class="string">&quot;sentence-transformers/all-MiniLM-L12-v2&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">query_vector = embeddings.embed_query(<span class="string">&quot;你好，我是慕小课，我喜欢打篮球游泳&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(query_vector)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(query_vector))</span><br></pre></td></tr></table></figure>

<p>相关资料信息：<br>1. Hugging Face 官网：<a target="_blank" rel="noopener" href="https://huggingface.co/">https://huggingface.co/</a><br>2. HuggingFace 嵌入文档：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/text_embedding/sentence_transformers/">https://python.langchain.com/v0.2/docs/integrations/text_embedding&#x2F;sentence_transformers&#x2F;</a><br>3. HuggingFace 嵌入翻译文档：<a target="_blank" rel="noopener" href="http://imooc-langchain.shortvar.com/docs/integrations/text_embedding/sentence_transformers/">http://imooc-langchain.shortvar.com/docs/integrations/text_embedding&#x2F;sentence_transformers&#x2F;</a></p>
<h1 id="3-文档加载器"><a href="#3-文档加载器" class="headerlink" title="3 文档加载器"></a>3 文档加载器</h1><h2 id="3-1-Document-与文档加载器"><a href="#3-1-Document-与文档加载器" class="headerlink" title="3.1 Document 与文档加载器"></a>3.1 Document 与文档加载器</h2><p>Document 类是 LangChain 中的核心组件，这个类定义了一个文档对象的结构，涵盖了文本内容和相关的元数据，Document 也是文档加载器、文档分割器、向量数据库、检索器这几个组件之间交互传递的状态数据。<br>在 LangChain 中所有文档加载器的基类为 BaseLoader，封装了统一的 5 个方法：<br>1. load()&#x2F;aload()：加载和异步加载文档，返回的数据为文档列表。<br>2. load_and_split()：传递分割器，加载并将大文档按照传入的分割器进行切割，返回的数据为分割后的文档列表。<br>3. lazy_load()&#x2F;alazy_load()：懒加载和异步懒加载文档，返回的是一个迭代器，适用于传递的数据源有多份文档的情况，例如文件夹加载器，可以每次获得最新的加载文档，不需要等到所有文档都加载完毕。</p>
<p>在 LangChain 中封装了上百种文档加载器，几乎所有的文件都可以使用这些加载器完成数据的读取，而不需要手动去封装<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430095626.png" alt="image.png"></p>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建加载器  </span></span><br><span class="line">loader = TextLoader(<span class="string">&quot;./电商产品数据.txt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.加载数据  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  </span><br><span class="line"><span class="built_in">print</span>(documents[<span class="number">0</span>].metadata)</span><br></pre></td></tr></table></figure>

<h2 id="3-2-内置文档加载器的使用技巧"><a href="#3-2-内置文档加载器的使用技巧" class="headerlink" title="3.2 内置文档加载器的使用技巧"></a>3.2 内置文档加载器的使用技巧</h2><p>LangChain 内置文档加载器文档：<a target="_blank" rel="noopener" href="https://imooc-langchain.shortvar.com/docs/integrations/document_loaders/">https://imooc-langchain.shortvar.com/docs/integrations/document_loaders&#x2F;</a></p>
<h3 id="3-2-1-Markdown-文档加载器"><a href="#3-2-1-Markdown-文档加载器" class="headerlink" title="3.2.1 Markdown 文档加载器"></a>3.2.1 Markdown 文档加载器</h3><p>LangChain 中封装了一个 UnstructuredMarkdownLoader 对象，要使用这个加载器，必须安装 unstructured 包，安装命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install unstructured</span><br></pre></td></tr></table></figure>

<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line">  </span><br><span class="line">loader = UnstructuredMarkdownLoader(<span class="string">&quot;./项目API资料.md&quot;</span>)  </span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  </span><br><span class="line"><span class="built_in">print</span>(documents[<span class="number">0</span>].metadata)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-Office-文档加载器"><a href="#3-2-2-Office-文档加载器" class="headerlink" title="3.2.2 Office 文档加载器"></a>3.2.2 Office 文档加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> (  </span><br><span class="line">    UnstructuredPowerPointLoader,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># excel_loader = UnstructuredExcelLoader(&quot;./员工考勤表.xlsx&quot;, mode=&quot;elements&quot;)  </span></span><br><span class="line"><span class="comment"># excel_documents = excel_loader.load()  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># word_loader = UnstructuredWordDocumentLoader(&quot;./喵喵.docx&quot;)  </span></span><br><span class="line"><span class="comment"># documents = word_loader.load()  </span></span><br><span class="line">  </span><br><span class="line">ppt_loader = UnstructuredPowerPointLoader(<span class="string">&quot;./章节介绍.pptx&quot;</span>)  </span><br><span class="line">documents = ppt_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  </span><br><span class="line"><span class="built_in">print</span>(documents[<span class="number">0</span>].metadata)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-通用文档加载器"><a href="#3-2-3-通用文档加载器" class="headerlink" title="3.2.3 通用文档加载器"></a>3.2.3 通用文档加载器</h3><p>在实际的 LLM 应用开发中，由于数据的种类是无穷的，没办法单独为每一种数据配置一个加载器（也不现实），所以对于一些无法判断的数据类型或者想进行通用性文件加载，可以统一使用非结构化文件加载器 UnstructuredFileLoader 来实现对文件的加载。</p>
<p>UnstructuredFileLoader 是所有 UnstructuredXxxLoader 文档类的基类，其核心是将文档划分为元素，当传递一个文件时，库将读取文档，将其分割为多个部分，对这些部分进行分类，然后提取每个部分的文本，然后根据模式决定是否合并（single、paged、elements）。<br>一个 UnstructuredFileLoader 可以加载多种类型的文件，涵盖了：文本文件、PowerPoint 文件、HTML、PDF、图像、Markdown、Excel、Word 等</p>
<p>例如通过检测文件的扩展名来加载不同的文件加载器，对于没校验到的文件类型，才考虑使用 UnstructuredFileLoader，如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> file_extension <span class="keyword">in</span> [<span class="string">&quot;.xlsx&quot;</span>, <span class="string">&quot;.xls&quot;</span>]:</span><br><span class="line">    loader = UnstructuredExcelLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension == <span class="string">&quot;.pdf&quot;</span>:</span><br><span class="line">    loader = UnstructuredPDFLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension <span class="keyword">in</span> [<span class="string">&quot;.md&quot;</span>, <span class="string">&quot;.markdown&quot;</span>]:</span><br><span class="line">    loader = UnstructuredMarkdownLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension <span class="keyword">in</span> [<span class="string">&quot;.htm&quot;</span>, <span class="string">&quot;html&quot;</span>]:</span><br><span class="line">    loader = UnstructuredHTMLLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension <span class="keyword">in</span> [<span class="string">&quot;.docx&quot;</span>, <span class="string">&quot;.doc&quot;</span>]:</span><br><span class="line">    loader = UnstructuredWordDocumentLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension == <span class="string">&quot;.csv&quot;</span>:</span><br><span class="line">    loader = UnstructuredCSVLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension <span class="keyword">in</span> [<span class="string">&quot;.ppt&quot;</span>, <span class="string">&quot;.pptx&quot;</span>]:</span><br><span class="line">    loader = UnstructuredPowerPointLoader(file_path)</span><br><span class="line"><span class="keyword">elif</span> file_extension == <span class="string">&quot;.xml&quot;</span>:</span><br><span class="line">    loader = UnstructuredXMLLoader(file_path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loader = UnstructuredFileLoader(file_path) <span class="keyword">if</span> is_unstructured <span class="keyword">else</span> TextLoader(file_path)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4-自定义文档加载器"><a href="#3-2-4-自定义文档加载器" class="headerlink" title="3.2.4 自定义文档加载器"></a>3.2.4 自定义文档加载器</h3><p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Iterator, AsyncIterator  </span><br><span class="line"><span class="keyword">from</span> langchain_core.document_loaders <span class="keyword">import</span> BaseLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDocumentLoader</span>(<span class="title class_ inherited__">BaseLoader</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义文档加载器，将文本文件的每一行都解析成Document&quot;&quot;&quot;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, file_path: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:  </span><br><span class="line">        self.file_path = file_path  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lazy_load</span>(<span class="params">self</span>) -&gt; Iterator[Document]:  </span><br><span class="line">        <span class="comment"># 1.读取对应的文件  </span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(self.file_path, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">            line_number = <span class="number">0</span>  </span><br><span class="line">            <span class="comment"># 2.提取文件的每一行  </span></span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:  </span><br><span class="line">                <span class="comment"># 3.将每一行生成一个Document实例并通过yield返回  </span></span><br><span class="line">                <span class="keyword">yield</span> Document(  </span><br><span class="line">                    page_content=line,  </span><br><span class="line">                    metadata=&#123;<span class="string">&quot;score&quot;</span>: self.file_path, <span class="string">&quot;line_number&quot;</span>: line_number&#125;  </span><br><span class="line">                )  </span><br><span class="line">                line_number += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">alazy_load</span>(<span class="params">self</span>) -&gt; AsyncIterator[Document]:  </span><br><span class="line">        <span class="keyword">import</span> aiofiles  </span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> aiofiles.<span class="built_in">open</span>(self.file_path, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">            line_number = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> line <span class="keyword">in</span> f:  </span><br><span class="line">                <span class="keyword">yield</span> Document(  </span><br><span class="line">                    page_content=line,  </span><br><span class="line">                    metadata=&#123;<span class="string">&quot;score&quot;</span>: self.file_path, <span class="string">&quot;line_number&quot;</span>: line_number&#125;  </span><br><span class="line">                )  </span><br><span class="line">                line_number += <span class="number">1</span>  </span><br><span class="line">    </span><br><span class="line">loader = CustomDocumentLoader(<span class="string">&quot;./喵喵.txt&quot;</span>)  </span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  </span><br><span class="line"><span class="built_in">print</span>(documents[<span class="number">0</span>].metadata)</span><br></pre></td></tr></table></figure>

<p>lazy_load() 方法的两个核心步骤就是：读取文件数据、将文件数据解析成Document，并且绝大部分文档加载器都有着两个核心步骤，而且 读取文件数据 这个步骤大家都大差不差。</p>
<p>就像 <code>*.md、*.txt、*.py</code> 这类文本文件，甚至是 <code>*.pdf、*.doc</code> 等这类非文本文件，都可以使用同一个 读取文件数据 步骤将文件读取为 二进制内容，然后在使用不同的解析逻辑来解析对应的二进制内容，所以很容易可以得出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">文档加载器 = 二进制数据读取 + 解析逻辑</span><br></pre></td></tr></table></figure>
<p>因此，在项目开发中，如果大量配置自定义文档解析器的话，将解析逻辑与加载逻辑分离，维护起来会更容易，而且也更容易复用相应的逻辑（具体使用哪种方式取决于开发）。</p>
<p>这样原先的 DocumentLoader 运行流程就变成了如下：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430100854.png" alt="image.png"></p>
<h1 id="4-文本分割器"><a href="#4-文本分割器" class="headerlink" title="4 文本分割器"></a>4 文本分割器</h1><h2 id="4-1-DocumentTransformer-组件"><a href="#4-1-DocumentTransformer-组件" class="headerlink" title="4.1 DocumentTransformer 组件"></a>4.1 DocumentTransformer 组件</h2><p>在 LangChain 中针对文档的转换也统一封装了一个基类 BaseDocumentTransformer，<strong>所有涉及到文档的转换的类均是该类的子类</strong>，将大块文档切割成 chunk 分块的文档分割器也是 BaseDocumentTransformer 的子类实现。</p>
<p>BaseDocumentTransformer 基类封装了两个方法：<br>1. transform_documents()：抽象方法，传递文档列表，返回转换后的文档列表。<br>2. atransform_documents()：转换文档列表函数的异步实现，如果没有实现，则会委托 transform_documents() 函数实现。</p>
<p>在 LangChain 中，文档转换组件分成了两类：文档分割器(使用频率高)、文档处理转换器(使用频率低，老版本写法)。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -qU langchain-text-splitters</span><br></pre></td></tr></table></figure>
<h2 id="4-2-字符分割器"><a href="#4-2-字符分割器" class="headerlink" title="4.2 字符分割器"></a>4.2 字符分割器</h2><p>在文档分割器中，最简单的分割器就是——<strong>字符串分割器</strong>，这个组件会基于给定的字符串进行分割，默认为 \n\n，并且在分割时会尽可能保证数据的连续性。分割出来每一块的长度是通过字符数来衡量的，使用起来也非常简单，实例化 CharacterTextSplitter 需传递多个参数，信息如下：</p>
<p>1. separator：分隔符，默认为 <code>\n\n</code>。<br>2. is_separator_regex：是否正则表达式，默认为 False。<br>3. chunk_size：每块文档的内容大小，默认为 4000。<br>4. chunk_overlap：块与块之间重叠的内容大小，默认为 200。<br>5. length_function：计算文本长度的函数，默认为 len。<br>6. keep_separator：是否将分隔符保留到分割的块中，默认为 False。<br>7. add_start_index：是否添加开始索引，默认为 False，如果是的话会在元数据中添加该切块的起点。<br>8. strip_whitespace：是否删除文档头尾的空白，默认为 True。</p>
<p>如果想将文档切割为不超过 500 字符，并且每块之间文本重叠 50 个字符，可以使用 CharacterTextSplitter 来实现，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.加载对应的文档  </span></span><br><span class="line">loader = UnstructuredMarkdownLoader(<span class="string">&quot;./项目API文档.md&quot;</span>)  </span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.创建文本分割器  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(  </span><br><span class="line">    separator=<span class="string">&quot;\n\n&quot;</span>,  </span><br><span class="line">    chunk_size=<span class="number">500</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">50</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.分割文本  </span></span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块大小:<span class="subst">&#123;<span class="built_in">len</span>(chunk.page_content)&#125;</span>, 元数据:<span class="subst">&#123;chunk.metadata&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(chunks))</span><br></pre></td></tr></table></figure>

<h2 id="4-3-递归字符文本分割器"><a href="#4-3-递归字符文本分割器" class="headerlink" title="4.3 递归字符文本分割器"></a>4.3 递归字符文本分割器</h2><p>普通的字符文本分割器只能使用单个分隔符对文本内容进行划分，在划分的过程中，可能会出现文档块 过小 或者 过大 的情况，这会让 RAG 变得不可控，例如：<br>1. <strong>文档块可能会变得非常大</strong>，极端的情况下某个块的内容长度可能就超过了 LLM 的上下文长度限制，这样这个文本块永远不会被引用到，相当于存储了数据，但是数据又丢失了。<br>2. <strong>文档块可能会远远小于窗口大小</strong>，导致文档块的信息密度太低，块内容即使填充到 Prompt 中，LLM 也无法提取出有用的信息。</p>
<p>RecursiveCharacterTextSplitter，即<strong>递归字符串分割</strong>，这个分割器可以传递 一组分隔符 和 设定块内容大小，根据分隔符的优先顺序对文本进行预分割，然后将小块进行合并，将大块进行递归分割，直到获得所需块的大小，最终这些文档块的大小并不能完全相同，但是仍然会逼近指定长度。<br>RecursiveCharacterTextSplitter 的分隔符参数默认为 <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;]</code>，即优先使用换两行的数据进行分割，然后在使用单个换行符，如果块内容还是太大，则使用空格，最后再拆分成单个字符。<br>所以如果使用默认参数，这个字符文本分割器最后得到的文档块长度一定不会超过预设的大小，但是仍然会有小概率出现远小于的情况（目前也没有很好的解决方案）。</p>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line">loader = UnstructuredMarkdownLoader(<span class="string">&quot;./项目API文档.md&quot;</span>)  </span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">500</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">50</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块大小: <span class="subst">&#123;<span class="built_in">len</span>(chunk.page_content)&#125;</span>, 元数据: <span class="subst">&#123;chunk.metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430102610.png" alt="image.png"></p>
<h2 id="4-4-语义文档分割器"><a href="#4-4-语义文档分割器" class="headerlink" title="4.4 语义文档分割器"></a>4.4 语义文档分割器</h2><p>语义相似性分割器，SemanticChunker 在使用上和其他的文档分割器存在一些差异，并且该类并没有继承 TextSplitter，实例化参数含义如下：</p>
<p>1. embeddings：文本嵌入模型，在该分类器底层使用向量的 余弦相似度 来识别语句之间的相似性。<br>2. buffer_size：文本缓冲区大小，默认为 1，即在计算相似性时，该文本会叠加前后各 1 条文本，如果不够则不叠加（例如第 1 条和最后 1 条）。<br>3. add_start_index：是否添加起点索引，默认为 False。<br>4. breakpoint_threshold_type：断点阈值类型，默认为 percentile 即百分位<br>5. breakpoint_threshold_amount：断点阈值金额&#x2F;得分。<br>6. number_of_chunks：分割后的文档块个数，默认为 None。<br>7. sentence_split_regex：句子切割正则，默认为 <code>(?&lt;=[.?!])\s+</code>，即以英文的点、问号、感叹号切割语句，不同的文档需要传递不同的切割正则表达式。</p>
<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredFileLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_experimental.text_splitter <span class="keyword">import</span> SemanticChunker  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建加载器和文本分割器  </span></span><br><span class="line">loader = UnstructuredFileLoader(<span class="string">&quot;./科幻短篇.txt&quot;</span>)  </span><br><span class="line">text_splitter = SemanticChunker(  </span><br><span class="line">    embeddings=OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>),  </span><br><span class="line">    number_of_chunks=<span class="number">10</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">    sentence_split_regex=<span class="string">r&quot;(?&lt;=[。？！.?!])&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.加载文本与分割  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.循环打印  </span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块大小: <span class="subst">&#123;<span class="built_in">len</span>(chunk.page_content)&#125;</span>, 元数据: <span class="subst">&#123;chunk.metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-5-自定义文档分割器"><a href="#4-5-自定义文档分割器" class="headerlink" title="4.5 自定义文档分割器"></a>4.5 自定义文档分割器</h2><p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> jieba.analyse  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredFileLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> TextSplitter  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomTextSplitter</span>(<span class="title class_ inherited__">TextSplitter</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义文本分割器&quot;&quot;&quot;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, seperator: <span class="built_in">str</span>, top_k: <span class="built_in">int</span> = <span class="number">10</span>, **kwargs</span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;构造函数，传递分割器还有需要提取的关键词数，默认为10&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)  </span><br><span class="line">        self._seperator = seperator  </span><br><span class="line">        self._top_k = top_k  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split_text</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;传递对应的文本执行分割并提取分割数据的关键词，组成文档列表返回&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="comment"># 1.根据传递的分隔符分割传入的文本  </span></span><br><span class="line">        split_texts = text.split(self._seperator)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.提取分割出来的每一段文本的关键词，数量为self._top_k个  </span></span><br><span class="line">        text_keywords = []  </span><br><span class="line">        <span class="keyword">for</span> split_text <span class="keyword">in</span> split_texts:  </span><br><span class="line">            text_keywords.append(jieba.analyse.extract_tags(split_text, self._top_k))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 3.将关键词使用逗号进行拼接组成字符串列表并返回  </span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&quot;,&quot;</span>.join(keywords) <span class="keyword">for</span> keywords <span class="keyword">in</span> text_keywords]  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.创建加载器与分割器  </span></span><br><span class="line">loader = UnstructuredFileLoader(<span class="string">&quot;./科幻短篇.txt&quot;</span>)  </span><br><span class="line">text_splitter = CustomTextSplitter(<span class="string">&quot;\n\n&quot;</span>, <span class="number">10</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.加载文档并分割  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.循环遍历文档信息  </span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:  </span><br><span class="line">    <span class="built_in">print</span>(chunk.page_content)</span><br></pre></td></tr></table></figure>
<h2 id="4-6-非分割类型的文档分割器"><a href="#4-6-非分割类型的文档分割器" class="headerlink" title="4.6 非分割类型的文档分割器"></a>4.6 非分割类型的文档分割器</h2><p>在 LangChain 中，还存在另一种非分割类型的文档转换器，这类转换器也是传递 文档列表 并返回 文档列表，一般是将某种文档按照需求转换成另外一种格式（例如：<strong>翻译文档、文档重排、HTML 转文本、文档元数据提取、文档转问答</strong>等）</p>
<h3 id="4-6-1-问答转换器"><a href="#4-6-1-问答转换器" class="headerlink" title="4.6.1 问答转换器"></a>4.6.1 问答转换器</h3><p>在 RAG 的外挂知识库中，向量存储知识库中使用的文档通常以叙述或对话格式存储。但是，绝大部分用户的查询都是问题格式，所以如果我们在对文档进行向量化之前先将其转换为 问答格式，可以在一定程度上增加检索相关文档的可能性，降低检索不相关文档的可能性。</p>
<p>这个技巧也是 RAG 应用开发中常见的一种优化策略，即将原始数据转换成 QA 数据后进行存储，除此之外，对于绝大部分 LLM 的微调，使用的也是 QA问答数据 也可以考虑使用该问答转换器进行转换。</p>
<p>在 LangChain 中封装了 Doctran 库并实现了 DoctranQATransformer 类可以快捷实现该功能，这个库底层使用 OpenAI 的函数回调来实现对问答数据的提取，首先安装该库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U doctran</span><br></pre></td></tr></table></figure>

<p><strong>代码示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> doctran <span class="keyword">import</span> Doctran  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_transformers <span class="keyword">import</span> DoctranQATransformer  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line">  </span><br><span class="line">_ = Doctran  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建文档列表  </span></span><br><span class="line">page_content = <span class="string">&quot;&quot;&quot;机密文件 - 仅供内部使用  </span></span><br><span class="line"><span class="string">日期：2023年7月1日  </span></span><br><span class="line"><span class="string">主题：各种话题的更新和讨论  </span></span><br><span class="line"><span class="string">亲爱的团队，  </span></span><br><span class="line"><span class="string">希望这封邮件能找到你们一切安好。在这份文件中，我想向你们提供一些重要的更新，并讨论需要我们关注的各种话题。请将此处包含的信息视为高度机密。  </span></span><br><span class="line"><span class="string">安全和隐私措施  </span></span><br><span class="line"><span class="string">作为我们不断致力于确保客户数据安全和隐私的一部分，我们已在所有系统中实施了强有力的措施。我们要赞扬IT部门的John Doe（电子邮件：john.doe@example.com）在增强我们网络安全方面的勤奋工作。未来，我们提醒每个人严格遵守我们的数据保护政策和准则。此外，如果您发现任何潜在的安全风险或事件，请立即向我们专门的团队报告，联系邮箱为security@example.com。  </span></span><br><span class="line"><span class="string">人力资源更新和员工福利  </span></span><br><span class="line"><span class="string">最近，我们迎来了几位为各自部门做出重大贡献的新团队成员。我要表扬Jane Smith（社保号：049-45-5928）在客户服务方面的出色表现。Jane一直受到客户的积极反馈。此外，请记住我们的员工福利计划的开放报名期即将到来。如果您有任何问题或需要帮助，请联系我们的人力资源代表Michael Johnson（电话：418-492-3850，电子邮件：michael.johnson@example.com）。  </span></span><br><span class="line"><span class="string">营销倡议和活动  </span></span><br><span class="line"><span class="string">我们的营销团队一直在积极制定新策略，以提高品牌知名度并推动客户参与。我们要感谢Sarah Thompson（电话：415-555-1234）在管理我们的社交媒体平台方面的杰出努力。Sarah在过去一个月内成功将我们的关注者基数增加了20%。此外，请记住7月15日即将举行的产品发布活动。我们鼓励所有团队成员参加并支持我们公司的这一重要里程碑。  </span></span><br><span class="line"><span class="string">研发项目  </span></span><br><span class="line"><span class="string">在追求创新的过程中，我们的研发部门一直在为各种项目不懈努力。我要赞扬David Rodriguez（电子邮件：david.rodriguez@example.com）在项目负责人角色中的杰出工作。David对我们尖端技术的发展做出了重要贡献。此外，我们希望每个人在7月10日定期举行的研发头脑风暴会议上分享他们的想法和建议，以开展潜在的新项目。  </span></span><br><span class="line"><span class="string">请将此文档中的信息视为最机密，并确保不与未经授权的人员分享。如果您对讨论的话题有任何疑问或顾虑，请随时直接联系我。  </span></span><br><span class="line"><span class="string">感谢您的关注，让我们继续共同努力实现我们的目标。  </span></span><br><span class="line"><span class="string">此致，  </span></span><br><span class="line"><span class="string">Jason Fan  </span></span><br><span class="line"><span class="string">联合创始人兼首席执行官  </span></span><br><span class="line"><span class="string">Psychic  </span></span><br><span class="line"><span class="string">jason@psychic.dev&quot;&quot;&quot;</span>  </span><br><span class="line">documents = [Document(page_content=page_content)]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.构建问答转换器并转换  </span></span><br><span class="line">qa_transformer = DoctranQATransformer(openai_api_model=<span class="string">&quot;gpt-3.5-turbo-16k&quot;</span>)  </span><br><span class="line">transformer_documents = qa_transformer.transform_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.输出内容  </span></span><br><span class="line"><span class="keyword">for</span> qa <span class="keyword">in</span> transformer_documents[<span class="number">0</span>].metadata.get(<span class="string">&quot;questions_and_answers&quot;</span>):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;问答数据:&quot;</span>, qa)</span><br></pre></td></tr></table></figure>
<p><strong>输出内容：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;文件日期是什么？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;2023年7月1日&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;文件主题是什么？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;各种话题的更新和讨论&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;谁是IT部门的网络安全负责人？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;John Doe（电子邮件：john.doe@example.com）&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;如果发现安全风险或事件，应该向谁报告？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;专门的团队，联系邮箱为security@example.com&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;谁在客户服务方面表现出色？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Jane Smith（社保号：049-45-5928）&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;员工福利计划的开放报名期是什么时候？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;即将到来&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;人力资源代表的联系信息是什么？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Michael Johnson（电话：418-492-3850，电子邮件：michael.johnson@example.com）&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;谁在管理社交媒体平台方面做出了杰出努力？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Sarah Thompson（电话：415-555-1234）&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;产品发布活动的日期是什么时候？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;7月15日&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;谁在研发部门担任项目负责人角色？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;David Rodriguez（电子邮件：david.rodriguez@example.com）&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;研发头脑风暴会议的日期是什么时候？&#x27;</span>, <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;7月10日&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-6-2-翻译转换器"><a href="#4-6-2-翻译转换器" class="headerlink" title="4.6.2 翻译转换器"></a>4.6.2 翻译转换器</h3><p>在 RAG 应用开发中，将文档通过嵌入&#x2F;向量的方式进行比较的好处在于能跨语言工作，例如：你好，世界！、Hello, World! 和 こんにちは、世界！ 分别是 中英日 三国的语言，但是因为语义相近，所以在向量空间中的位置也是非常接近的。</p>
<p>当一个 RAG 应用需要跨语言工作时，一般有两种策略：<br>1. 在将文档切块并嵌入存储到向量数据库时，同时将文档翻译成多国语言并进行相同的操作。<br>2. 在进行检索操作时，将检索出来的文档执行翻译功能，然后使用翻译后的文档。<br>这两种策略都涉及到一个功能，就是 文档的翻译，或者是说将 文档 转换成另外一种形式的 文档，这类操作其实和 文档转换器 的作用一模一样，所以可以考虑使用该组件来实现这个功能，LangChain 中针对翻译的转换器就提供了不少，例如 Doctran。</p>
<h1 id="5-文档检索器"><a href="#5-文档检索器" class="headerlink" title="5 文档检索器"></a>5 文档检索器</h1><h2 id="5-1-带得分阈值的相似性搜索"><a href="#5-1-带得分阈值的相似性搜索" class="headerlink" title="5.1 带得分阈值的相似性搜索"></a>5.1 带得分阈值的相似性搜索</h2><p>在 LangChain 的相似性搜索中，无论结果多不匹配，只要向量数据库中存在数据，一定会查找出相应的结果，在 RAG 应用开发中，一般是将高相似文档插入到 Prompt 中，所以可以考虑添加一个 相似性得分阈值，超过该数值的部分才等同于有相似性。<br>在 similarity_search_with_relevance_scores() 函数中，可以传递 score_threshold 阈值参数，过滤低于该得分的文档。<br>例如没有添加阈值检索 我养了一只猫，叫笨笨，示例与输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">embedding = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">documents = [  </span><br><span class="line">    Document(page_content=<span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">1</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">2</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">3</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">4</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">5</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">6</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">7</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">8</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">9</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">10</span>&#125;),  </span><br><span class="line">]  </span><br><span class="line">db = FAISS.from_documents(documents, embedding)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(db.similarity_search_with_relevance_scores(<span class="string">&quot;我养了一只猫，叫笨笨&quot;</span>, score_threshold=<span class="number">0.4</span>))</span><br></pre></td></tr></table></figure>

<h2 id="5-2-as-retriever-检索器"><a href="#5-2-as-retriever-检索器" class="headerlink" title="5.2 as_retriever() 检索器"></a>5.2 as_retriever() 检索器</h2><p>在 LangChain 中，VectorStore 可以通过 as_retriever() 方法转换成检索器，在 as_retriever() 中可以传递一下参数：</p>
<p>1. search_type：搜索类型，支持 similarity(基础相似性搜索)、similarity_score_threshold(携带相似性得分+阈值判断的相似性搜索)、mmr(最大边际相关性搜索)。<br>2. search_kwargs：其他键值对搜索参数，类型为字典，例如：k、filter、score_threshold、fetch_k、lambda_mult 等，当搜索类型配置为 similarity_score_threshold 后，必须添加 score_threshold 配置选项，否则会报错，参数的具体信息要看 search_type 类型对应的函数配合使用。</p>
<p>并且由于检索器是 Runnable 可运行组件，所以可以使用 Runnable 组件的所有功能（组件替换、参数配置、重试、回退、并行等）。</p>
<p>例如将向量数据库转换成 携带得分+阈值判断的相似性搜索，并设置得分阈值为0.5，数据条数为10条，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">import</span> weaviate  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> langchain_weaviate <span class="keyword">import</span> WeaviateVectorStore  </span><br><span class="line"><span class="keyword">from</span> weaviate.auth <span class="keyword">import</span> AuthApiKey  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建加载器与分割器  </span></span><br><span class="line">loader = UnstructuredMarkdownLoader(<span class="string">&quot;./项目API文档.md&quot;</span>)  </span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot;。|！|？&quot;</span>, <span class="string">&quot;\.\s|\!\s|\?\s&quot;</span>, <span class="string">&quot;；|;\s&quot;</span>, <span class="string">&quot;，|,\s&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>, ],  </span><br><span class="line">    is_separator_regex=<span class="literal">True</span>,  </span><br><span class="line">    chunk_size=<span class="number">500</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">50</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.加载文档并分割  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.将数据存储到向量数据库  </span></span><br><span class="line">db = WeaviateVectorStore(  </span><br><span class="line">    client=weaviate.connect_to_wcs(  </span><br><span class="line">        cluster_url=<span class="string">&quot;https://eftofnujtxqcsa0sn272jw.c0.us-west3.gcp.weaviate.cloud&quot;</span>,  </span><br><span class="line">        auth_credentials=AuthApiKey(<span class="string">&quot;21pzYy0orl2dxH9xCoZG1O2b0euDeKJNEbB0&quot;</span>),  </span><br><span class="line">    ),  </span><br><span class="line">    index_name=<span class="string">&quot;DatasetDemo&quot;</span>,  </span><br><span class="line">    text_key=<span class="string">&quot;text&quot;</span>,  </span><br><span class="line">    embedding=OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>),  </span><br><span class="line">)  </span><br><span class="line">db.add_documents(chunks)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.转换检索器（带阈值的相似性搜索，数据为10条，得分阈值为0.5）  </span></span><br><span class="line">retriever = db.as_retriever(  </span><br><span class="line">    search_type=<span class="string">&quot;similarity_score_threshold&quot;</span>,  </span><br><span class="line">    search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">10</span>, <span class="string">&quot;score_threshold&quot;</span>: <span class="number">0.5</span>&#125;,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.检索结果  </span></span><br><span class="line">documents = retriever.invoke(<span class="string">&quot;关于配置接口的信息有哪些&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(document.page_content[:<span class="number">50</span>] <span class="keyword">for</span> document <span class="keyword">in</span> documents))  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))</span><br></pre></td></tr></table></figure>

<h2 id="5-3-MMR-最大边际相关性"><a href="#5-3-MMR-最大边际相关性" class="headerlink" title="5.3 MMR 最大边际相关性"></a>5.3 MMR 最大边际相关性</h2><p>最大边际相关性（MMR，max_marginal_relevance_search）的基本思想是同时考量查询与文档的 相关度，以及文档之间的 相似度。相关度 确保返回结果对查询高度相关，相似度 则鼓励不同语义的文档被包含进结果集。具体来说，它计算每个候选文档与查询的 相关度，并减去与已经入选结果集的文档的最大 相似度，这样更不相似的文档会有更高分。</p>
<p>而在 LangChain 中MMR 的实现过程和 FAISS 的 带过滤器的相似性搜索 非常接近，同样也是先执行相似性搜索，并得到一个远大于 k 的结果列表，例如 fetch_k 条数据，然后对搜索得到的 fetch_k 条数据计算文档之间的相似度，通过加权得分找到最终的 k 条数据。</p>
<p>简单来说，MMR 就是在一大堆最相似的文档中查找最不相似的，从而保证 结果多样化。</p>
<p>执行一个 MMR 最大边际相似性搜索需要的参数为：搜索语句、k条搜索结果数据、fetch_k条中间数据、多样性系数(0代表最大多样性，1代表最小多样性)，在 LangChain 中也是基于这个思想进行封装，max_marginal_relevance_search() 函数的参数如下：</p>
<p>1. query：搜索语句，类型为字符串，必填参数。<br>2. k：搜索的结果条数，类型为整型，默认为 4。<br>3. fetch_k：要传递给 MMR 算法的的文档数，默认为 20。<br>4. lambda_mult：函数系数，数值范围从0-1，<code>底层计算得分 = lambda_mult *相关性 - (1 - lambda_mult)*相似性</code>，所以 0 代表最大多样性、1 代表最小多样性。<br>5. kwargs：其他传递给搜索方法的参数，例如 filter 等，这个参数使用和相似性搜索类似，具体取决于使用的向量数据库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">import</span> weaviate  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> langchain_weaviate <span class="keyword">import</span> WeaviateVectorStore  </span><br><span class="line"><span class="keyword">from</span> weaviate.auth <span class="keyword">import</span> AuthApiKey  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建加载器与分割器  </span></span><br><span class="line">loader = UnstructuredMarkdownLoader(<span class="string">&quot;./项目API文档.md&quot;</span>)  </span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot;。|！|？&quot;</span>, <span class="string">&quot;\.\s|\!\s|\?\s&quot;</span>, <span class="string">&quot;；|;\s&quot;</span>, <span class="string">&quot;，|,\s&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>, ],  </span><br><span class="line">    is_separator_regex=<span class="literal">True</span>,  </span><br><span class="line">    chunk_size=<span class="number">500</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">50</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.加载文档并分割  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">chunks = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.将数据存储到向量数据库  </span></span><br><span class="line">db = WeaviateVectorStore(  </span><br><span class="line">    client=weaviate.connect_to_wcs(  </span><br><span class="line">        cluster_url=<span class="string">&quot;https://eftofnujtxqcsa0sn272jw.c0.us-west3.gcp.weaviate.cloud&quot;</span>,  </span><br><span class="line">        auth_credentials=AuthApiKey(<span class="string">&quot;21pzYy0orl2dxH9xCoZG1O2b0euDeKJNEbB0&quot;</span>),  </span><br><span class="line">    ),  </span><br><span class="line">    index_name=<span class="string">&quot;DatasetDemo&quot;</span>,  </span><br><span class="line">    text_key=<span class="string">&quot;text&quot;</span>,  </span><br><span class="line">    embedding=OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>),  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.执行最大边际相关性搜索（可以去除重复数据）  </span></span><br><span class="line"><span class="comment"># search_documents = db.similarity_search(&quot;关于应用配置的接口有哪些？&quot;)  # 会查到重复数据  </span></span><br><span class="line">search_documents = db.max_marginal_relevance_search(<span class="string">&quot;关于应用配置的接口有哪些？&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.打印搜索的结果  </span></span><br><span class="line"><span class="comment"># print(list(document.page_content[:100] for document in search_documents))  </span></span><br><span class="line"><span class="keyword">for</span> document <span class="keyword">in</span> search_documents:  </span><br><span class="line">    <span class="built_in">print</span>(document.page_content[:<span class="number">100</span>])  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===========&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="5-4-检索器组件"><a href="#5-4-检索器组件" class="headerlink" title="5.4 检索器组件"></a>5.4 检索器组件</h2><p>在 LangChain 中，传递一段 query 并返回与这段文本相关联文档的组件被称为 检索器，并且 LangChain 为所有检索器设计了一个基类——BaseRetriever，该类继承了 RunnableSerializable，所以该类是一个 Runnable 可运行组件，支持使用 Runnable 组件的所有配置，在 BaseRetriever 下封装了一些通用的方法，类图如下<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430104950.png" alt="image.png"></p>
<p>其中 get_relevance_documents() 方法将在 0.3.0 版本开始被遗弃（老版本非 Runnable 写法），使用检索器的技巧也非常简单，按照特定的规则创建好检索器后（通过 as_retriever() 或者 构造函数），调用 invoke() 方法即可。</p>
<p>并且针对所有 向量数据库，LangChain 都配置了 as_retriever() 方法，便于快捷将向量数据库转换成检索器，不同的检索器传递的参数会有所差异，需要查看源码或者查看文档搭配使用，例如下方是一个向量数据库检索器的使用示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line"><span class="keyword">import</span> weaviate  </span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> ConfigurableField  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_weaviate <span class="keyword">import</span> WeaviateVectorStore  </span><br><span class="line"><span class="keyword">from</span> weaviate.auth <span class="keyword">import</span> AuthApiKey  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.构建向量数据库  </span></span><br><span class="line">db = WeaviateVectorStore(  </span><br><span class="line">    client=weaviate.connect_to_wcs(  </span><br><span class="line">        cluster_url=<span class="string">&quot;https://eftofnujtxqcsa0sn272jw.c0.us-west3.gcp.weaviate.cloud&quot;</span>,  </span><br><span class="line">        auth_credentials=AuthApiKey(<span class="string">&quot;21pzYy0orl2dxH9xCoZG1O2b0euDeKJNEbB0&quot;</span>),  </span><br><span class="line">    ),  </span><br><span class="line">    index_name=<span class="string">&quot;DatasetDemo&quot;</span>,  </span><br><span class="line">    text_key=<span class="string">&quot;text&quot;</span>,  </span><br><span class="line">    embedding=OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-3-small&quot;</span>),  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.转换检索器  </span></span><br><span class="line">retriever = db.as_retriever(  </span><br><span class="line">    search_type=<span class="string">&quot;similarity_score_threshold&quot;</span>,  </span><br><span class="line">    search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">10</span>, <span class="string">&quot;score_threshold&quot;</span>: <span class="number">0.5</span>&#125;,  </span><br><span class="line">).configurable_fields(  </span><br><span class="line">    search_type=ConfigurableField(<span class="built_in">id</span>=<span class="string">&quot;db_search_type&quot;</span>),  </span><br><span class="line">    search_kwargs=ConfigurableField(<span class="built_in">id</span>=<span class="string">&quot;db_search_kwargs&quot;</span>),  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.修改运行时配置执行MMR搜索，并返回4条数据  </span></span><br><span class="line">mmr_documents = retriever.with_config(  </span><br><span class="line">    configurable=&#123;  </span><br><span class="line">        <span class="string">&quot;db_search_type&quot;</span>: <span class="string">&quot;mmr&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;db_search_kwargs&quot;</span>: &#123;  </span><br><span class="line">            <span class="string">&quot;k&quot;</span>: <span class="number">4</span>,  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">).invoke(<span class="string">&quot;关于应用配置的接口有哪些？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;相似性搜索: &quot;</span>, mmr_documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;内容长度:&quot;</span>, <span class="built_in">len</span>(mmr_documents))  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(mmr_documents[<span class="number">0</span>].page_content[:<span class="number">20</span>])  </span><br><span class="line"><span class="built_in">print</span>(mmr_documents[<span class="number">1</span>].page_content[:<span class="number">20</span>])</span><br></pre></td></tr></table></figure>

<h2 id="5-5-自定义检索器"><a href="#5-5-自定义检索器" class="headerlink" title="5.5 自定义检索器"></a>5.5 自定义检索器</h2><p>在 LangChain 中实现自定义检索器的技巧其实非常简单，只需要继承 BaseRetriever 类，然后实现 <code>_get_relevant_documents()</code> 方法即可，从 query 到 <code>list[document]</code> 的逻辑全部都在这个函数内部实现，异步的方法也可以不需要实现，底层会委托同步方法来执行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">from</span> langchain_core.callbacks <span class="keyword">import</span> CallbackManagerForRetrieverRun  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line"><span class="keyword">from</span> langchain_core.retrievers <span class="keyword">import</span> BaseRetriever  </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRetriever</span>(<span class="title class_ inherited__">BaseRetriever</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义检索器&quot;&quot;&quot;</span>  </span><br><span class="line">    documents: <span class="built_in">list</span>[Document]  </span><br><span class="line">    k: <span class="built_in">int</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_relevant_documents</span>(<span class="params">self, query: <span class="built_in">str</span>, *, run_manager: CallbackManagerForRetrieverRun</span>) -&gt; <span class="type">List</span>[Document]:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;根据传入的query，获取相关联的文档列表&quot;&quot;&quot;</span>  </span><br><span class="line">        matching_documents = []  </span><br><span class="line">        <span class="keyword">for</span> document <span class="keyword">in</span> self.documents:  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(matching_documents) &gt; self.k:  </span><br><span class="line">                <span class="keyword">return</span> matching_documents  </span><br><span class="line">            <span class="keyword">if</span> query.lower() <span class="keyword">in</span> document.page_content.lower():  </span><br><span class="line">                matching_documents.append(document)  </span><br><span class="line">        <span class="keyword">return</span> matching_documents  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 1.定义预设文档  </span></span><br><span class="line">documents = [  </span><br><span class="line">    Document(page_content=<span class="string">&quot;笨笨是一只很喜欢睡觉的猫咪&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">1</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我喜欢在夜晚听音乐，这让我感到放松。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">2</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;猫咪在窗台上打盹，看起来非常可爱。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">3</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;学习新技能是每个人都应该追求的目标。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">4</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我最喜欢的食物是意大利面，尤其是番茄酱的那种。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">5</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;昨晚我做了一个奇怪的梦，梦见自己在太空飞行。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">6</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我的手机突然关机了，让我有些焦虑。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">7</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;阅读是我每天都会做的事情，我觉得很充实。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">8</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;他们一起计划了一次周末的野餐，希望天气能好。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">9</span>&#125;),  </span><br><span class="line">    Document(page_content=<span class="string">&quot;我的狗喜欢追逐球，看起来非常开心。&quot;</span>, metadata=&#123;<span class="string">&quot;page&quot;</span>: <span class="number">10</span>&#125;),  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.创建检索器  </span></span><br><span class="line">retriever = CustomRetriever(documents=documents, k=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.调用检索器获取搜索结果并打印  </span></span><br><span class="line">retriever_documents = retriever.invoke(<span class="string">&quot;猫&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(retriever_documents)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(retriever_documents))</span><br></pre></td></tr></table></figure>

<h1 id="6-RAG-优化策略"><a href="#6-RAG-优化策略" class="headerlink" title="6 RAG 优化策略"></a>6 RAG 优化策略</h1><h3 id="6-1-RAG-开发6个阶段优化策略"><a href="#6-1-RAG-开发6个阶段优化策略" class="headerlink" title="6.1 RAG 开发6个阶段优化策略"></a>6.1 RAG 开发6个阶段优化策略</h3><p>在 RAG 应用开发中，无论架构多复杂，接入了多少组件，使用了多少优化策略与特性，所有优化的最终目标都是 提升LLM生成内容的准确性，而对于 Transformer架构类型 的大模型来说，要实现这个目标，一般只需要 3 个步骤：</p>
<p>1. 传递更准确的内容：传递和提问准确性更高的内容，会让 LLM 能识别到关联的内容， 生成的内容准确性更高。<br>2. 让重要的内容更靠前：GPT 模型的注意力机制会让传递 Prompt 中更靠前的内容权重更高，越靠后权重越低。<br>3. 尽可能不传递不相关内容：缩短每个块的大小，尽可能让每个块只包含关联的内容，缩小不相关内容的比例。</p>
<p>看起来很简单，但是目前针对这 3 个步骤 N 多研究员提出了不少方案，比较遗憾的是，目前也没有一种统一的方案，不同的场合仍然需要考虑不同的方案结合才能实现相对好一点的效果，并不是所有场合都适合配置很复杂的优化策略。</p>
<p>在 RAG 应用开发中，使用的优化策略越多，单次响应成本越高，性能越差，需要合理使用。映射到 RAG 中，其实就是 切割合适的文档块、更准确的搜索语句、正确地排序文档、剔除重复无关的检索内容，所以在 RAG应用开发 中，想进行优化，可以针对 query(提问查询)、TextSplitter(文本分割器)、VectorStore(向量数据库)、Retriever(检索器)、Prompt(基础prompt编写) 这几个组件。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430140325.png" alt="image.png"><br>在完整的 LLM 应用流程中拆解 RAG 开发阶段并进行优化看起来相对繁琐，可以考虑单独将 RAG 开发阶段的流程拎出来，并针对性对每个阶段进行优化与调整，按照不同的功能模块，共可以划分成 6 个阶段：查询转换、路由、查询构建、索引、检索 和 生成。</p>
<p>在 RAG 开发的 6 个阶段中，不同的阶段拥有不同的优化策略，需要针对不同的应用进行特定性的优化，目前市面上常见的优化方案有：问题转换、多路召回、混合检索、搜索重排、动态路由、图查询、问题重建、自检索 等数十种优化策略，每种策略所在的阶段并不一致，效果也有差异，并且相互影响。<br>并且 RAG 优化和 LangChain 并没有关系，无论使用任何框架、任何编程语言，进行 RAG 开发时，掌握优化的思路才是最重要的！<br>将对应的优化策略整理到 RAG 运行流程中，优化策略与开发阶段对应图如下：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/20250430140425.png" alt="image.png"></p>
<h2 id="6-2"><a href="#6-2" class="headerlink" title="6.2"></a>6.2</h2><h1 id="7"><a href="#7" class="headerlink" title="7"></a>7</h1></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://baihlup.github.io">梦之痕</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://baihlup.github.io/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/">https://baihlup.github.io/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a><a class="post-meta__tags" href="/tags/RAG/">RAG</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/02/12/260%20-%20%E5%90%8E%E7%AB%AF&amp;%E6%9E%B6%E6%9E%84/263%20-%20%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/06%20-%20WASM%20%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" title="06 - WASM 插件开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">06 - WASM 插件开发</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2024/41710043961_.pic.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">梦之痕</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">62</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/BaihlUp"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">个人笔记迁移中ing....</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.</span> <span class="toc-text">1 向量数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 向量数据库简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 传统数据库与向量数据库的差异</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.3.</span> <span class="toc-text">1.3 传统数据库与向量数据库优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95"><span class="toc-number">1.4.</span> <span class="toc-text">1.4 相似度搜索算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%8E%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.4.1.</span> <span class="toc-text">1.4.1 余弦相似度与欧氏距离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-2-%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%8A%A0%E9%80%9F%E7%AE%97%E6%B3%95"><span class="toc-number">1.4.2.</span> <span class="toc-text">1.4.2 相似性搜索加速算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">1.5 向量数据库的配置和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-1-Faiss-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.5.1.</span> <span class="toc-text">1.5.1 Faiss 向量数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-1-1-Faiss-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">1.5.1.1 Faiss 基本使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-1-2-%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">1.5.1.2 删除指定数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-1-3-%E5%B8%A6%E8%BF%87%E6%BB%A4%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">1.5.1.3 带过滤的相似性搜索</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-2-Pinecone-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.5.2.</span> <span class="toc-text">1.5.2 Pinecone 向量数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-2-1-Pinecone-%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">1.5.2.1 Pinecone 配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-2-2-Pinecone-%E4%BD%BF%E7%94%A8"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">1.5.2.2 Pinecone 使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-3-Weaviate-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.5.3.</span> <span class="toc-text">1.5.3 Weaviate 向量数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-3-1-Weaviate-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">1.5.3.1 Weaviate 介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-3-2-Weaviate-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.5.3.2.</span> <span class="toc-text">1.5.3.2 Weaviate 向量数据库的使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-4-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.5.4.</span> <span class="toc-text">1.5.4 自定义向量数据库</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">2 嵌入模型介绍和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 嵌入模型介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-Embedding-%E7%9A%84%E4%BB%B7%E5%80%BC"><span class="toc-number">2.2.</span> <span class="toc-text">2.3 Embedding 的价值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-CacheBackEmbedding-%E7%BB%84%E4%BB%B6"><span class="toc-number">2.3.</span> <span class="toc-text">2.4 CacheBackEmbedding 组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-HuggingFace-Embedding-%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">2.4.</span> <span class="toc-text">2.5 HuggingFace Embedding 模型的配置和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-1-HuggingFace-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.1.</span> <span class="toc-text">2.5.1 HuggingFace 本地模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-2-HuggingFace%E8%BF%9C%E7%A8%8B%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.2.</span> <span class="toc-text">2.5.2 HuggingFace远程嵌入模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.</span> <span class="toc-text">3 文档加载器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Document-%E4%B8%8E%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 Document 与文档加载器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E5%86%85%E7%BD%AE%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 内置文档加载器的使用技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-Markdown-%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.2.1.</span> <span class="toc-text">3.2.1 Markdown 文档加载器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-Office-%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.2.2.</span> <span class="toc-text">3.2.2 Office 文档加载器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E9%80%9A%E7%94%A8%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.2.3.</span> <span class="toc-text">3.2.3 通用文档加载器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-4-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">3.2.4.</span> <span class="toc-text">3.2.4 自定义文档加载器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%96%87%E6%9C%AC%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.</span> <span class="toc-text">4 文本分割器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-DocumentTransformer-%E7%BB%84%E4%BB%B6"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 DocumentTransformer 组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%AD%97%E7%AC%A6%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 字符分割器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E9%80%92%E5%BD%92%E5%AD%97%E7%AC%A6%E6%96%87%E6%9C%AC%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 递归字符文本分割器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-%E8%AF%AD%E4%B9%89%E6%96%87%E6%A1%A3%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 语义文档分割器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.5.</span> <span class="toc-text">4.5 自定义文档分割器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-6-%E9%9D%9E%E5%88%86%E5%89%B2%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E5%88%86%E5%89%B2%E5%99%A8"><span class="toc-number">4.6.</span> <span class="toc-text">4.6 非分割类型的文档分割器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-1-%E9%97%AE%E7%AD%94%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">4.6.1.</span> <span class="toc-text">4.6.1 问答转换器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-2-%E7%BF%BB%E8%AF%91%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">4.6.2.</span> <span class="toc-text">4.6.2 翻译转换器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E6%96%87%E6%A1%A3%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="toc-number">5.</span> <span class="toc-text">5 文档检索器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E5%B8%A6%E5%BE%97%E5%88%86%E9%98%88%E5%80%BC%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 带得分阈值的相似性搜索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-as-retriever-%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 as_retriever() 检索器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-MMR-%E6%9C%80%E5%A4%A7%E8%BE%B9%E9%99%85%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 MMR 最大边际相关性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-%E6%A3%80%E7%B4%A2%E5%99%A8%E7%BB%84%E4%BB%B6"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 检索器组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A3%80%E7%B4%A2%E5%99%A8"><span class="toc-number">5.5.</span> <span class="toc-text">5.5 自定义检索器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-RAG-%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">6.</span> <span class="toc-text">6 RAG 优化策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-RAG-%E5%BC%80%E5%8F%916%E4%B8%AA%E9%98%B6%E6%AE%B5%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">6.0.1.</span> <span class="toc-text">6.1 RAG 开发6个阶段优化策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2"><span class="toc-number">6.1.</span> <span class="toc-text">6.2</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7"><span class="toc-number">7.</span> <span class="toc-text">7</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/29/250%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;%E5%A4%A7%E6%95%B0%E6%8D%AE/257%20-%20AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B/09%20-%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20RAG%20%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%BC%80%E5%8F%91/" title="大模型 RAG 的应用和开发">大模型 RAG 的应用和开发</a><time datetime="2025-04-29T00:00:00.000Z" title="Created 2025-04-29 00:00:00">2025-04-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/12/260%20-%20%E5%90%8E%E7%AB%AF&amp;%E6%9E%B6%E6%9E%84/263%20-%20%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/06%20-%20WASM%20%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" title="06 - WASM 插件开发">06 - WASM 插件开发</a><time datetime="2025-02-12T00:00:00.000Z" title="Created 2025-02-12 00:00:00">2025-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/28/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/279%20-%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/02%20-%20%E8%AE%B0%E5%BD%95%E8%AE%BF%E9%97%AE%20HTTPS%20%E7%BD%91%E7%AB%99%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/" title="记录访问 HTTPS 网站报错问题">记录访问 HTTPS 网站报错问题</a><time datetime="2024-09-28T00:00:00.000Z" title="Created 2024-09-28 00:00:00">2024-09-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/29/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/279%20-%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/06%20-%20%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E4%B8%B2%E8%AE%B2%EF%BC%9A%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%9A%84%E6%95%85%E4%BA%8B%E4%B8%B2%E8%B5%B7%E7%A2%8E%E7%89%87%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%AD%EF%BC%89/" title="Untitled">Untitled</a><time datetime="2024-08-29T08:17:15.548Z" title="Created 2024-08-29 08:17:15">2024-08-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/29/270%20-%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/279%20-%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/05%20-%20%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E4%B8%B2%E8%AE%B2%EF%BC%9A%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%9A%84%E6%95%85%E4%BA%8B%E4%B8%B2%E8%B5%B7%E7%A2%8E%E7%89%87%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8A%EF%BC%89/" title="Untitled">Untitled</a><time datetime="2024-08-29T08:17:15.544Z" title="Created 2024-08-29 08:17:15">2024-08-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 梦之痕</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>