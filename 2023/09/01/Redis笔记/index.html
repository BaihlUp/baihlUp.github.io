<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Redis学习笔记 | Hexo</title>
  <meta name="keywords" content=" Redis 数据库 ">
  <meta name="description" content="Redis学习笔记 | Hexo">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="[toc] 1 编程基础1.1 Main方法 class  在Java语言中的一等公民，Java程序就是一个一个的类组成的类由修饰符，类名和类的内容组成类名必须与保存类源文件的文件名相同  main方法  Main方法是Java程序执行的入口方法由方法修饰符，方法名，参数列表和方法体等组成 1.2 基本数据类型 整数类型   byte 占用1个 byte，值域是 -128 ~ 127 short">
<meta property="og:type" content="article">
<meta property="og:title" content="Java学习笔记">
<meta property="og:url" content="http://example.com/2023/09/01/220%20-%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/224%20-%20Java%E3%80%81Lua/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="[toc] 1 编程基础1.1 Main方法 class  在Java语言中的一等公民，Java程序就是一个一个的类组成的类由修饰符，类名和类的内容组成类名必须与保存类源文件的文件名相同  main方法  Main方法是Java程序执行的入口方法由方法修饰符，方法名，参数列表和方法体等组成 1.2 基本数据类型 整数类型   byte 占用1个 byte，值域是 -128 ~ 127 short">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308081038318.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308081043733.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308081053010.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308091136168.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308091139131.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308091141822.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308091645115.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308091715269.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308101443784.png">
<meta property="og:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308101454744.png">
<meta property="article:published_time" content="2023-09-01T09:27:41.000Z">
<meta property="article:modified_time" content="2023-09-01T09:07:19.096Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Java 编程语言">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202308081038318.png">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 6.3.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>John Doe</span>
</div>

<div class="icon">
    
        
            <a title="rss"
               href="/atom.xml"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-rss"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="github"
               href="https://github.com/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="facebook"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-facebook"></use>
                    </svg>
                
            </a>
        
    
        
    
        
    
        
            <a title="instagram"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-instagram"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="reddit"
               href="https://www.reddit.com/user/yelog/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-reddit"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="weibo"
               href="http://weibo.com/u/2307534817"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-weibo"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="jianshu"
               href="https://www.jianshu.com/u/ff56736de7cf"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-jianshu"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="zhihu"
               href="https://www.zhihu.com/people/jaytp/activities"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-zhihu"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="oschina"
               href="https://my.oschina.net/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-oschina"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="email"
               href="mailto:jaytp@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=872336115&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="kugou"
               href="https://www.kugou.com/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-kugou"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="neteasemusic"
               href="https://music.163.com/#/user/home?id=88151013"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-neteasemusic"></use>
                    </svg>
                
            </a>
        
    
</div>





<ul>
    <li>
        <div class="all active" data-rel="All">All
            
                <small>(3)</small>
            
        </div>
    </li>
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
            <a class="about  hasFriend  site_url"
               
               href="/about">About</a>
        
        <a style="width: 50%"
                
                                           class="friends">Friends</a>
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="3">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        Links
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">All</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Java 编程语言</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Redis 数据库</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="All "
           href="/2023/09/01/220%20-%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/224%20-%20Java%E3%80%81Lua/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="Java 编程语言"
           data-author="" >
            <span class="post-title" title="Java学习笔记">Java学习笔记</span>
            <span class="post-date" title="2023-09-01 09:27:41">2023/09/01</span>
        </a>
        
        
        <a  class="All "
           href="/2023/09/01/Redis%E7%AC%94%E8%AE%B0/"
           data-tag="Redis 数据库"
           data-author="" >
            <span class="post-title" title="Redis学习笔记">Redis学习笔记</span>
            <span class="post-date" title="2023-09-01 09:27:41">2023/09/01</span>
        </a>
        
        
        <a  class="All "
           href="/2023/09/01/hello-world/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hello World">Hello World</span>
            <span class="post-date" title="2023-09-01 09:07:19">2023/09/01</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-Redis笔记" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">Redis学习笔记</h1>
    
    <div class="article-meta">
        
        
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color5">Redis 数据库</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            Created At : <time class="date" title='Updated At: 2023-09-01 09:07:19'>2023-09-01 09:27</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            Views 👀 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-text">0 参考资料</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-1-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%8E%A8%E8%8D%90"><span class="toc-text">0.1 学习资料推荐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-2-%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-text">0.2 学习方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E5%9F%BA%E7%A1%80%E7%AF%87"><span class="toc-text">1 基础篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%80%E4%B8%AA%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8C%85%E5%90%AB%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1.1 基础架构：一个键值数据库包含什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">1.2 数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-%E9%94%AE%E5%92%8C%E5%80%BC%E7%94%A8%E4%BB%80%E4%B9%88%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87%EF%BC%9F"><span class="toc-text">1.2.1 键和值用什么结构组织？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E6%95%88%E7%8E%87"><span class="toc-text">1.2.2 集合数据操作效率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-3-%E4%B8%8D%E5%90%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-text">1.2.3 不同操作的复杂度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.2.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-text">1.3 Redis为什么这么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-AOF%E6%97%A5%E5%BF%97"><span class="toc-text">1.4 AOF日志</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-AOF%E6%97%A5%E5%BF%97%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-text">1.4.1 AOF日志是如何实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-2-%E4%B8%89%E7%A7%8D%E5%86%99%E5%9B%9E%E7%AD%96%E7%95%A5"><span class="toc-text">1.4.2 三种写回策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-3-AOF%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="toc-text">1.4.3 AOF重写机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.4.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-RDB%EF%BC%9A%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7"><span class="toc-text">1.5 RDB：内存快照</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4"><span class="toc-text">1.6 数据同步：主从库实现数据一致</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-1-%E4%B8%BB%E4%BB%8E%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5"><span class="toc-text">1.6.1 主从库第一次同步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-2-%E4%B8%BB%E4%BB%8E%E7%BA%A7%E8%81%94%E6%A8%A1%E5%BC%8F"><span class="toc-text">1.6.2 主从级联模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-3-%E4%B8%BB%E4%BB%8E%E5%BA%93%E9%97%B4%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E6%96%AD%E5%BC%80"><span class="toc-text">1.6.3 主从库间网络异常断开</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-4-replication-buffer%E5%92%8Crepl-backlog-buffer%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">1.6.4 replication buffer和repl_backlog_buffer的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6"><span class="toc-text">1.7 哨兵机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-1-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-text">1.7.1 哨兵机制的基本流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-2-%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF"><span class="toc-text">1.7.2 主观下线和客观下线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-3-%E9%80%89%E5%AE%9A%E6%96%B0%E4%B8%BB%E5%BA%93"><span class="toc-text">1.7.3 选定新主库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4"><span class="toc-text">1.8 哨兵集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-1-%E5%9F%BA%E4%BA%8Epub-sub%E6%9C%BA%E5%88%B6%E7%9A%84%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%BB%84%E6%88%90"><span class="toc-text">1.8.1 基于pub&#x2F;sub机制的哨兵集群组成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-2-%E5%9F%BA%E4%BA%8Epub-sub%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5"><span class="toc-text">1.8.2 基于pub&#x2F;sub机制的客户端事件通知</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-3-%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E6%89%A7%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%EF%BC%9F"><span class="toc-text">1.8.3 由哪个哨兵执行主从切换？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.8.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-9-%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4"><span class="toc-text">1.9 切片集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-9-1-%E6%95%B0%E6%8D%AE%E5%88%87%E7%89%87%E5%92%8C%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%AF%B9%E5%BA%94%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB"><span class="toc-text">1.9.1 数据切片和实例的对应分布关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-9-2-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE"><span class="toc-text">1.9.2 客户端如何定位数据</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E5%AE%9E%E8%B7%B5%E7%AF%87"><span class="toc-text">2 实践篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-11%E2%80%9C%E4%B8%87%E9%87%91%E6%B2%B9%E2%80%9D%E7%9A%84String%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86%EF%BC%9F"><span class="toc-text">2.11“万金油”的String，为什么不好用了？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-1-string%E7%B1%BB%E5%9E%8B%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84"><span class="toc-text">2.11.1 string类型如何保存数据的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-2-%E9%80%89%E6%8B%A9%E8%8A%82%E7%9C%81%E5%86%85%E5%AD%98%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">2.11.2 选择节省内存的数据结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-12-%E6%9C%89%E4%B8%80%E4%BA%BF%E4%B8%AAkeys%E8%A6%81%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12 有一亿个keys要统计，使用Redis实现统计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-1-%E8%81%9A%E5%90%88%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.1 聚合统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-2-%E6%8E%92%E5%BA%8F%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.2 排序统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-3-%E4%BA%8C%E5%80%BC%E7%8A%B6%E6%80%81%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.3 二值状态统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-4-%E5%9F%BA%E6%95%B0%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.4 基数统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-5-%E6%80%BB%E7%BB%93"><span class="toc-text">2.12.5 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-13-GEO%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%90%97%EF%BC%9F"><span class="toc-text">2.13 GEO是什么？还可以定义新的数据类型吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-1-GEO%E7%9A%84%E5%BA%95%E5%B1%82%E7%BB%93%E6%9E%84"><span class="toc-text">2.13.1 GEO的底层结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-2-GeoHash%E7%9A%84%E7%BC%96%E7%A0%81%E6%96%B9%E6%B3%95"><span class="toc-text">2.13.2 GeoHash的编码方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-3-%E5%A6%82%E4%BD%95%E6%93%8D%E4%BD%9CGEO%E7%B1%BB%E5%9E%8B"><span class="toc-text">2.13.3 如何操作GEO类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-4-%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%9F"><span class="toc-text">2.13.4 如何自定义数据类型？***</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-14-%E5%9C%A8Redis%E4%B8%AD%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14 在Redis中保存时间序列数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-1-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%BB%E5%86%99%E7%89%B9%E7%82%B9"><span class="toc-text">2.14.1 时间序列数据的读写特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-2-%E5%9F%BA%E4%BA%8EHash%E5%92%8CSorted-Set%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14.2 基于Hash和Sorted Set保存时间序列数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-3-%E5%9F%BA%E4%BA%8ERedisTimeSeries%E6%A8%A1%E5%9D%97%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14.3 基于RedisTimeSeries模块保存时间序列数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-15-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E8%80%83%E9%AA%8C%EF%BC%9ARedis%E6%9C%89%E5%93%AA%E4%BA%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-text">2.15 消息队列的考验：Redis有哪些解决方案？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-1-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%B6%88%E6%81%AF%E5%AD%98%E5%8F%96%E9%9C%80%E6%B1%82"><span class="toc-text">2.15.1 消息队列的消息存取需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-2-%E5%9F%BA%E4%BA%8EList%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">2.15.2 基于List的消息队列解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-3-%E5%9F%BA%E4%BA%8EStreams%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">2.15.3 基于Streams的消息队列解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-4-%E6%80%BB%E7%BB%93"><span class="toc-text">2.15.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-16-%E5%BC%82%E6%AD%A5%E6%9C%BA%E5%88%B6%EF%BC%9A%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%98%BB%E5%A1%9E%EF%BC%9F"><span class="toc-text">2.16 异步机制：如何避免单线程模型的阻塞？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-1-Redis%E5%AE%9E%E4%BE%8B%E6%9C%89%E5%93%AA%E4%BA%9B%E9%98%BB%E5%A1%9E%E7%82%B9%EF%BC%9F"><span class="toc-text">2.16.1 Redis实例有哪些阻塞点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-2-%E9%82%A3%E4%BA%9B%E9%98%BB%E5%A1%9E%E7%82%B9%E5%8F%AF%E4%BB%A5%E5%BC%82%E6%AD%A5%E6%89%A7%E8%A1%8C"><span class="toc-text">2.16.2 那些阻塞点可以异步执行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-3-%E5%BC%82%E6%AD%A5%E7%9A%84%E5%AD%90%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6"><span class="toc-text">2.16.3 异步的子线程机制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-18-%E6%B3%A2%E5%8A%A8%E7%9A%84%E5%93%8D%E5%BA%94%E5%BB%B6%E8%BF%9F%EF%BC%9A%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%8F%98%E6%85%A2%E7%9A%84Redis%EF%BC%9F"><span class="toc-text">2.18 波动的响应延迟：如何应对变慢的Redis？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-25-%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-text">2.25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-26-%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%E9%9A%BE%E9%A2%98%EF%BC%9F"><span class="toc-text">2.26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-27-%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B1%A1%E6%9F%93%E4%BA%86%EF%BC%8C%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-text">2.27 缓存被污染了，该怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-28-Pika-%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8ESSD%E5%AE%9E%E7%8E%B0%E5%A4%A7%E5%AE%B9%E9%87%8FRedis%EF%BC%9F"><span class="toc-text">2.28 Pika-如何基于SSD实现大容量Redis？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-29-%E6%97%A0%E9%94%81%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%EF%BC%9ARedis%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%B9%B6%E5%8F%91%E8%AE%BF%E9%97%AE%EF%BC%9F"><span class="toc-text">2.29 无锁的原子操作：Redis如何应对并发访问？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-30-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F"><span class="toc-text">2.30 如何使用Redis实现分布式锁？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-30-1-%E5%9F%BA%E4%BA%8E%E5%8D%95%E4%B8%AARedis%E8%8A%82%E7%82%B9%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2.30.1 基于单个Redis节点实现分布式锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-30-2-%E5%9F%BA%E4%BA%8E%E5%A4%9A%E4%B8%AARedis%E8%8A%82%E7%82%B9%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2.30.2 基于多个Redis节点实现高可靠的分布式锁</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-31-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%EF%BC%9ARedis%E8%83%BD%E5%AE%9E%E7%8E%B0ACID%E5%B1%9E%E6%80%A7%E5%90%97%EF%BC%9F"><span class="toc-text">2.31 事务机制：Redis能实现ACID属性吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-2-%E5%8E%9F%E5%AD%90%E6%80%A7"><span class="toc-text">2.31.2 原子性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-3-%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-text">2.31.3 一致性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-4-%E9%9A%94%E7%A6%BB%E6%80%A7"><span class="toc-text">2.31.4 隔离性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-5-%E6%8C%81%E4%B9%85%E6%80%A7"><span class="toc-text">2.31.5 持久性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-32-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8E%E6%95%85%E9%9A%9C%E5%88%87%E6%8D%A2"><span class="toc-text">2.32 Redis主从同步与故障切换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-33-%E8%84%91%E8%A3%82%EF%BC%9A%E4%B8%80%E6%AC%A1%E5%A5%87%E6%80%AA%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1"><span class="toc-text">2.33 脑裂：一次奇怪的数据丢失</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-35"><span class="toc-text">2.35</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-36-Redis%E6%94%AF%E6%92%91%E7%A7%92%E6%9D%80%E5%9C%BA%E6%99%AF"><span class="toc-text">2.36 Redis支撑秒杀场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-37"><span class="toc-text">2.37</span></a></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><div class='inner-toc'><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-text">0 参考资料</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-1-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%8E%A8%E8%8D%90"><span class="toc-text">0.1 学习资料推荐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-2-%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-text">0.2 学习方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E5%9F%BA%E7%A1%80%E7%AF%87"><span class="toc-text">1 基础篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%80%E4%B8%AA%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8C%85%E5%90%AB%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1.1 基础架构：一个键值数据库包含什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">1.2 数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-%E9%94%AE%E5%92%8C%E5%80%BC%E7%94%A8%E4%BB%80%E4%B9%88%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87%EF%BC%9F"><span class="toc-text">1.2.1 键和值用什么结构组织？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E6%95%88%E7%8E%87"><span class="toc-text">1.2.2 集合数据操作效率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-3-%E4%B8%8D%E5%90%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-text">1.2.3 不同操作的复杂度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.2.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-text">1.3 Redis为什么这么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-AOF%E6%97%A5%E5%BF%97"><span class="toc-text">1.4 AOF日志</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-AOF%E6%97%A5%E5%BF%97%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-text">1.4.1 AOF日志是如何实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-2-%E4%B8%89%E7%A7%8D%E5%86%99%E5%9B%9E%E7%AD%96%E7%95%A5"><span class="toc-text">1.4.2 三种写回策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-3-AOF%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="toc-text">1.4.3 AOF重写机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.4.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-RDB%EF%BC%9A%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7"><span class="toc-text">1.5 RDB：内存快照</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4"><span class="toc-text">1.6 数据同步：主从库实现数据一致</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-1-%E4%B8%BB%E4%BB%8E%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5"><span class="toc-text">1.6.1 主从库第一次同步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-2-%E4%B8%BB%E4%BB%8E%E7%BA%A7%E8%81%94%E6%A8%A1%E5%BC%8F"><span class="toc-text">1.6.2 主从级联模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-3-%E4%B8%BB%E4%BB%8E%E5%BA%93%E9%97%B4%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E6%96%AD%E5%BC%80"><span class="toc-text">1.6.3 主从库间网络异常断开</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-4-replication-buffer%E5%92%8Crepl-backlog-buffer%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">1.6.4 replication buffer和repl_backlog_buffer的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6"><span class="toc-text">1.7 哨兵机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-1-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-text">1.7.1 哨兵机制的基本流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-2-%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF"><span class="toc-text">1.7.2 主观下线和客观下线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-3-%E9%80%89%E5%AE%9A%E6%96%B0%E4%B8%BB%E5%BA%93"><span class="toc-text">1.7.3 选定新主库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4"><span class="toc-text">1.8 哨兵集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-1-%E5%9F%BA%E4%BA%8Epub-sub%E6%9C%BA%E5%88%B6%E7%9A%84%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%BB%84%E6%88%90"><span class="toc-text">1.8.1 基于pub&#x2F;sub机制的哨兵集群组成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-2-%E5%9F%BA%E4%BA%8Epub-sub%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5"><span class="toc-text">1.8.2 基于pub&#x2F;sub机制的客户端事件通知</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-3-%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E6%89%A7%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%EF%BC%9F"><span class="toc-text">1.8.3 由哪个哨兵执行主从切换？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-8-4-%E6%80%BB%E7%BB%93"><span class="toc-text">1.8.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-9-%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4"><span class="toc-text">1.9 切片集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-9-1-%E6%95%B0%E6%8D%AE%E5%88%87%E7%89%87%E5%92%8C%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%AF%B9%E5%BA%94%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB"><span class="toc-text">1.9.1 数据切片和实例的对应分布关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-9-2-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE"><span class="toc-text">1.9.2 客户端如何定位数据</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E5%AE%9E%E8%B7%B5%E7%AF%87"><span class="toc-text">2 实践篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-11%E2%80%9C%E4%B8%87%E9%87%91%E6%B2%B9%E2%80%9D%E7%9A%84String%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86%EF%BC%9F"><span class="toc-text">2.11“万金油”的String，为什么不好用了？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-1-string%E7%B1%BB%E5%9E%8B%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84"><span class="toc-text">2.11.1 string类型如何保存数据的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-2-%E9%80%89%E6%8B%A9%E8%8A%82%E7%9C%81%E5%86%85%E5%AD%98%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">2.11.2 选择节省内存的数据结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-12-%E6%9C%89%E4%B8%80%E4%BA%BF%E4%B8%AAkeys%E8%A6%81%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12 有一亿个keys要统计，使用Redis实现统计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-1-%E8%81%9A%E5%90%88%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.1 聚合统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-2-%E6%8E%92%E5%BA%8F%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.2 排序统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-3-%E4%BA%8C%E5%80%BC%E7%8A%B6%E6%80%81%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.3 二值状态统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-4-%E5%9F%BA%E6%95%B0%E7%BB%9F%E8%AE%A1"><span class="toc-text">2.12.4 基数统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-5-%E6%80%BB%E7%BB%93"><span class="toc-text">2.12.5 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-13-GEO%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%90%97%EF%BC%9F"><span class="toc-text">2.13 GEO是什么？还可以定义新的数据类型吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-1-GEO%E7%9A%84%E5%BA%95%E5%B1%82%E7%BB%93%E6%9E%84"><span class="toc-text">2.13.1 GEO的底层结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-2-GeoHash%E7%9A%84%E7%BC%96%E7%A0%81%E6%96%B9%E6%B3%95"><span class="toc-text">2.13.2 GeoHash的编码方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-3-%E5%A6%82%E4%BD%95%E6%93%8D%E4%BD%9CGEO%E7%B1%BB%E5%9E%8B"><span class="toc-text">2.13.3 如何操作GEO类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-4-%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%9F"><span class="toc-text">2.13.4 如何自定义数据类型？***</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-14-%E5%9C%A8Redis%E4%B8%AD%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14 在Redis中保存时间序列数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-1-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%BB%E5%86%99%E7%89%B9%E7%82%B9"><span class="toc-text">2.14.1 时间序列数据的读写特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-2-%E5%9F%BA%E4%BA%8EHash%E5%92%8CSorted-Set%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14.2 基于Hash和Sorted Set保存时间序列数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-3-%E5%9F%BA%E4%BA%8ERedisTimeSeries%E6%A8%A1%E5%9D%97%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-text">2.14.3 基于RedisTimeSeries模块保存时间序列数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-15-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E8%80%83%E9%AA%8C%EF%BC%9ARedis%E6%9C%89%E5%93%AA%E4%BA%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-text">2.15 消息队列的考验：Redis有哪些解决方案？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-1-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%B6%88%E6%81%AF%E5%AD%98%E5%8F%96%E9%9C%80%E6%B1%82"><span class="toc-text">2.15.1 消息队列的消息存取需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-2-%E5%9F%BA%E4%BA%8EList%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">2.15.2 基于List的消息队列解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-3-%E5%9F%BA%E4%BA%8EStreams%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">2.15.3 基于Streams的消息队列解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-15-4-%E6%80%BB%E7%BB%93"><span class="toc-text">2.15.4 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-16-%E5%BC%82%E6%AD%A5%E6%9C%BA%E5%88%B6%EF%BC%9A%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%98%BB%E5%A1%9E%EF%BC%9F"><span class="toc-text">2.16 异步机制：如何避免单线程模型的阻塞？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-1-Redis%E5%AE%9E%E4%BE%8B%E6%9C%89%E5%93%AA%E4%BA%9B%E9%98%BB%E5%A1%9E%E7%82%B9%EF%BC%9F"><span class="toc-text">2.16.1 Redis实例有哪些阻塞点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-2-%E9%82%A3%E4%BA%9B%E9%98%BB%E5%A1%9E%E7%82%B9%E5%8F%AF%E4%BB%A5%E5%BC%82%E6%AD%A5%E6%89%A7%E8%A1%8C"><span class="toc-text">2.16.2 那些阻塞点可以异步执行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-16-3-%E5%BC%82%E6%AD%A5%E7%9A%84%E5%AD%90%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6"><span class="toc-text">2.16.3 异步的子线程机制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-18-%E6%B3%A2%E5%8A%A8%E7%9A%84%E5%93%8D%E5%BA%94%E5%BB%B6%E8%BF%9F%EF%BC%9A%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%8F%98%E6%85%A2%E7%9A%84Redis%EF%BC%9F"><span class="toc-text">2.18 波动的响应延迟：如何应对变慢的Redis？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-25-%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-text">2.25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-26-%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%E9%9A%BE%E9%A2%98%EF%BC%9F"><span class="toc-text">2.26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-27-%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B1%A1%E6%9F%93%E4%BA%86%EF%BC%8C%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-text">2.27 缓存被污染了，该怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-28-Pika-%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8ESSD%E5%AE%9E%E7%8E%B0%E5%A4%A7%E5%AE%B9%E9%87%8FRedis%EF%BC%9F"><span class="toc-text">2.28 Pika-如何基于SSD实现大容量Redis？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-29-%E6%97%A0%E9%94%81%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%EF%BC%9ARedis%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%B9%B6%E5%8F%91%E8%AE%BF%E9%97%AE%EF%BC%9F"><span class="toc-text">2.29 无锁的原子操作：Redis如何应对并发访问？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-30-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F"><span class="toc-text">2.30 如何使用Redis实现分布式锁？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-30-1-%E5%9F%BA%E4%BA%8E%E5%8D%95%E4%B8%AARedis%E8%8A%82%E7%82%B9%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2.30.1 基于单个Redis节点实现分布式锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-30-2-%E5%9F%BA%E4%BA%8E%E5%A4%9A%E4%B8%AARedis%E8%8A%82%E7%82%B9%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2.30.2 基于多个Redis节点实现高可靠的分布式锁</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-31-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%EF%BC%9ARedis%E8%83%BD%E5%AE%9E%E7%8E%B0ACID%E5%B1%9E%E6%80%A7%E5%90%97%EF%BC%9F"><span class="toc-text">2.31 事务机制：Redis能实现ACID属性吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-2-%E5%8E%9F%E5%AD%90%E6%80%A7"><span class="toc-text">2.31.2 原子性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-3-%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-text">2.31.3 一致性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-4-%E9%9A%94%E7%A6%BB%E6%80%A7"><span class="toc-text">2.31.4 隔离性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-31-5-%E6%8C%81%E4%B9%85%E6%80%A7"><span class="toc-text">2.31.5 持久性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-32-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8E%E6%95%85%E9%9A%9C%E5%88%87%E6%8D%A2"><span class="toc-text">2.32 Redis主从同步与故障切换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-33-%E8%84%91%E8%A3%82%EF%BC%9A%E4%B8%80%E6%AC%A1%E5%A5%87%E6%80%AA%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1"><span class="toc-text">2.33 脑裂：一次奇怪的数据丢失</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-35"><span class="toc-text">2.35</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-36-Redis%E6%94%AF%E6%92%91%E7%A7%92%E6%9D%80%E5%9C%BA%E6%99%AF"><span class="toc-text">2.36 Redis支撑秒杀场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-37"><span class="toc-text">2.37</span></a></li></ol></li></ol></div></p>
<h1 id="0-参考资料"><a href="#0-参考资料" class="headerlink" title="0 参考资料"></a>0 参考资料</h1><ul>
<li>本笔记是极客时间《Redis核心技术与实战》课程</li>
</ul>
<h2 id="0-1-学习资料推荐"><a href="#0-1-学习资料推荐" class="headerlink" title="0.1 学习资料推荐"></a>0.1 学习资料推荐</h2><p>书籍：</p>
<ul>
<li>工具书：《Redis使用手册》：<a target="_blank" rel="noopener" href="http://redisdoc.com/">Redis命令参考</a></li>
<li>原理书：《Redis设计与实现》</li>
<li>实战书：《Redis开发与运维》</li>
</ul>
<p>可以尝试读一下<a target="_blank" rel="noopener" href="https://github.com/redis/redis">Redis源码</a>，有一个<a target="_blank" rel="noopener" href="https://github.com/huangz1990/redis-3.0-annotated">网站</a>提供了Redis 3.0源码的部分中文注释，你也可以参考一下。</p>
<p>Redis涉及的知识比较多，比如：操作系统、分布式系统等知识点，如下图：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262136386.png"></p>
<h2 id="0-2-学习方法"><a href="#0-2-学习方法" class="headerlink" title="0.2 学习方法"></a>0.2 学习方法</h2><p>分为三大模块：</p>
<ol>
<li>掌握数据结构和缓存的基本使用方法；</li>
<li>掌握支撑Redis实现高可靠、高性能的技术；</li>
<li>精通Redis底层实现原理。</li>
</ol>
<p>参考<a target="_blank" rel="noopener" href="https://app.yinxiang.com/shard/s16/nl/19257560/ffd85b7b-9ea3-4a73-83c1-92d484a4e15f/">加餐（二）-Kaito：我是如何学习Redis的？_For_group_share</a></p>
<h1 id="1-基础篇"><a href="#1-基础篇" class="headerlink" title="1 基础篇"></a>1 基础篇</h1><h2 id="1-1-基础架构：一个键值数据库包含什么？"><a href="#1-1-基础架构：一个键值数据库包含什么？" class="headerlink" title="1.1 基础架构：一个键值数据库包含什么？"></a>1.1 基础架构：一个键值数据库包含什么？</h2><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262139653.png"><br>从这张对比图中，我们可以看到，从SimpleKV演进到Redis，有以下几个重要变化：</p>
<ul>
<li>Redis主要通过网络框架进行访问，而不再是动态库了，这也使得Redis可以作为一个基础性的网络服务进行访问，扩大了Redis的应用范围。</li>
<li>Redis数据模型中的value类型很丰富，因此也带来了更多的操作接口，例如面向列表的LPUSH&#x2F;LPOP，面向集合的SADD&#x2F;SREM等。在下节课，我将和你聊聊这些value模型背后的数据结构和操作效率，以及它们对Redis性能的影响。</li>
<li>Redis的持久化模块能支持两种方式：日志（AOF）和快照（RDB），这两种持久化方式具有不同的优劣势，影响到Redis的访问性能和可靠性。</li>
<li>SimpleKV是个简单的单机键值数据库，但是，Redis支持高可靠集群和高可扩展集群，因此，Redis中包含了相应的集群功能支撑模块。</li>
</ul>
<h2 id="1-2-数据结构"><a href="#1-2-数据结构" class="headerlink" title="1.2 数据结构"></a>1.2 数据结构</h2><p>Redis的<strong>数据类型</strong>有String（字符串）、List（列表）、Hash（哈希）、Set（集合）和Sorted Set（有序集合）。</p>
<p><strong>底层数据结构</strong>一共有6种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</p>
<p>Redis数据类型和底层数据结构的对应关系：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262140969.png"></p>
<h3 id="1-2-1-键和值用什么结构组织？"><a href="#1-2-1-键和值用什么结构组织？" class="headerlink" title="1.2.1 键和值用什么结构组织？"></a>1.2.1 键和值用什么结构组织？</h3><p>为了实现从键到值的快速访问，Redis使用了一个哈希表来保存所有键值对。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262220132.png"><br>通过计算键的哈希值，找到对应的哈希桶的位置，然后就可以访问到相应的entry元素。<br>哈希桶中的entry元素中保存了<em>key和</em>value指针，分别指向了实际的键和值，这样一来，即使值是一个集合，也可以通过*value指针被查找到。</p>
<p>但是，当Redis写入大量的数据后，就会出现操作有时候突然变慢了，这里边可以的问题是，大量的键，导致出现哈希表的冲突和rehash，然后造成操作阻塞。</p>
<p>Redis解决哈希冲突的方式，就是链式哈希。链式哈希也很容易理解，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。</p>
<p>如下图：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262141514.png"><br>哈希冲突增大，冲突链就会越来越长，对应的查找这个桶中的值就会变慢。</p>
<p>并且，在出现大量冲突后，Redis会对哈希表做rehash操作。rehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。</p>
<ul>
<li>rehash的操作过程</li>
</ul>
<p>为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2。一开始，当你刚插入数据时，默认使用哈希表1，此时的哈希表2并没有被分配空间。随着数据逐步增多，Redis开始执行rehash，这个过程分为三步：</p>
<ol>
<li>给哈希表2分配更大的空间，例如是当前哈希表1大小的两倍；</li>
<li>把哈希表1中的数据重新映射并拷贝到哈希表2中；</li>
<li>释放哈希表1的空间。</li>
</ol>
<p>到此，我们就可以从哈希表1切换到哈希表2，用增大的哈希表2保存更多数据，而原来的哈希表1留作下一次rehash扩容备用。<br>在第2步中的拷贝操作并不是一次就完成的，那样会造成长时间阻塞，Redis采用了<strong>渐进式rehash</strong>。</p>
<blockquote>
<p>在第二步拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺带着将这个索引位置上的所有entries拷贝到哈希表2中；等处理下一个请求时，再顺带拷贝哈希表1中的下一个索引位置的entries。如下图所示：</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262142911.png"></p>
<p>这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p>
<h3 id="1-2-2-集合数据操作效率"><a href="#1-2-2-集合数据操作效率" class="headerlink" title="1.2.2 集合数据操作效率"></a>1.2.2 集合数据操作效率</h3><p>Redis的中的键值对中的值除了String类型外，其他类型的值会是一个集合类型，所以完成通过键找到对应的哈希桶位置后，还要在集合类型中再进行增删改查等操作。</p>
<p>集合的操作效率与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点有关，比如读写一个元素的操作要比读写所有元素的效率高。</p>
<ul>
<li>压缩列表</li>
</ul>
<p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的entry个数；压缩列表在表尾还有一个zlend，表示列表结束。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262145194.png"><br>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是O(N)了。</p>
<ul>
<li>跳表</li>
</ul>
<p>有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262147034.png"></p>
<p><strong>以下列出各数据结构的时间复杂度：</strong></p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262146324.png"></p>
<p>所以集合数据的操作效率依赖于使用的是什么数据结构。</p>
<h3 id="1-2-3-不同操作的复杂度"><a href="#1-2-3-不同操作的复杂度" class="headerlink" title="1.2.3 不同操作的复杂度"></a>1.2.3 不同操作的复杂度</h3><p>集合类型的操作类型很多，有读写单个集合元素的，例如HGET、HSET，也有操作多个元素的，例如SADD，还有对整个集合进行遍历操作的，例如SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。</p>
<p>总了一个“四句口诀”，帮助你快速记住集合常见操作的复杂度。这样你在使用过程中，就可以提前规避高复杂度操作了。</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
<ol>
<li><p>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash类型的HGET、HSET和HDEL，Set类型的SADD、SREM、SRANDMEMBER等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET和HDEL是对哈希表做操作，所以它们的复杂度都是O(1)；Set类型用哈希表作为底层数据结构时，它的SADD、SREM、SRANDMEMBER复杂度也是O(1)。</p>
</li>
<li><p>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如Hash类型的HGETALL和Set类型的SMEMBERS，或者返回一个范围内的部分数据，比如List类型的LRANGE和ZSet类型的ZRANGE。这类操作的复杂度一般是O(N)，比较耗时，我们应该尽量避免。</p>
<blockquote>
<p>不过，Redis从2.8版本开始提供了SCAN系列操作（包括HSCAN，SSCAN和ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于HGETALL、SMEMBERS这类操作来说，就避免了一次性返回所有元素而导致的Redis阻塞。</p>
</blockquote>
</li>
<li><p>统计操作，是指集合类型对集合中所有元素个数的记录，例如LLEN和SCARD。这类操作复杂度只有O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
</li>
<li><p>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于List类型的LPOP、RPOP、LPUSH、RPUSH这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有O(1)，可以实现快速操作。</p>
</li>
</ol>
<h3 id="1-2-4-总结"><a href="#1-2-4-总结" class="headerlink" title="1.2.4 总结"></a>1.2.4 总结</h3><p>Redis之所以能快速操作键值对，一方面是因为O(1)复杂度的哈希表被广泛使用，包括String、Hash和Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set也采用了O(logN)复杂度的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是O(N)。这里，我的建议是：用其他命令来替代，例如可以用SCAN来代替，避免在Redis内部产生费时的全集合遍历操作。<br>当然，我们不能忘了复杂度较高的List类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是O(N)。因此，我的建议是：因地制宜地使用List类型。例如，既然它的POP&#x2F;PUSH效率很高，那么就将它主要用于FIFO队列场景，而不是作为一个可以随机读写的集合。</p>
<h2 id="1-3-Redis为什么这么快？"><a href="#1-3-Redis为什么这么快？" class="headerlink" title="1.3 Redis为什么这么快？"></a>1.3 Redis为什么这么快？</h2><ul>
<li>Redis真的只有单线程吗？</li>
</ul>
<p>Redis是单线程，主要是指Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。但Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>
<ul>
<li>为什么用单线程？</li>
</ul>
<p>Redis单线程是指它对网络IO和数据读写的操作采用了一个线程，<strong>而采用单线程的一个核心原因是避免多线程开发的并发控制问题</strong>。</p>
<ul>
<li>单线程为什么这么快？</li>
</ul>
<p>单线程的Redis也能获得高性能，跟多路复用的IO模型密切相关，因为这避免了accept()和send()&#x2F;recv()潜在的网络IO操作阻塞点。</p>
<ul>
<li>Redis单线程处理IO请求性能瓶颈主要包括2个方面：</li>
</ul>
<ol>
<li><p>任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：</p>
<blockquote>
<p>a. 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；<br>b. 使用复杂度过高的命令：例如SORT&#x2F;SUNION&#x2F;ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；<br>c. 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；<br>d. 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长;<br>e. AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；<br>f. 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</p>
</blockquote>
</li>
<li><p>并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</p>
</li>
</ol>
<blockquote>
<p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。<br>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>
</blockquote>
<h2 id="1-4-AOF日志"><a href="#1-4-AOF日志" class="headerlink" title="1.4 AOF日志"></a>1.4 AOF日志</h2><h3 id="1-4-1-AOF日志是如何实现的？"><a href="#1-4-1-AOF日志是如何实现的？" class="headerlink" title="1.4.1 AOF日志是如何实现的？"></a>1.4.1 AOF日志是如何实现的？</h3><p>AOF日志的写入顺序为：Redis在接收到命令后，先执行命令，把数据写入内存，然后再记录日志。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262148218.png"><br>这样防止有些命令不符合规范，在执行时报错，就可以直接返回错误，不记录日志。</p>
<p>AOF日志是以文本形式保存，如下执行一个“set testkey testvalue”命令后记录的日志为例：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262149666.png"><br>“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有3个字节，也就是“set”命令。</p>
<h3 id="1-4-2-三种写回策略"><a href="#1-4-2-三种写回策略" class="headerlink" title="1.4.2 三种写回策略"></a>1.4.2 三种写回策略</h3><p>AOF机制给我们提供了三个选择，也就是AOF配置项appendfsync的三个可选值。</p>
<ul>
<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>
</ul>
<p>三种写回策略的对比如下：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262149354.png"></p>
<h3 id="1-4-3-AOF重写机制"><a href="#1-4-3-AOF重写机制" class="headerlink" title="1.4.3 AOF重写机制"></a>1.4.3 AOF重写机制</h3><p>AOF日志长时间写入文件会变的越来越大，这时候需要进行AOF重写。Redis根据数据库的现状创建一个新的AOF文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对“testkey”: “testvalue”之后，重写机制会记录set testkey testvalue这条命令。这样，当需要恢复时，可以重新执行该命令，实现“testkey”: “testvalue”的写入。</p>
<p>AOF重写机制可以合并一些命令，直接以Redis数据库的现状为依据，如下：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262150064.png"><br>之前先后6次修改操作，列表的最后状态是[“D”, “C”, “N”]，此时，只用LPUSH u:list “N”, “C”, “D”这一条命令就能实现该数据的恢复，这就节省了五条命令的空间。对于被修改过成百上千次的键值对来说，重写能节省的空间当然就更大了。</p>
<p>AOF日志由主线程写回不同，重写过程是由后台线程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。<br>如下图：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262153433.png"><br>每次AOF重写时，Redis会先执行一个内存拷贝，用于重写；然后，使用两个日志（AOF缓冲，AOF重写缓冲）保证在重写过程中，新写入的数据不会丢失。而且，因为Redis采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>
<h3 id="1-4-4-总结"><a href="#1-4-4-总结" class="headerlink" title="1.4.4 总结"></a>1.4.4 总结</h3><p><strong>问题</strong>： Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，</p>
<ol>
<li>fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。</li>
<li>fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。</li>
</ol>
<h2 id="1-5-RDB：内存快照"><a href="#1-5-RDB：内存快照" class="headerlink" title="1.5 RDB：内存快照"></a>1.5 RDB：内存快照</h2><p>AOF记录日志的方法在宕机恢复时，恢复时需要逐一把AOF日志操作都执行一遍。如果操作日志非常多，Redis就会恢复得很缓慢，影响到正常使用。</p>
<p>和AOF相比，RDB记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把RDB文件读入内存，很快地完成恢复。</p>
<p>Redis的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是<strong>全量快照</strong>。</p>
<p>Redis提供了两个命令来生成RDB文件，分别是save和bgsave。</p>
<ul>
<li>save：在主线程中执行，会导致阻塞；</li>
<li>bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。</li>
</ul>
<p>bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件。<br>此时，如果主线程对这些数据也都是读操作（例如图中的键值对A），那么，主线程和bgsave子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave子进程会把这个副本数据写入RDB文件，而在这个过程中，主线程仍然可以直接修改原来的数据。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262151502.png"><br>这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。</p>
<p>如果频繁地执行全量快照，也会带来两方面的开销。</p>
<ol>
<li>频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</li>
<li>bgsave子进程需要通过fork操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁fork出bgsave子进程，这就会频繁阻塞主线程了。</li>
</ol>
<p>全量快照执行频率高的话会影响主线程性能下降，但是如果在两次执行全量快照的间隔中宕机，也会丢失一部分数据：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262154555.png"></p>
<p>在Redis4.0中提出了一个混合使用AOF日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用AOF日志记录这期间的所有命令操作。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262155848.png"><br>T1和T2时刻的修改，用AOF日志记录，等到第二次做全量快照时，就可以清空AOF日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。<br>这个方法既能享受到RDB文件快速恢复的好处，又能享受到AOF只记录操作命令的简单优势。</p>
<h2 id="1-6-数据同步：主从库实现数据一致"><a href="#1-6-数据同步：主从库实现数据一致" class="headerlink" title="1.6 数据同步：主从库实现数据一致"></a>1.6 数据同步：主从库实现数据一致</h2><p>我们总说的Redis具有高可靠性，这里有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF和RDB保证了前者，而对于后者，Redis的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。</p>
<p>多个副本为了保持一致，Redis提供了主从库模式，主从库之间采用的是读写分离的方式。</p>
<ul>
<li>读操作：主库、从库都可以接收；</li>
<li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262155473.png"><br>主从库模式采用了读写分离，所有数据的修改只会在主库上进行，主库有了最新的数据后，会同步给从库，这样，主从库的数据就是一致的。</p>
<h3 id="1-6-1-主从库第一次同步"><a href="#1-6-1-主从库第一次同步" class="headerlink" title="1.6.1 主从库第一次同步"></a>1.6.1 主从库第一次同步</h3><p>启动多个Redis实例的时候，它们相互之间就可以通过replicaof（Redis 5.0之前使用slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</p>
<p>例如，现在有实例1（ip：172.16.19.3）和实例2（ip：172.16.19.5），我们在实例2上执行以下这个命令后，实例2就变成了实例1的从库，并从实例1上复制数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof  172.16.19.3  6379</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262156548.png"></p>
<ol>
<li>第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。<br>从库给主库发送psync命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync命令包含了主库的runID和复制进度offset两个参数。<blockquote>
<ul>
<li>runID，是每个Redis实例启动时都会自动生成的一个随机ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的runID，所以将runID设为“？”。</li>
<li>offset，此时设为-1，表示第一次复制。</li>
</ul>
</blockquote>
</li>
</ol>
<p>主库收到psync命令后，会用FULLRESYNC响应（表示第一次复制采用全量复制，主库会把当前所有的数据都复制给从库）命令带上两个参数：主库runID和主库目前的复制进度offset，返回给从库。从库收到响应后，会记录下这两个参数。</p>
<ol start="2">
<li><p>在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的RDB文件。</p>
<blockquote>
<p>主库执行bgsave命令，生成RDB文件，接着将文件发给从库。从库接收到RDB文件后，会先清空当前数据库，然后加载RDB文件。这是因为从库在通过replicaof命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。<br>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。这些请求中的写操作并没有记录到刚刚生成的RDB文件中。为了保证主从库的数据一致性，主库会在内存中用专门的replication buffer，记录RDB文件生成后收到的所有写操作。</p>
</blockquote>
</li>
<li><p>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成RDB文件发送后，就会把此时replication buffer中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p>
</li>
</ol>
<p>经过以上三个阶段，主从库就完成了第一次全量复制数据同步。</p>
<h3 id="1-6-2-主从级联模式"><a href="#1-6-2-主从级联模式" class="headerlink" title="1.6.2 主从级联模式"></a>1.6.2 主从级联模式</h3><p>当有多个从库的时候，如果每个从库都从主库同步数据，对主库压力会很大。可以通过“主-从-从”模式将主库生成RDB和传输RDB的压力，以级联的方式分散到从库上。</p>
<p>在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof  所选从库的IP 6379</span><br></pre></td></tr></table></figure>
<p>如下图：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262156619.png"><br>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。</p>
<h3 id="1-6-3-主从库间网络异常断开"><a href="#1-6-3-主从库间网络异常断开" class="headerlink" title="1.6.3 主从库间网络异常断开"></a>1.6.3 主从库间网络异常断开</h3><p>主从库为了数据同步，需要一直保持长连接做命令传播，但是如果网络异常断开，则会导致主从库数据不一致。<br>从Redis 2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。</p>
<p>当主从库断连后，主库会把断连期间收到的写操作命令，写入replication buffer，同时也会把这些操作命令也写入repl_backlog_buffer这个缓冲区。<br>repl_backlog_buffer是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。<br>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是master_repl_offset。主库接收的新写操作越多，这个值就会越大。<br>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量slave_repl_offset也在不断增加。正常情况下，这两个偏移量基本相等。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262157814.png"><br>主从库的连接恢复之后，从库首先会给主库发送psync命令，并把自己当前的slave_repl_offset发给主库，主库会判断自己的master_repl_offset和slave_repl_offset之间的差距。<br>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset会大于slave_repl_offset。此时，主库只用把master_repl_offset和slave_repl_offset之间的命令操作同步给从库就行。</p>
<p>就像刚刚示意图的中间部分，主库和从库之间相差了put d e和put d f两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p>
<blockquote>
<p>但是，repl_backlog_buffer是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。<br>办法避免这一情况，一般而言，我们可以调整repl_backlog_size这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 &#x3D; 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即repl_backlog_size &#x3D; 缓冲空间大小 * 2，这也就是repl_backlog_size的最终值。</p>
</blockquote>
<h3 id="1-6-4-replication-buffer和repl-backlog-buffer的区别"><a href="#1-6-4-replication-buffer和repl-backlog-buffer的区别" class="headerlink" title="1.6.4 replication buffer和repl_backlog_buffer的区别"></a>1.6.4 replication buffer和repl_backlog_buffer的区别</h3><p>replication buffer是主从库在进行全量复制时，主库上用于和从库连接的客户端的buffer，而repl_backlog_buffer是为了支持从库增量复制，主库上用于持续保存写操作的一块专用buffer。</p>
<p>Redis主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个buffer，这个buffer就被称为replication buffer。Redis通过client_buffer配置项来控制这个buffer的大小。主库会给每个从库建立一个客户端，所以replication buffer不是共享的，而是每个从库都有一个对应的客户端。</p>
<p>repl_backlog_buffer是一块专用buffer，在Redis服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262158206.png"></p>
<h2 id="1-7-哨兵机制"><a href="#1-7-哨兵机制" class="headerlink" title="1.7 哨兵机制"></a>1.7 哨兵机制</h2><p>如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作，但是如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。<br>如果客户端发送的都是读操作请求，那还可以由从库继续提供服务，这在纯读的业务场景下还能被接受。但是，一旦有写操作请求了，按照主从库模式下的读写分离要求，需要由主库来完成写操作。此时，也没有实例可以来服务客户端的写操作请求了，如下图所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262159297.png"></p>
<p>Redis中使用哨兵机制，实现主从库自动切换，解决主从复制模式下故障转移问题。</p>
<h3 id="1-7-1-哨兵机制的基本流程"><a href="#1-7-1-哨兵机制的基本流程" class="headerlink" title="1.7.1 哨兵机制的基本流程"></a>1.7.1 哨兵机制的基本流程</h3><p>哨兵其实就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p>
<ol>
<li>监控是指哨兵进程在运行时，周期性地给所有的主从库发送PING命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。</li>
<li>主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</li>
<li>在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行replicaof命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262159602.png"></p>
<p>三个任务中，监控任务怎么确定主库下线，选主任务中最终怎么确定新的主库？</p>
<h3 id="1-7-2-主观下线和客观下线"><a href="#1-7-2-主观下线和客观下线" class="headerlink" title="1.7.2 主观下线和客观下线"></a>1.7.2 主观下线和客观下线</h3><p>哨兵进程会使用PING命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对PING命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。<br>为了降低误判率，并不能因为一个哨兵判断主库下线，就进行主从切换流程，<strong>通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群</strong>。<br>引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262200413.png"><br>当有N个哨兵实例时，最好要有N&#x2F;2 + 1个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由Redis管理员自行设定）。</p>
<h3 id="1-7-3-选定新主库"><a href="#1-7-3-选定新主库" class="headerlink" title="1.7.3 选定新主库"></a>1.7.3 选定新主库</h3><p>哨兵选择新主库的过程称为“筛选+打分”。简单来说，我们在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262200998.png"><br>在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。<br>具体怎么判断呢？你使用配置项down-after-milliseconds * 10。其中，down-after-milliseconds是我们认定主从库断连的最大连接超时时间。如果在down-after-milliseconds毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了10次，就说明这个从库的网络状况不好，不适合作为新主库。</p>
<p>完成了筛选后，接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库ID号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。</p>
<ol>
<li>优先级最高的从库得分高。</li>
</ol>
<p>用户可以通过slave-priority配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</p>
<ol start="2">
<li>和旧主库同步程度最接近的从库得分高。</li>
</ol>
<p>这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。</p>
<p>主从库同步时有个命令传播的过程。在这个过程中，主库会用master_repl_offset记录当前的最新写操作在repl_backlog_buffer中的位置，而从库会用slave_repl_offset这个值记录当前的复制进度。</p>
<p>此时，我们想要找的从库，它的slave_repl_offset需要最接近master_repl_offset。如果在所有从库中，有从库的slave_repl_offset最接近master_repl_offset，那么它的得分就最高，可以作为新主库。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262201250.png"><br>旧主库的master_repl_offset是1000，从库1、2和3的slave_repl_offset分别是950、990和900，那么，从库2就应该被选为新主库。<br>当然，如果有两个从库的slave_repl_offset值大小是一样的（例如，从库1和从库2的slave_repl_offset值都是990），我们就需要给它们进行第三轮打分了。</p>
<ol start="3">
<li>ID号小的从库得分高。</li>
</ol>
<p>每个实例都会有一个ID，这个ID就类似于这里的从库的编号。目前，Redis在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID号最小的从库得分最高，会被选为新主库。</p>
<h2 id="1-8-哨兵集群"><a href="#1-8-哨兵集群" class="headerlink" title="1.8 哨兵集群"></a>1.8 哨兵集群</h2><p>哨兵机制，它可以实现主从库的自动切换。通过部署多个实例，就形成了一个哨兵集群。哨兵集群中的多个实例共同判断，可以降低对主库下线的误判率。<br>实际上，一旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端。<br>在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的IP和端口，并没有配置其他哨兵的连接信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; </span><br></pre></td></tr></table></figure>
<p>这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。</p>
<h3 id="1-8-1-基于pub-sub机制的哨兵集群组成"><a href="#1-8-1-基于pub-sub机制的哨兵集群组成" class="headerlink" title="1.8.1 基于pub&#x2F;sub机制的哨兵集群组成"></a>1.8.1 基于pub&#x2F;sub机制的哨兵集群组成</h3><p>pub&#x2F;sub机制，也就是发布&#x2F;订阅机制。哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的IP地址和端口。<br>除了哨兵实例，我们自己编写的应用程序也可以通过Redis进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。<strong>只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换</strong>。<br>在主从集群中，主库上有一个名为“<strong>sentinel</strong>:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p>
<p>举个例子，具体说明一下。在下图中，哨兵1把自己的IP（172.16.19.3）和端口（26579）发布到“<strong>sentinel</strong>:hello”频道上，哨兵2和3订阅了该频道。那么此时，哨兵2和3就可以从这个频道直接获取哨兵1的IP地址和端口号。<br>然后，哨兵2、3可以和哨兵1建立网络连接。通过这个方式，哨兵2和3也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262201603.png"><br>以上机制可以让哨兵知道其他哨兵的存在，并建立连接，组成集群。</p>
<p>哨兵还需要知道从库的地址，以监控主从库的状态。这是由哨兵向主库发送INFO命令来完成的。就像下图所示，哨兵2给主库发送INFO命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵1和3可以通过相同的方法和从库建立连接。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262202434.png"></p>
<blockquote>
<p>通过pub&#x2F;sub机制，哨兵之间可以组成集群，同时，哨兵又通过INFO命令，获得了从库连接信息，也能和从库建立连接，并进行监控了。</p>
</blockquote>
<h3 id="1-8-2-基于pub-sub机制的客户端事件通知"><a href="#1-8-2-基于pub-sub机制的客户端事件通知" class="headerlink" title="1.8.2 基于pub&#x2F;sub机制的客户端事件通知"></a>1.8.2 基于pub&#x2F;sub机制的客户端事件通知</h3><p>主动库的切换，也需要让客户端知道，并且客户端也需要通过监控可以连接哨兵进行主从切换的过程，比如主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。</p>
<p>每个哨兵实例也提供pub&#x2F;sub机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。<br>以下，涉及几个关键事件，包括主库下线判断、新主库选定、从库重新配置。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262203662.png"><br>知道了这些频道之后，你就可以让客户端从哨兵这里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。</p>
<p>举个例子，你可以执行如下命令，来订阅“所有实例进入客观下线状态的事件”：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE +odown</span><br></pre></td></tr></table></figure>
<p>当然，你也可以执行如下命令，订阅所有的事件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PSUBSCRIBE  *</span><br></pre></td></tr></table></figure>
<p>当哨兵把新主库选择出来后，客户端就会看到下面的switch-master事件。这个事件表示主库已经切换了，新主库的IP地址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</span><br></pre></td></tr></table></figure>
<p>有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p>
<h3 id="1-8-3-由哪个哨兵执行主从切换？"><a href="#1-8-3-由哪个哨兵执行主从切换？" class="headerlink" title="1.8.3 由哪个哨兵执行主从切换？"></a>1.8.3 由哪个哨兵执行主从切换？</h3><p>确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。</p>
<p>在投票过程中，任何一个想成为Leader的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的quorum值。以3个哨兵为例，假设此时的quorum设置为2，那么，任何一个想成为Leader的哨兵只要拿到2张赞成票，就可以了。</p>
<p>如下图，展示一下3个哨兵、quorum为2的选举过程。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262203773.png"><br>在T1时刻，S1判断主库为“客观下线”，它想成为Leader，就先给自己投一张赞成票，然后分别向S2和S3发送命令，表示要成为Leader。</p>
<p>在T2时刻，S3判断主库为“客观下线”，它也想成为Leader，所以也先给自己投一张赞成票，再分别向S1和S2发送命令，表示要成为Leader。</p>
<p>在T3时刻，S1收到了S3的Leader投票请求。因为S1已经给自己投了一票Y，所以它不能再给其他哨兵投赞成票了，所以S1回复N表示不同意。同时，S2收到了T2时S3发送的Leader投票请求。因为S2之前没有投过票，它会给第一个向它发送投票请求的哨兵回复Y，给后续再发送投票请求的哨兵回复N，所以，在T3时，S2回复S3，同意S3成为Leader。</p>
<p>在T4时刻，S2才收到T1时S1发送的投票命令。因为S2已经在T3时同意了S3的投票请求，此时，S2给S1回复N，表示不同意S1成为Leader。发生这种情况，是因为S3和S2之间的网络传输正常，而S1和S2之间的网络传输可能正好拥塞了，导致投票请求传输慢了。</p>
<p>最后，在T5时刻，S1得到的票数是来自它自己的一票Y和来自S2的一票N。而S3除了自己的赞成票Y以外，还收到了来自S2的一票Y。此时，S3不仅获得了半数以上的Leader赞成票，也达到预设的quorum值（quorum为2），所以它最终成为了Leader。接着，S3会开始执行选主操作，而且在选定新主库后，会给其他从库和客户端通知新主库的信息。</p>
<p>在投票后，如果没有符合条件的哨兵被选出，哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的2倍），再重新选举。</p>
<blockquote>
<p>需要注意的是，如果哨兵集群只有2个实例，此时，一个哨兵要想成为Leader，必须获得2票，而不是1票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置3个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。</p>
</blockquote>
<h3 id="1-8-4-总结"><a href="#1-8-4-总结" class="headerlink" title="1.8.4 总结"></a>1.8.4 总结</h3><ul>
<li>基于pub&#x2F;sub机制的哨兵集群组成过程；</li>
<li>基于INFO命令的从库列表，这可以帮助哨兵和从库建立连接；</li>
<li>基于哨兵自身的pub&#x2F;sub功能，这实现了客户端和哨兵之间的事件通知。</li>
</ul>
<blockquote>
<p>最后，我想再给你分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。</p>
</blockquote>
<h2 id="1-9-切片集群"><a href="#1-9-切片集群" class="headerlink" title="1.9 切片集群"></a>1.9 切片集群</h2><p>当需要缓存的数据量很大，单实例无法满足的情况下，可以考虑使用切片集群。<br>切片集群，也叫分片集群，就是指启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。</p>
<p>如果要保存更多的数据有两个方案：</p>
<ol>
<li>纵向扩展：升级单个Redis实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的CPU。就像下图中，原来的实例内存是8GB，硬盘是50GB，纵向扩展后，内存增加到24GB，磁盘增加到150GB。</li>
<li>横向扩展：横向增加当前Redis实例的个数，就像下图中，原来使用1个8GB内存、50GB磁盘的实例，现在使用三个相同配置的实例。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262204211.png"></p>
<p>两种方案的优缺点：</p>
<ol>
<li>纵向方案</li>
</ol>
<p><strong>优点</strong>：实施起来简单、直接<br><strong>缺点</strong>：当使用RDB对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程fork子进程时就可能会阻塞（比如刚刚的例子中的情况）。会受到硬件和成本的限制。比如：把内存从32GB扩展到64GB还算容易，但是，要想扩充到1TB，就会面临硬件容量和成本上的限制了。</p>
<ol start="2">
<li>横向扩展</li>
</ol>
<p><strong>优点</strong>：只用增加Redis的实例个数就行了，不用担心单个实例的硬件和成本限制。在面向百万、千万级别的用户规模时，横向扩展的Redis切片集群会是一个非常好的选择。<br><strong>缺点</strong>：维护多个实例，会更复杂。涉及到多个实例的分布式管理问题。</p>
<h3 id="1-9-1-数据切片和实例的对应分布关系"><a href="#1-9-1-数据切片和实例的对应分布关系" class="headerlink" title="1.9.1 数据切片和实例的对应分布关系"></a>1.9.1 数据切片和实例的对应分布关系</h3><p>在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？<br>切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在Redis 3.0之前，官方并没有针对切片集群提供具体的方案。从3.0开始，官方提供了一个名为Redis Cluster的方案，用于实现切片集群。Redis Cluster方案中就规定了数据和实例的对应规则。</p>
<p>Redis Cluster方案采用哈希槽（Hash Slot，接下来我会直接称之为Slot），来处理数据和实例之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中。<br>具体的映射过程分为两大步：</p>
<ol>
<li>根据键值对的key，按照CRC16算法计算一个16 bit的值；</li>
<li>用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。</li>
</ol>
<p>在部署Redis Cluster方案时，可以使用cluster create命令创建集群，此时，Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有N个实例，那么，每个实例上的槽个数为16384&#x2F;N个。<br>也可以使用cluster meet命令手动建立实例间的连接，形成集群，再使用cluster addslots命令，指定每个实例上的哈希槽个数。</p>
<p><strong>示例：</strong> 假设集群中不同Redis实例的内存大小配置不一，如果把哈希槽均分在各个实例上，在保存相同数量的键值对时，和内存大的实例相比，内存小的实例就会有更大的容量压力。遇到这种情况时，你可以根据不同实例的资源配置情况，使用cluster addslots命令手动分配哈希槽。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262204758.png"><br>示意图中的切片集群一共有3个实例，同时假设有5个哈希槽，我们首先可以通过下面的命令手动分配哈希槽：实例1保存哈希槽0和1，实例2保存哈希槽2和3，实例3保存哈希槽4。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1</span><br><span class="line">redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3</span><br><span class="line">redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4</span><br></pre></td></tr></table></figure>
<p>在集群运行的过程中，key1和key2计算完CRC16值后，对哈希槽总个数5取模，再根据各自的模数结果，就可以被映射到对应的实例1和实例3上了。</p>
<blockquote>
<p>在手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作。</p>
</blockquote>
<h3 id="1-9-2-客户端如何定位数据"><a href="#1-9-2-客户端如何定位数据" class="headerlink" title="1.9.2 客户端如何定位数据"></a>1.9.2 客户端如何定位数据</h3><p>客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，但是最终Redis实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</p>
<p>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。<br>但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：</p>
<ul>
<li>在集群中，实例有新增或删除，Redis需要重新分配哈希槽；</li>
<li>为了负载均衡，Redis需要把哈希槽在所有实例上重新分布一遍。</li>
</ul>
<p>针对哈希槽变化的信息，客户端无法感知，每次还是会访问缓存中的信息。<br>针对这种情况，Redis Cluster方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。</p>
<p>当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的MOVED命令响应结果，这个结果中就包含了新实例的访问地址。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key</span><br><span class="line">(error) MOVED 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure>
<p>其中，MOVED命令表示，客户端请求的键值对所在的哈希槽13320，实际是在172.16.19.5这个实例上。通过返回的MOVED命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和172.16.19.5连接，并发送操作请求了。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262259045.png"><br>如上图，slot2迁移到了实例3，客户端第一次根据缓存信息，还是访问了实例2，实例2给客户端返回一条MOVED命令，把Slot 2的最新位置（也就是在实例3上），返回给客户端，客户端就会再次向实例3发送请求，同时还会更新本地缓存，把Slot 2与实例的对应关系更新过来。</p>
<p>以上的示例，是Slot 2中的数据已经全部迁移到了实例3。在实际应用时，如果Slot 2中的数据比较多，就可能会出现一种情况：客户端向实例2发送请求，但此时，Slot 2中的数据只有一部分迁移到了实例3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条ASK报错信息，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key</span><br><span class="line">(error) ASK 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure>
<p>这个结果中的ASK命令就表示，客户端请求的键值对所在的哈希槽13320，在172.16.19.5这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给172.16.19.5这个实例发送一个ASKING命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送GET命令，以读取数据。<br>如下：Slot 2正在从实例2往实例3迁移，key1和key2已经迁移过去，key3和key4还在实例2。客户端向实例2请求key2后，就会收到实例2返回的ASK命令。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262206159.png"></p>
<p>ASK命令表示两层含义：</p>
<ol>
<li>表明Slot数据还在迁移中；</li>
<li>ASK命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例3发送ASKING命令，然后再发送操作命令。</li>
</ol>
<p>和MOVED命令不同，ASK命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求Slot 2中的数据，它还是会给实例2发送请求。这也就是说，ASK命令的作用只是让客户端能给新实例发送一次请求，而不像MOVED命令那样，会更改本地缓存，让后续所有命令都发往新实例。</p>
<h1 id="2-实践篇"><a href="#2-实践篇" class="headerlink" title="2 实践篇"></a>2 实践篇</h1><h2 id="2-11“万金油”的String，为什么不好用了？"><a href="#2-11“万金油”的String，为什么不好用了？" class="headerlink" title="2.11“万金油”的String，为什么不好用了？"></a>2.11“万金油”的String，为什么不好用了？</h2><h3 id="2-11-1-string类型如何保存数据的"><a href="#2-11-1-string类型如何保存数据的" class="headerlink" title="2.11.1 string类型如何保存数据的"></a>2.11.1 string类型如何保存数据的</h3><p>举一个示例，用10位数来表示图片ID和图片存储对象ID，例如，图片ID为1101000051，它在存储系统中对应的ID号是3301000051，在图片数量巨大的场景下。</p>
<p>如果保存1亿张图片，使用string类型，大约用6.4GB的内存。一个图片ID和图片存储对象ID的记录平均用了64字节。<br>来分析一下。图片ID和图片存储对象ID都是10位数，我们可以用两个8字节的Long类型表示这两个ID。因为8字节的Long类型最大可以表示2的64次方的数值，所以肯定可以表示10位数。但是，为什么String类型却用了64字节呢？<br>通过对string类型进行分析，在记录实际数据时，string类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫做元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了。</p>
<p>String类型具体是怎么保存数据的呢？</p>
<ol>
<li>当你保存64位有符号整数时，String类型会把它保存为一个8字节的Long类型整数，这种保存方式通常也叫作int编码方式。</li>
<li>当你保存的数据中包含字符时，String类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：</li>
</ol>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262207482.png"></p>
<ul>
<li>buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis会自动在数组最后加一个“\0”，这就会额外占用1个字节的开销。</li>
<li>len：占4个字节，表示buf的已用长度。</li>
<li>alloc：也占个4字节，表示buf的实际分配长度，一般大于len。</li>
</ul>
<p>在SDS中，buf保存实际数据，而len和alloc本身其实是SDS结构体的额外开销。</p>
<p>对于String类型来说，除了SDS的额外开销，还有一个来自于RedisObject结构体的开销。<br>因为Redis的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据。<br>一个RedisObject包含了8字节的元数据和一个8字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向String类型的SDS结构所在的内存地址，可以看一下下面的示意图。关于RedisObject的具体结构细节，我会在后面的课程中详细介绍，现在你只要了解它的基本结构和元数据开销就行了。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262208668.png"><br>为了节省内存空间，Redis还对Long类型整数和SDS的内存布局做了专门的设计。<br>一方面，当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。<br>另一方面，当保存的是字符串数据，并且字符串小于等于44字节时，RedisObject中的元数据、指针和SDS是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为embstr编码方式。<br>当然，当字符串大于44字节时，SDS的数据量就开始变多了，Redis就不再把SDS和RedisObject布局在一起了，而是会给SDS分配独立的空间，并用指针指向SDS结构。这种布局方式被称为raw编码模式。<br>为了帮助你理解int、embstr和raw这三种编码模式，我画了一张示意图，如下所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262209860.png"></p>
<p>现在来计算下存储上边示例的图片需要的内存使用量。<br>因为10位数的图片ID和图片存储对象ID是Long类型整数，所以可以直接用int编码的RedisObject保存。每个int编码的RedisObject元数据部分占8字节，指针部分被直接赋值为8字节的整数了。此时，每个ID会使用16字节，加起来一共是32字节。<br>为了保存string类型的key，Redis会使用全局哈希表，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对。dictEntry结构中有三个8字节的指针，分别指向key、value以及下一个dictEntry，三个指针共24字节，如下图所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262209344.png"><br>然后由于Redis使用的内存分配库jemalloc，在分配内存时会根据我们申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，这样可以减少频繁分配的次数。所以在申请24字节空间时，会分配32字节。</p>
<h3 id="2-11-2-选择节省内存的数据结构"><a href="#2-11-2-选择节省内存的数据结构" class="headerlink" title="2.11.2 选择节省内存的数据结构"></a>2.11.2 选择节省内存的数据结构</h3><p>Redis有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。<br>表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量，以及列表中的entry个数。压缩列表尾还有一个zlend，表示列表结束。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262210821.png"><br>压缩列表之所以能节省内存，就在于它是用一系列连续的entry保存数据。每个entry的元数据包括下面几部分。</p>
<ul>
<li>prev_len，表示前一个entry的长度。prev_len有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。</li>
<li>len：表示自身长度，4字节；</li>
<li>encoding：表示编码方式，1字节；</li>
<li>content：保存实际数据。</li>
</ul>
<p>这些entry会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。<br>Redis基于压缩列表实现了List、Hash和Sorted Set这样的集合类型，这样做的最大好处就是节省了dictEntry的开销。当你用String类型时，一个键值对就有一个dictEntry，要用32字节空间。但采用集合类型时，一个key就对应一个集合的数据，能保存的数据多了很多，但也只用了一个dictEntry，这样就节省了内存。</p>
<ul>
<li>使用集合类型保存单值键值对</li>
</ul>
<p>在保存单值的键值对时，可以采用基于Hash类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为Hash集合的key，后一部分作为Hash集合的value，这样一来，我们就可以把单值数据保存到Hash集合中了。<br>以图片ID 1101000060和图片存储对象ID 3302000080为例，我们可以把图片ID的前7位（1101000）作为Hash类型的键，把图片ID的最后3位（060）和图片存储对象ID分别作为Hash类型值中的key和value。<br>按照这种设计方法，我在Redis中插入了一组图片ID及其存储对象ID的记录，并且用info命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了16字节，如下所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262210884.png"><br>在使用String类型时，每个记录需要消耗64字节，这种方式却只用了16字节，所使用的内存空间是原来的1&#x2F;4，满足了我们节省内存空间的需求。</p>
<p>Redis Hash类型的两种底层实现结构，分别是压缩列表和哈希表。<br>Hash类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash类型就会用哈希表来保存数据了。<br>这两个阈值分别对应以下两个配置项：</p>
<ul>
<li>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</li>
<li>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</li>
</ul>
<p>如果我们往Hash集合中写入的元素个数超过了hash-max-ziplist-entries，或者写入的单个元素大小超过了hash-max-ziplist-value，Redis就会自动把Hash类型的实现结构由压缩列表转为哈希表。<br>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在Hash集合中的元素个数。所以，在刚才的二级编码中，我们只用图片ID最后3位作为Hash集合的key，也就保证了Hash集合的元素个数不超过1000，同时，我们把hash-max-ziplist-entries设置为1000，这样一来，Hash集合就可以一直使用压缩列表来节省内存空间了。</p>
<h2 id="2-12-有一亿个keys要统计，使用Redis实现统计"><a href="#2-12-有一亿个keys要统计，使用Redis实现统计" class="headerlink" title="2.12 有一亿个keys要统计，使用Redis实现统计"></a>2.12 有一亿个keys要统计，使用Redis实现统计</h2><p>比如要保存如下一些信息：</p>
<ul>
<li>手机App中的每天的用户登录信息：一天对应一系列用户ID或移动设备ID；</li>
<li>电商网站上商品的用户评论列表：一个商品对应了一系列的评论；</li>
<li>用户在手机App上的签到打卡信息：一天对应一系列用户的签到记录；</li>
<li>应用网站上的网页访问信息：一个网页对应一系列的访问点击。</li>
</ul>
<p>Redis集合类型的特点就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，例如：</p>
<ul>
<li>在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；</li>
<li>在电商网站的商品评论中，需要统计评论列表中的最新评论；</li>
<li>在签到打卡中，需要统计一个月内连续打卡的用户数；</li>
<li>在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。</li>
</ul>
<p>要想选择合适的集合，我们就得了解常用的集合统计模式，下边介绍集合类型常见的四种统计模式，包括聚合统计、排序统计、二值状态统计和基数统计。</p>
<h3 id="2-12-1-聚合统计"><a href="#2-12-1-聚合统计" class="headerlink" title="2.12.1 聚合统计"></a>2.12.1 聚合统计</h3><p>聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。<br>在刚才提到的场景中，统计手机App每天的新增用户数和第二天的留存用户数，正好对应了聚合统计。<br>要完成这个统计任务，我们可以用一个集合记录所有登录过App的用户ID，同时，用另一个集合记录每一天登录过App的用户ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。<br>记录所有登录过App的用户ID还是比较简单的，我们可以直接使用Set类型，把key设置为user280680，表示记录的是用户ID，value就是一个Set集合，里面是所有登录过App的用户ID，我们可以把这个Set叫作累计用户Set。<br>每日用户Set可以在key中加入日期信息，比如：</p>
<ul>
<li>key是user280680以及当天日期，例如user280680:20200803；</li>
<li>value是Set集合，记录当天登录的用户ID。</li>
</ul>
<p>在统计每天的新增用户时，我们只用计算每日用户Set和累计用户Set的差集就行。<br>假设我们的手机App在2020年8月3日上线，那么，8月3日前是没有用户的。此时，累计用户Set是空集，当天登录的用户ID会被记录到 key为user280680:20200803的Set中。所以，user280680:20200803这个Set中的用户就是当天的新增用户。<br>然后，我们计算累计用户Set和user280680:20200803 Set的并集结果，结果保存在user280680这个累计用户Set中，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUNIONSTORE user280680 user280680 user280680:20200803</span><br></pre></td></tr></table></figure>
<p>此时，user280680这个累计用户Set中就有了8月3日的用户ID。等到8月4日再统计时，我们把8月4日登录的用户ID记录到user280680:20200804 的Set中。接下来，我们执行SDIFFSTORE命令计算累计用户Set和user280680:20200804 Set的差集，结果保存在key为user:new的Set中，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SDIFFSTORE  user:new  user280680:20200804 user280680  </span><br></pre></td></tr></table></figure>
<p>可以看到，这个差集中的用户ID在user280680:20200804 的Set中存在，但是不在累计用户Set中。所以，user:new这个Set中记录的就是8月4日的新增用户。<br>当要计算8月4日的留存用户时，我们只需要再计算user280680:20200803 和 user280680:20200804两个Set的交集，就可以得到同时在这两个集合中的用户ID了，这些就是在8月3日登录，并且在8月4日留存的用户。执行的命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SINTERSTORE user280680:rem user280680:20200803 user280680:20200804</span><br></pre></td></tr></table></figure>
<p>当你需要对多个集合进行聚合计算时，Set类型会是一个非常不错的选择。但是Set的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致Redis实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p>
<h3 id="2-12-2-排序统计"><a href="#2-12-2-排序统计" class="headerlink" title="2.12.2 排序统计"></a>2.12.2 排序统计</h3><p>通过电商网站上查看最新评论的场景，可以看下有序集合的使用方式。<br>在Redis常用的4个集合类型中（List、Hash、Set、Sorted Set），List和Sorted Set就属于有序集合。<br>List是按照元素进入List的顺序进行排序的，而Sorted Set可以根据元素的权重来排序。<br>使用List保存评论时，评论在分页时，如果此时新添加了评论，则评论在List中的位置会发生变化，导致分页展示评论时出问题。<br>可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到Sorted Set中。Sorted Set的ZRANGEBYSCORE命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set也能通过ZRANGEBYSCORE命令准确地获取到按序排列的数据。</p>
<p>假设越新的评论权重越大，目前最新评论的权重是N，我们执行下面的命令时，就可以获得最新的10条评论：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE comments N-9 N</span><br></pre></td></tr></table></figure>
<p>所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用Sorted Set。</p>
<h3 id="2-12-3-二值状态统计"><a href="#2-12-3-二值状态统计" class="headerlink" title="2.12.3 二值状态统计"></a>2.12.3 二值状态统计</h3><p>在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态，在签到统计时，每个用户一天的签到用1个bit位就能表示，一个月（假设是31天）的签到情况用31个bit位就可以，而一年的签到也只需要用365个bit位，根本不用太复杂的集合类型。这个时候，我们就可以选择Bitmap。这是Redis提供的扩展数据类型。<br>Bitmap本身是用String类型作为底层数据结构实现的一种统计二值状态的数据类型。String类型是会保存为二进制的字节数组，所以，Redis就把字节数组的每个bit位利用起来，用来表示一个元素的二值状态。你可以把Bitmap看作是一个bit数组。<br>Bitmap提供了GETBIT&#x2F;SETBIT操作，使用一个偏移值offset对bit数组的某一个bit位进行读和写。不过，需要注意的是，Bitmap的偏移量是从0开始算的，也就是说offset的最小值是0。当使用SETBIT对一个bit位进行写操作时，这个bit位会被设置为1。Bitmap还提供了BITCOUNT操作，用来统计这个bit数组中所有“1”的个数。</p>
<p>假设我们要统计ID 3000的用户在2020年8月份的签到情况，就可以按照下面的步骤进行操作。</p>
<ol>
<li>执行下面的命令，记录该用户8月3号已签到。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT uid:sign:3000:202008 2 1</span><br></pre></td></tr></table></figure></li>
<li>检查该用户8月3日是否签到。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT uid:sign:3000:202008 2</span><br></pre></td></tr></table></figure></li>
<li>统计该用户在8月份的签到次数。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITCOUNT uid:sign:3000:202008</span><br></pre></td></tr></table></figure></li>
</ol>
<p>如果记录了1亿个用户10天的签到情况，你有办法统计出这10天连续签到的用户总数吗？<br>在介绍具体的方法之前，我们要先知道，Bitmap支持用BITOP命令对多个Bitmap按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的Bitmap中。<br>可以把每天的日期作为key，每个key对应一个1亿位的Bitmap，每一个bit对应一个用户当天的签到情况。<br>接下来，我们对10个Bitmap做“与”操作，得到的结果也是一个Bitmap。在这个Bitmap中，只有10天都签到的用户对应的bit位上的值才会是1。最后，我们可以用BITCOUNT统计下Bitmap中的1的个数，这就是连续签到10天的用户总数了。<br>现在，我们可以计算一下记录了10天签到情况后的内存开销。每天使用1个1亿位的Bitmap，大约占12MB的内存（10^8&#x2F;8&#x2F;1024&#x2F;1024），10天的Bitmap的内存开销约为120MB，内存压力不算太大。不过，在实际应用时，最好对Bitmap设置过期时间，让Redis自动删除不再需要的签到记录，以节省内存开销。</p>
<p>所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用Bitmap，因为它只用一个bit位就能表示0或1。在记录海量数据时，Bitmap能够有效地节省内存空间。</p>
<h3 id="2-12-4-基数统计"><a href="#2-12-4-基数统计" class="headerlink" title="2.12.4 基数统计"></a>2.12.4 基数统计</h3><p>统计访问一个网页的用户数，网页可能很火爆，有千万人访问，一个用户也可能访问多个，只算一次。<br>以上的基数统计场景可以使用HyperLogLog，的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。<br>在Redis中，每个 HyperLogLog只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的Set和Hash类型相比，HyperLogLog就非常节省空间。<br>在统计UV时，你可以用PFADD命令（用于向HyperLogLog中添加新元素）把访问页面的每个用户都添加到HyperLogLog中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFADD page1:uv user1 user2 user3 user4 user5</span><br></pre></td></tr></table></figure>
<p>接下来，就可以用PFCOUNT命令直接获得page1的UV值了，这个命令的作用就是返回HyperLogLog的统计结果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFCOUNT page1:uv</span><br></pre></td></tr></table></figure>

<h3 id="2-12-5-总结"><a href="#2-12-5-总结" class="headerlink" title="2.12.5 总结"></a>2.12.5 总结</h3><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221119181247.png" alt="20221119181247"><br>Set和Sorted Set都支持多种聚合统计，不过，对于差集计算来说，只有Set支持。Bitmap也能做多个Bitmap间的聚合计算，包括与、或和异或操作。<br>当需要进行排序统计时，List中的元素虽然有序，但是一旦有新元素插入，原来的元素在List中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而Sorted Set本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。<br>如果我们记录的数据只有0和1两个值的状态，Bitmap会是一个很好的选择，这主要归功于Bitmap对于一个数据只用1个bit记录，可以节省内存。<br>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用HyperLogLog。</p>
<h2 id="2-13-GEO是什么？还可以定义新的数据类型吗？"><a href="#2-13-GEO是什么？还可以定义新的数据类型吗？" class="headerlink" title="2.13 GEO是什么？还可以定义新的数据类型吗？"></a>2.13 GEO是什么？还可以定义新的数据类型吗？</h2><h3 id="2-13-1-GEO的底层结构"><a href="#2-13-1-GEO的底层结构" class="headerlink" title="2.13.1 GEO的底层结构"></a>2.13.1 GEO的底层结构</h3><p>GEO的底层结构就是用Sorted Set来实现的。<br>场景：查看附近车辆，每辆车由经纬度信息和车辆ID<br>在保存车辆ID和经纬度信息时考虑使用Sorted Set类型，<br>用Sorted Set来保存车辆的经纬度信息时，Sorted Set的元素是车辆ID，元素的权重分数是经纬度信息，如下图所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221206101635.png" alt="20221206101635"><br>Sorted Set元素的权重分数是一个浮点数（float类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那具体该怎么进行保存呢？<br>这就要用到GEO类型中的GeoHash编码了。</p>
<h3 id="2-13-2-GeoHash的编码方法"><a href="#2-13-2-GeoHash的编码方法" class="headerlink" title="2.13.2 GeoHash的编码方法"></a>2.13.2 GeoHash的编码方法</h3><p>为了能高效地对经纬度进行比较，Redis采用了业界广泛使用的GeoHash编码方法，这个方法的基本原理就是“二分区间，区间编码”。<br>当我们要对一组经纬度进行GeoHash编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。</p>
<p>首先，我们来看下经度和纬度的单独编码过程。<br>对于一个地理位置信息来说，它的经度范围是[-180,180]。GeoHash编码会把一个经度值编码成一个N位的二进制值，我们来对经度范围[-180,180]做N次的二分区操作，其中N可以自定义。<br>在进行第一次二分区时，经度范围[-180,180]会被分成两个子区间：[-180,0)和[0,180]（我称之为左、右分区）。此时，我们可以查看一下要编码的经度值落在了左分区还是右分区。如果是落在左分区，我们就用0表示；如果落在右分区，就用1表示。这样一来，每做完一次二分区，我们就可以得到1位编码值。以此类推</p>
<p>示例：对经度值为116.37，用5位编码值（就是N&#x3D;5，做5次分区）<br>先做第一次二分区操作，把经度区间[-180,180]分成了左分区[-180,0)和右分区[0,180]，此时，经度值116.37是属于右分区[0,180]，所以，我们用1表示第一次二分区后的编码值。以此类推。<br>按照这种方法，做完5次分区后，我们把经度值116.37定位在[112.5, 123.75]这个区间，并且得到了经度值的5位编码值，即11010。这个编码过程如下表所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221206102240.png" alt="20221206102240"><br>对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值39.86的编码过程。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262222994.png"><br>当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从0开始，奇数位从1开始。<br>刚刚计算的经纬度（116.37，39.86）的各自编码值是11010和10111，组合之后，第0位是经度的第0位1，第1位是纬度的第0位1，第2位是经度的第1位1，第3位是纬度的第1位0，以此类推，就能得到最终编码值1110011101，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221206102423.png" alt="20221206102423"><br>用了GeoHash编码后，原来无法用一个权重分数表示的一组经纬度（116.37，39.86）就可以用1110011101这一个值来表示，就可以保存为Sorted Set的权重分数了。<br>使用GeoHash编码后，我们相当于把整个地理空间划分成了一个个方格，每个方格对应了GeoHash中的一个分区。<br>举个例子。我们把经度区间[-180,180]做一次二分区，把纬度区间[-90,90]做一次二分区，就会得到4个分区。我们来看下它们的经度和纬度范围以及对应的GeoHash组合编码。</p>
<ul>
<li>分区一：[-180,0)和[-90,0)，编码00；</li>
<li>分区二：[-180,0)和[0,90]，编码01；</li>
<li>分区三：[0,180]和[-90,0)，编码10；</li>
<li>分区四：[0,180]和[0,90]，编码11。</li>
</ul>
<p>这4个分区对应了4个方格，每个方格覆盖了一定范围内的经纬度值，分区越多，每个方格能覆盖到的地理空间就越小，也就越精准。我们把所有方格的编码值映射到一维空间时，相邻方格的GeoHash编码值基本也是接近的，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221206102557.png" alt="20221206102557"><br>所以，我们使用Sorted Set范围查询得到的相近编码值，在实际的地理空间上，也是相邻的方格，这就可以实现LBS应用“搜索附近的人或物”的功能了。<br>不过，我要提醒你一句，有的编码值虽然在大小上接近，但实际对应的方格却距离比较远。例如，我们用4位来做GeoHash编码，把经度区间[-180,180]和纬度区间[-90,90]各分成了4个分区，一共16个分区，对应了16个方格。编码值为0111和1000的两个方格就离得比较远，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221206102613.png" alt="20221206102613"><br>所以，为了避免查询不准确问题，我们可以同时查询给定经纬度所在的方格周围的4个或8个方格。</p>
<h3 id="2-13-3-如何操作GEO类型"><a href="#2-13-3-如何操作GEO类型" class="headerlink" title="2.13.3 如何操作GEO类型"></a>2.13.3 如何操作GEO类型</h3><p>在使用GEO类型时，我们经常会用到两个命令，分别是GEOADD和GEORADIUS。</p>
<ul>
<li>GEOADD命令：用于把一组经纬度信息和相对应的一个ID记录到GEO类型集合中；</li>
<li>GEORADIUS命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。</li>
</ul>
<p>假设车辆ID是33，经纬度位置是（116.034579，39.030452），我们可以用一个GEO集合保存所有车辆的经纬度，集合key是cars:locations。执行下面的这个命令，就可以把ID号为33的车辆的当前经纬度位置存入GEO集合中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEOADD cars:locations 116.034579 39.030452 33</span><br></pre></td></tr></table></figure>
<p>当用户想要寻找自己附近的网约车时，LBS应用就可以使用GEORADIUS命令。<br>例如，LBS应用执行下面的命令时，Redis会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的5公里内的车辆信息，并返回给LBS应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10</span><br></pre></td></tr></table></figure>

<h3 id="2-13-4-如何自定义数据类型？"><a href="#2-13-4-如何自定义数据类型？" class="headerlink" title="2.13.4 如何自定义数据类型？***"></a>2.13.4 如何自定义数据类型？***</h3><h2 id="2-14-在Redis中保存时间序列数据"><a href="#2-14-在Redis中保存时间序列数据" class="headerlink" title="2.14 在Redis中保存时间序列数据"></a>2.14 在Redis中保存时间序列数据</h2><h3 id="2-14-1-时间序列数据的读写特点"><a href="#2-14-1-时间序列数据的读写特点" class="headerlink" title="2.14.1 时间序列数据的读写特点"></a>2.14.1 时间序列数据的读写特点</h3><p>场景：要求记录近万台设备的实时状态信息，包括设备ID、压力、温度、湿度，以及对应的时间戳。<br>时间序列数据的写入主要就是插入新数据，而不是更新一个已存在的数据，也就是说，一个时间序列数据被记录后通常就不会变了，因为它就代表了一个设备在某个时刻的状态值（例如，一个设备在某个时刻的温度测量值，一旦记录下来，这个值本身就不会再变了）。</p>
<blockquote>
<p>种数据的写入特点很简单，就是插入数据快，这就要求我们选择的数据类型，在进行数据插入时，复杂度要低，尽量不要阻塞。</p>
</blockquote>
<p>时间序列数据的“读”操作有什么特点：</p>
<ul>
<li>对单条记录的查询（例如查询某个设备在某一个时刻的运行状态信息，对应的就是这个设备的一条记录）</li>
<li>对某个时间范围内的数据的查询（例如每天早上8点到10点的所有设备的状态信息）。</li>
<li>对某个时间范围内的数据做聚合计算（包括计算均值、最大&#x2F;最小值、求和等）</li>
</ul>
<p>弄清楚了时间序列数据的读写特点，接下来我们就看看如何在Redis中保存这些数据。我们来分析下：针对时间序列数据的“写要快”，Redis的高性能写特性直接就可以满足了；而针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis提供了保存时间序列数据的两种方案，分别可以基于Hash和Sorted Set实现，以及基于RedisTimeSeries模块实现。</p>
<h3 id="2-14-2-基于Hash和Sorted-Set保存时间序列数据"><a href="#2-14-2-基于Hash和Sorted-Set保存时间序列数据" class="headerlink" title="2.14.2 基于Hash和Sorted Set保存时间序列数据"></a>2.14.2 基于Hash和Sorted Set保存时间序列数据</h3><p>可以考虑使用Hash集合记录设备的温度值示意图如下：</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221207112556.png" alt="20221207112556"></p>
<p>当我们想要查询某个时间点或者是多个时间点上的温度数据时，直接使用HGET命令或者HMGET命令，就可以分别获得Hash集合中的一个key和多个key的value值了。<br>举个例子。我们用HGET命令查询202008030905这个时刻的温度值，使用HMGET查询202008030905、202008030907、202008030908这三个时刻的温度值，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HGET device:temperature 202008030905</span><br><span class="line">&quot;25.1&quot;</span><br><span class="line"></span><br><span class="line">HMGET device:temperature 202008030905 202008030907 202008030908</span><br><span class="line">1) &quot;25.1&quot;</span><br><span class="line">2) &quot;25.9&quot;</span><br><span class="line">3) &quot;24.9&quot;</span><br></pre></td></tr></table></figure>
<p><strong>Hash类型有个短板：它并不支持对数据进行范围查询。</strong><br>为了能同时支持按时间戳范围的查询，可以用Sorted Set来保存时间序列数据，因为它能够根据元素的权重分数来排序。我们可以把时间戳作为Sorted Set集合的元素分数，把时间点上记录的数据作为元素本身。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221207112729.png" alt="20221207112729"><br>使用Sorted Set保存数据后，我们就可以使用ZRANGEBYSCORE命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值了。如下所示，我们来查询一下在2020年8月3日9点7分到9点10分间的所有温度值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE device:temperature 202008030907 202008030910</span><br><span class="line">1) &quot;25.9&quot;</span><br><span class="line">2) &quot;24.9&quot;</span><br><span class="line">3) &quot;25.3&quot;</span><br><span class="line">4) &quot;25.2&quot;</span><br></pre></td></tr></table></figure>
<p>同时使用Hash和Sorted Set，可以满足单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题，也就是我们要解答的第二个问题：如何保证写入Hash和Sorted Set是一个原子性的操作呢？</p>
<p>可以使用Redis中的事务机制满足原子操作，MULTI和EXEC命令。</p>
<ul>
<li>MULTI命令：表示一系列原子性操作的开始。收到这个命令后，Redis就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。</li>
<li>EXEC命令：表示一系列原子性操作的结束。一旦Redis收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，Redis开始执行刚才放到内部队列中的所有命令操作。</li>
</ul>
<p>以保存设备状态信息的需求为例，我们执行下面的代码，把设备在2020年8月3日9时5分的温度，分别用HSET命令和ZADD命令写入Hash集合和Sorted Set集合。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; HSET device:temperature 202008030911 26.8</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; ZADD device:temperature 202008030911 26.8</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; EXEC</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br></pre></td></tr></table></figure>
<p>可以看到，首先，Redis收到了客户端执行的MULTI命令。然后，客户端再执行HSET和ZADD命令后，Redis返回的结果为“QUEUED”，表示这两个命令暂时入队，先不执行；执行了EXEC命令后，HSET命令和ZADD命令才真正执行，并返回成功结果（结果值为1）。<br>存取的问题解决了，下边需要解决聚合计算的问题，如果把数据读到客户端再计算，大量数据在Redis实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。</p>
<h3 id="2-14-3-基于RedisTimeSeries模块保存时间序列数据"><a href="#2-14-3-基于RedisTimeSeries模块保存时间序列数据" class="headerlink" title="2.14.3 基于RedisTimeSeries模块保存时间序列数据"></a>2.14.3 基于RedisTimeSeries模块保存时间序列数据</h3><p>RedisTimeSeries是Redis的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在Redis实例上直接对数据进行按时间范围的聚合计算。<br>因为RedisTimeSeries不属于Redis的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库redistimeseries.so，再使用loadmodule命令进行加载，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loadmodule redistimeseries.so</span><br></pre></td></tr></table></figure>
<p>当用于时间序列数据存取时，RedisTimeSeries的操作主要有5个：</p>
<ul>
<li>用TS.CREATE命令创建时间序列数据集合；</li>
<li>用TS.ADD命令插入数据；</li>
<li>用TS.GET命令读取最新数据；</li>
<li>用TS.MGET命令按标签过滤查询数据集合；</li>
<li>用TS.RANGE支持聚合计算的范围查询。</li>
</ul>
<ol>
<li>用TS.CREATE命令创建一个时间序列数据集合</li>
</ol>
<p>在TS.CREATE命令中，我们需要设置时间序列数据集合的key和数据的过期时间（以毫秒为单位）。此外，我们还可以为数据集合设置标签，来表示数据集合的属性。</p>
<p>例如，我们执行下面的命令，创建一个key为device:temperature、数据有效期为600s的时间序列数据集合。也就是说，这个集合中的数据创建了600s后，就会被自动删除。最后，我们给这个集合设置了一个标签属性{device_id:1}，表明这个数据集合中记录的是属于设备ID号为1的数据。</p>
<ol start="2">
<li>用TS.ADD命令插入数据，用TS.GET命令读取最新数据</li>
</ol>
<p>可以用TS.ADD命令往时间序列集合中插入数据，包括时间戳和具体的数值，并使用TS.GET命令读取数据集合中的最新一条数据。</p>
<p>例如，我们执行下列TS.ADD命令时，就往device:temperature集合中插入了一条数据，记录的是设备在2020年8月3日9时5分的设备温度；再执行TS.GET命令时，就会把刚刚插入的最新数据读取出来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TS.ADD device:temperature 1596416700 25.1</span><br><span class="line">1596416700</span><br><span class="line"></span><br><span class="line">TS.GET device:temperature </span><br><span class="line">25.1</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>用TS.MGET命令按标签过滤查询数据集合</li>
</ol>
<p>假设我们一共用4个集合为4个设备保存时间序列数据，设备的ID号是1、2、3、4，我们在创建数据集合时，把device_id设置为每个集合的标签。此时，我们就可以使用下列TS.MGET命令，以及FILTER设置（这个配置项用来设置集合标签的过滤条件），查询device_id不等于2的所有其他设备的数据集合，并返回各自集合中的最新的一条数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TS.MGET FILTER device_id!=2 </span><br><span class="line">1) 1) &quot;device:temperature:1&quot;</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) &quot;25.3&quot;</span><br><span class="line">2) 1) &quot;device:temperature:3&quot;</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) &quot;29.5&quot;</span><br><span class="line">3) 1) &quot;device:temperature:4&quot;</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) &quot;30.1&quot;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>用TS.RANGE支持需要聚合计算的范围查询</li>
</ol>
<p>在对时间序列数据进行聚合计算时，我们可以使用TS.RANGE命令指定要查询的数据的时间范围，同时用AGGREGATION参数指定要执行的聚合计算类型。RedisTimeSeries支持的聚合计算类型很丰富，包括求均值（avg）、求最大&#x2F;最小值（max&#x2F;min），求和（sum）等。<br>例如，在执行下列命令时，我们就可以按照每180s的时间窗口，对2020年8月3日9时5分和2020年8月3日9时12分这段时间内的数据进行均值计算了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TS.RANGE device:temperature 1596416700 1596417120 AGGREGATION avg 180000</span><br><span class="line">1) 1) (integer) 1596416700</span><br><span class="line">   2) &quot;25.6&quot;</span><br><span class="line">2) 1) (integer) 1596416880</span><br><span class="line">   2) &quot;25.8&quot;</span><br><span class="line">3) 1) (integer) 1596417060</span><br><span class="line">   2) &quot;26.1&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>与使用Hash和Sorted Set来保存时间序列数据相比，RedisTimeSeries是专门为时间序列数据访问设计的扩展模块，能支持在Redis实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，RedisTimeSeries就可以发挥优势了。</p>
</blockquote>
<h2 id="2-15-消息队列的考验：Redis有哪些解决方案？"><a href="#2-15-消息队列的考验：Redis有哪些解决方案？" class="headerlink" title="2.15 消息队列的考验：Redis有哪些解决方案？"></a>2.15 消息队列的考验：Redis有哪些解决方案？</h2><h3 id="2-15-1-消息队列的消息存取需求"><a href="#2-15-1-消息队列的消息存取需求" class="headerlink" title="2.15.1 消息队列的消息存取需求"></a>2.15.1 消息队列的消息存取需求</h3><p>消息队列在存取消息时，必须要满足三个需求，分别是<strong>消息保序</strong>、<strong>处理重复的消息</strong>和<strong>保证消息可靠性</strong>。</p>
<ol>
<li>消息保序：所有消息要按生产者生产的顺序进行消费，乱序会导致业务逻辑错误</li>
<li>重复消息处理：生产者尽量不产生重复的消息，每个消息可以使用一个唯一ID标识</li>
<li>消息可靠性保证：如果消费者在处理消息的时候挂了，消费者重启后可以再次处理宕机时未处理完的消息。</li>
</ol>
<h3 id="2-15-2-基于List的消息队列解决方案"><a href="#2-15-2-基于List的消息队列解决方案" class="headerlink" title="2.15.2 基于List的消息队列解决方案"></a>2.15.2 基于List的消息队列解决方案</h3><p>使用redis中的list结构实现消息队列，首先依据list的先进先出等操作方式可以保序。<br>可以使用LPUSH生产消息，RPOP读出消息。<br>为了保证不重复，可以使用全局ID标识：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LPUSH mq &quot;101030001:stock:5&quot; </span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262219692.png"></p>
<p>但以上方案有个缺点，就是消费者什么时候读消息，如果使用RPOP，则需要一直轮询看是否有消息需要消费，可以使用BRPOP，阻塞读，则不需要定时轮询。</p>
<p>如果消费者在读出消息后，处理时挂了，重启后则会丢失上次未处理完的消息，可以使用BRPOPLPUSH命令在读取消息时，备份到另一个list。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262219671.png"></p>
<blockquote>
<p>以上是一个消费者，一个生产者，如果消费者有多个，要分担处理生产者生产的消息，list类型不支持消费者组，无法实现，可以使用Streams数据类型。</p>
</blockquote>
<h3 id="2-15-3-基于Streams的消息队列解决方案"><a href="#2-15-3-基于Streams的消息队列解决方案" class="headerlink" title="2.15.3 基于Streams的消息队列解决方案"></a>2.15.3 基于Streams的消息队列解决方案</h3><p>Streams是Redis专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。</p>
<ul>
<li>XADD：插入消息，保证有序，可以自动生成全局唯一ID；</li>
<li>XREAD：用于读取消息，可以按ID读取数据；</li>
<li>XREADGROUP：按消费组形式读取消息；</li>
<li>XPENDING和XACK：XPENDING命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而XACK命令用于向消息队列确认消息处理已完成。</li>
</ul>
<p>执行下面的命令，就可以往名称为mqstream的消息队列中插入一条消息，消息的键是repo，值是5。其中，消息队列名称后面的<em>，表示让Redis为插入的数据自动生成一个全局唯一的ID，例如“1599203861727-0”。当然，我们也可以不用</em>，直接在消息队列名称后自行设定一个ID号，只要保证这个ID号是全局唯一的就行。不过，相比自行设定ID号，使用*会更加方便高效。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">XADD mqstream * repo 5 </span><br><span class="line">&quot;1599203861727-0&quot;</span><br></pre></td></tr></table></figure>
<p>消息的全局唯一ID由两部分组成，第一部分“1599203861727”是数据插入时，以毫秒为单位计算的当前服务器时间，第二部分表示插入消息在当前毫秒内的消息序号，这是从0开始编号的。例如，“1599203861727-0”就表示在“1599203861727”毫秒内的第1条消息。</p>
<p>XREAD在读取消息时，可以指定一个消息ID，并从这个消息ID的下一条消息开始进行读取。<br>可以执行下面的命令，从ID号为1599203861727-0的消息开始，读取后续的所有消息（示例中一共3条）。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262215410.png"><br>消费者也可以在调用XRAED时设定block配置项，实现类似于BRPOP的阻塞读取操作。当消息队列中没有消息时，一旦设置了block配置项，XREAD就会阻塞，阻塞的时长可以在block配置项进行设置。</p>
<p>Streams本身可以使用XGROUP创建消费组，创建消费组之后，Streams可以使用XREADGROUP命令让消费组内的消费者读取消息，<br>执行下面的命令，创建一个名为group1的消费组，这个消费组消费的消息队列是mqstream。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">XGROUP create mqstream group1 0 </span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>再执行一段命令，让group1消费组里的消费者consumer1从mqstream中读取所有消息，其中，命令最后的参数“&gt;”，表示从第一条尚未被消费的消息开始读取。因为在consumer1读取消息前，group1中没有其他消费者读取过消息，所以，consumer1就得到mqstream消息队列中的所有消息了（一共4条）。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262215388.png"></p>
<p>需要注意的是，消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。比如说，我们执行完刚才的XREADGROUP命令后，再执行下面的命令，让group1内的consumer2读取消息时，consumer2读到的就是空值，因为消息已经被consumer1读取完了，如下所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262216440.png"><br>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。例如，我们执行下列命令，让group2中的consumer1、2、3各自读取一条消息。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262217635.png"><br>为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams会自动使用内部队列（也称为PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用XACK命令通知Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给Streams发送XACK命令，消息仍然会留存。此时，消费者可以在重启后，用XPENDING命令查看已读取、但尚未确认处理完成的消息。</p>
<p>例如，我们来查看一下group2中各个消费者已读取、但尚未确认的消息个数。其中，XPENDING返回结果的第二、三行分别表示group2中所有消费者读取的消息最小ID和最大ID。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262217478.png"><br>如果我们还需要进一步查看某个消费者具体读取了哪些数据，可以执行下面的命令：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262217705.png"><br>可以看到，consumer2已读取的消息的ID是1599274912765-0。</p>
<p>一旦消息1599274912765-0被consumer2处理了，consumer2就可以使用XACK命令通知Streams，然后这条消息就会被删除。当我们再使用XPENDING命令查看时，就可以看到，consumer2已经没有已读取、但尚未确认处理的消息了。<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262218717.png"></p>
<blockquote>
<p>Streams是Redis 5.0专门针对消息队列场景设计的数据类型，如果你的Redis是5.0及5.0以后的版本，就可以考虑把Streams用作消息队列了。</p>
</blockquote>
<h3 id="2-15-4-总结"><a href="#2-15-4-总结" class="headerlink" title="2.15.4 总结"></a>2.15.4 总结</h3><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/202305262211832.png"></p>
<p>于Redis是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用Kafka、RabbitMQ这些专门面向消息队列场景的软件，而Redis更加适合做缓存。<br>关于是否用Redis做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。</p>
<blockquote>
<p>如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，你会使用Redis的什么数据类型来解决这个问题？</p>
</blockquote>
<blockquote>
<p>这种情况下，只能使用Streams数据类型来解决。使用Streams数据类型，创建多个消费者组，就可以实现同时消费生产者的数据。每个消费者组内可以再挂多个消费者分担读取消息进行消费，消费完成后，各自向Redis发送XACK，标记自己的消费组已经消费到了哪个位置，而且消费组之间互不影响。</p>
</blockquote>
<h2 id="2-16-异步机制：如何避免单线程模型的阻塞？"><a href="#2-16-异步机制：如何避免单线程模型的阻塞？" class="headerlink" title="2.16 异步机制：如何避免单线程模型的阻塞？"></a>2.16 异步机制：如何避免单线程模型的阻塞？</h2><h3 id="2-16-1-Redis实例有哪些阻塞点？"><a href="#2-16-1-Redis实例有哪些阻塞点？" class="headerlink" title="2.16.1 Redis实例有哪些阻塞点？"></a>2.16.1 Redis实例有哪些阻塞点？</h3><ul>
<li>客户端：网络IO，键值对增删改查操作，数据库操作；</li>
<li>磁盘：生成RDB快照，记录AOF日志，AOF日志重写；</li>
<li>主从节点：主库生成、传输RDB文件，从库接收RDB文件、清空数据库、加载RDB文件；</li>
<li>切片集群实例：向其他实例传输哈希槽信息，数据迁移。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221215100351.png" alt="20221215100351"></p>
<ol>
<li><strong>集合全量查询和聚合操作</strong></li>
</ol>
<p>Redis中涉及集合的操作复杂度通常为O(N)，所以在对集合元素全量查询操作HGETALL、SMEMBERS，如集合的统计操作：求交、并和差集。</p>
<ol start="2">
<li><strong>bigkey删除操作</strong></li>
</ol>
<p>bigkey删除操作，需要释放占用的内存空间，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成Redis主线程的阻塞。</p>
<p>测试了不同元素数量的集合在进行删除操作时所消耗的时间，如下表所示：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221215100830.png" alt="20221215100830"></p>
<p>可以得出三个结论：</p>
<ul>
<li>当元素数量从10万增加到100万时，4大集合类型的删除时间的增长幅度从5倍上升到了近20倍；</li>
<li>集合元素越大，删除所花费的时间就越长；</li>
<li>当删除有100万个元素的集合时，最大的删除时间绝对值已经达到了1.98s（Hash类型）。Redis的响应时间一般在微秒级别，所以，一个操作达到了近2s，不可避免地会阻塞主线程。</li>
</ul>
<ol start="3">
<li>清空数据库</li>
</ol>
<p>同第2个阻塞点，也需要释放大量内存</p>
<ol start="4">
<li>AOF日志同步写</li>
</ol>
<p>同步写，与磁盘交互，造成阻塞，一个同步写磁盘的操作耗时大约是1~2ms</p>
<ol start="5">
<li>主从节点交互阻塞</li>
</ol>
<p>对于从库来说，它在接收了RDB文件后，需要使用FLUSHDB命令清空当前数据库，这就正好撞上了刚才我们分析的第三个阻塞点。<br>从库在清空当前数据库后，还需要把RDB文件加载到内存，这个过程的快慢和RDB文件的大小密切相关，RDB文件越大，加载过程越慢，所以，加载RDB文件就成为了Redis的第五个阻塞点。</p>
<ol start="6">
<li>群实例交互时的阻塞点</li>
</ol>
<p>每个Redis实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对Redis主线程的阻塞风险不大。<br>如果你使用了Redis Cluster方案，而且同时正好迁移的是bigkey的话，就会造成主线程的阻塞，因为Redis Cluster使用了同步迁移。</p>
<p>总结下刚刚找到的五个阻塞点：</p>
<ul>
<li>集合全量查询和聚合操作；</li>
<li>bigkey删除；</li>
<li>清空数据库；</li>
<li>AOF日志同步写；</li>
<li>从库加载RDB文件。</li>
</ul>
<h3 id="2-16-2-那些阻塞点可以异步执行"><a href="#2-16-2-那些阻塞点可以异步执行" class="headerlink" title="2.16.2 那些阻塞点可以异步执行"></a>2.16.2 那些阻塞点可以异步执行</h3><p>对于Redis的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载RDB文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使用Redis的异步子线程机制来实现bigkey删除，清空数据库，以及AOF日志同步写。</p>
<h3 id="2-16-3-异步的子线程机制"><a href="#2-16-3-异步的子线程机制" class="headerlink" title="2.16.3 异步的子线程机制"></a>2.16.3 异步的子线程机制</h3><p>Redis主线程启动后，会使用操作系统提供的pthread_create函数创建3个子线程，分别由它们负责AOF日志写操作、键值对删除以及文件关闭的异步执行。<br>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。<br>但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p>
<p>和惰性删除类似，当AOF日志配置成everysec选项后，主线程会把AOF写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入AOF日志，这样主线程就不用一直等待AOF日志写完了。<br>下面这张图展示了Redis中的异步子线程执行机制：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/blog/20221215102523.png" alt="20221215102523"></p>
<p>异步的键值对删除和数据库清空操作是Redis 4.0后提供的功能，Redis也提供了新的命令来执行这两个操作。</p>
<ul>
<li>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用UNLINK命令。</li>
<li>清空数据库：可以在FLUSHDB和FLUSHALL命令后加上ASYNC选项，这样就可以让后台子线程异步地清空数据库，如下所示：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLUSHDB ASYNC </span><br><span class="line">FLUSHALL AYSNC</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-18-波动的响应延迟：如何应对变慢的Redis？"><a href="#2-18-波动的响应延迟：如何应对变慢的Redis？" class="headerlink" title="2.18 波动的响应延迟：如何应对变慢的Redis？"></a>2.18 波动的响应延迟：如何应对变慢的Redis？</h2><h2 id="2-25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"><a href="#2-25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？" class="headerlink" title="2.25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"></a>2.25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</h2><ul>
<li>读写缓存</li>
</ul>
<p>针对读写缓存，如果要对数据进行增删改，需要在缓存中进行，采取写回策略，决定是否同步写回到数据库中。</p>
<p>同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；<br>异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。<br>需要保证写缓存和写数据库具有原子性，两者要不一起更新，要不都不更新，返回错误信息，进行重试。</p>
<ul>
<li>只读缓存</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230513191020.png" alt="20230513191020"></p>
<p>Redis当做读写缓存使用，删改操作同时操作数据库和缓存：<br>1、先更新数据库，再更新缓存：如果更新数据库成功，但缓存更新失败，此时数据库中是最新值，但缓存中是旧值，后续的读请求会直接命中缓存，得到的是旧值。</p>
<p>2、先更新缓存，再更新数据库：如果更新缓存成功，但数据库更新失败，此时缓存中是最新值，数据库中是旧值，后续读请求会直接命中缓存，但得到的是最新值，短期对业务影响不大。但是，一旦缓存过期或者满容后被淘汰，读请求就会从数据库中重新加载旧值到缓存中，之后的读请求会从缓存中得到旧值，对业务产生影响。</p>
<p>针对这种其中一个操作可能失败的情况，也可以使用重试机制解决，把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库，成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。</p>
<p>并发请求的情况。如果存在并发读写，也会产生不一致，分为以下4种场景。<br>1、先更新数据库，再更新缓存，写+读并发：线程A先更新数据库，之后线程B读取数据，此时线程B会命中缓存，读取到旧值，之后线程A更新缓存成功，后续的读请求会命中缓存得到最新值。这种场景下，线程A未更新完缓存之前，在这期间的读请求会短暂读到旧值，对业务短暂影响。</p>
<p>2、先更新缓存，再更新数据库，写+读并发：线程A先更新缓存成功，之后线程B读取数据，此时线程B命中缓存，读取到最新值后返回，之后线程A更新数据库成功。这种场景下，虽然线程A还未更新完数据库，数据库会与缓存存在短暂不一致，但在这之前进来的读请求都能直接命中缓存，获取到最新值，所以对业务没影响。</p>
<p>3、先更新数据库，再更新缓存，写+写并发：线程A和线程B同时更新同一条数据，更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，这会导致数据库和缓存的不一致。</p>
<p>4、先更新缓存，再更新数据库，写+写并发：与场景3类似，线程A和线程B同时更新同一条数据，更新缓存的顺序是先A后B，但是更新数据库的顺序是先B后A，这也会导致数据库和缓存的不一致。</p>
<h2 id="2-26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"><a href="#2-26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？" class="headerlink" title="2.26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"></a>2.26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</h2><p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230513191846.png" alt="20230513191846"></p>
<p>所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。</p>
<ul>
<li>当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；</li>
<li>当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。</li>
</ul>
<blockquote>
<p>服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。</p>
</blockquote>
<p>尽量使用预防式方案：</p>
<ul>
<li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li>
<li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li>
<li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。</li>
</ul>
<h2 id="2-27-缓存被污染了，该怎么办？"><a href="#2-27-缓存被污染了，该怎么办？" class="headerlink" title="2.27 缓存被污染了，该怎么办？"></a>2.27 缓存被污染了，该怎么办？</h2><p>缓存污染：在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。</p>
<p>解决缓存污染问题的策略：</p>
<ul>
<li>volatile-random和allkeys-random这两种策略。它们都是采用随机挑选数据的方式：效果差</li>
<li>volatile-ttl策略：设置过期时间，把数据中剩余存活时间最短的淘汰掉</li>
<li>LRU策略：每个数据对应的RedisObject结构体中设置了lru字段，记录数据的访问时间戳，淘汰lru字段值最小的数据（访问时间最久的数据）</li>
<li>LFU策略：除了记录时间戳，还记录访问频次，淘汰时先淘汰访问次数最低的数据，如果访问次数一样再淘汰具体上次访问时间更久的数据。</li>
</ul>
<p>Redis在实现LFU策略的时候，只是把原来24bit大小的lru字段，又进一步拆分成了两部分。</p>
<ul>
<li>ldt值：lru字段的前16bit，表示数据的访问时间戳；</li>
<li>counter值：lru字段的后8bit，表示数据的访问次数。</li>
</ul>
<p>Redis只使用了8bit记录数据的访问次数，而8bit记录的最大值是255，这样可以吗？</p>
<p>在计算次数时，不是线性递增，每当数据被访问一次时，首先，用计数器当前的值乘以配置项lfu_log_factor再加1，再取其倒数，得到一个p值；然后，把这个p值和一个取值范围在（0，1）间的随机数r值比大小，只有p值大于r值时，计数器才加1。<br>其中，baseval是计数器当前的值。计数器的初始值默认是5（由代码中的LFU_INIT_VAL常量设置），而不是0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> r = (<span class="type">double</span>)rand()/RAND_MAX;</span><br><span class="line">...</span><br><span class="line"><span class="type">double</span> p = <span class="number">1.0</span>/(baseval*server.lfu_log_factor+<span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (r &lt; p) counter++;   </span><br></pre></td></tr></table></figure>
<p>使用了这种计算规则后，我们可以通过设置不同的lfu_log_factor配置项，来控制计数器值增加的速度，避免counter值很快就到255了。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230513195542.png" alt="20230513195542"></p>
<p>可以看到，当lfu_log_factor取值为1时，实际访问次数为100K后，counter值就达到255了，无法再区分实际访问次数更多的数据了。而当lfu_log_factor取值为100时，当实际访问次数为10M时，counter值才达到255，此时，实际访问次数小于10M的不同数据都可以通过counter值区分出来。</p>
<p>可以看到，当lfu_log_factor取值为10时，百、千、十万级别的访问次数对应的counter值已经有明显的区分了，所以，我们在应用LFU策略时，一般可以将lfu_log_factor取值为10。</p>
<p>在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis在实现LFU策略时，还设计了一个counter值的衰减机制。</p>
<p>简单来说，LFU策略使用衰减因子配置项lfu_decay_time来控制访问次数的衰减。LFU策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU策略再把这个差值除以lfu_decay_time值，所得的结果就是数据counter要衰减的值。</p>
<p>简单举个例子，假设lfu_decay_time取值为1，如果数据在N分钟内没有被访问，那么它的访问次数就要减N。如果lfu_decay_time取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把lfu_decay_time值设置为1，这样一来，LFU策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。</p>
<h2 id="2-28-Pika-如何基于SSD实现大容量Redis？"><a href="#2-28-Pika-如何基于SSD实现大容量Redis？" class="headerlink" title="2.28 Pika-如何基于SSD实现大容量Redis？"></a>2.28 Pika-如何基于SSD实现大容量Redis？</h2><p><a target="_blank" rel="noopener" href="https://github.com/OpenAtomFoundation/pika">Pika</a>一款可以基于SSD实现大容量存储的Redis<br>五大模块：<br><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230514091839.png" alt="20230514091839"></p>
<h2 id="2-29-无锁的原子操作：Redis如何应对并发访问？"><a href="#2-29-无锁的原子操作：Redis如何应对并发访问？" class="headerlink" title="2.29 无锁的原子操作：Redis如何应对并发访问？"></a>2.29 无锁的原子操作：Redis如何应对并发访问？</h2><p>Reids实现原子操作的两种方法：</p>
<ol>
<li>把多个操作在Redis中实现成一个操作，也就是单命令操作；</li>
<li>把多个操作写到一个Lua脚本中，以原子性方式执行单个Lua脚本。</li>
</ol>
<ul>
<li><p>示例1：对某数据进行加减</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">current = GET(id)</span><br><span class="line">current--</span><br><span class="line">SET(id, current)</span><br></pre></td></tr></table></figure>
<p>以上使用三个语句实现，在并发场景下无法保证原子性，可以使用加减操作的命令INCR&#x2F;DECR。</p>
</li>
<li><p>示例2：通过lua脚本实现复杂的操作</p>
</li>
</ul>
<p>下边设置每个IP地址1分钟以内，最多访问20次。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取ip对应的访问次数</span></span><br><span class="line">current = GET(ip)</span><br><span class="line"><span class="comment">//如果超过访问次数超过20次，则报错</span></span><br><span class="line">IF current != <span class="literal">NULL</span> AND current &gt; <span class="number">20</span> THEN</span><br><span class="line">    ERROR <span class="string">&quot;exceed 20 accesses per second&quot;</span></span><br><span class="line">ELSE</span><br><span class="line">    <span class="comment">//如果访问次数不足20次，增加一次访问计数</span></span><br><span class="line">    value = INCR(ip)</span><br><span class="line">    <span class="comment">//如果是第一次访问，将键值对的过期时间设置为60s后</span></span><br><span class="line">    IF value == <span class="number">1</span> THEN</span><br><span class="line">        EXPIRE(ip,<span class="number">60</span>)</span><br><span class="line">    END</span><br><span class="line">    <span class="comment">//执行其他操作</span></span><br><span class="line">    DO THINGS</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>客户端使用多线程访问，访问次数初始值为0，第一个线程执行了INCR(ip)操作后，第二个线程紧接着也执行了INCR(ip)，此时，ip对应的访问次数就被增加到了2，我们就无法再对这个ip设置过期时间了。这样就会导致，这个ip对应的客户端访问次数达到20次之后，就无法再进行访问了。<br>把访问次数加1和设置过期时间写入一个lua脚本执行，保证原子性，如下：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> current</span><br><span class="line">current = redis.call(<span class="string">&quot;incr&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">tonumber</span>(current) == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">    redis.call(<span class="string">&quot;expire&quot;</span>,KEYS[<span class="number">1</span>],<span class="number">60</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>脚本名称为lua.script，执行如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli  --<span class="built_in">eval</span> lua.script  keys , args</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以使用SCRIPT LOAD命令把 lua 脚本加载到 Redis 中，然后得到一个脚本唯一摘要值，再通过EVALSHA命令 + 脚本摘要值来执行脚本，这样可以避免每次发送脚本内容到 Redis，减少网络开销。</p>
</blockquote>
<h2 id="2-30-如何使用Redis实现分布式锁？"><a href="#2-30-如何使用Redis实现分布式锁？" class="headerlink" title="2.30 如何使用Redis实现分布式锁？"></a>2.30 如何使用Redis实现分布式锁？</h2><h3 id="2-30-1-基于单个Redis节点实现分布式锁"><a href="#2-30-1-基于单个Redis节点实现分布式锁" class="headerlink" title="2.30.1 基于单个Redis节点实现分布式锁"></a>2.30.1 基于单个Redis节点实现分布式锁</h3><ul>
<li>加锁操作：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230514095501.png" alt="20230514095501"></p>
<ul>
<li>释放锁操作</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230514095635.png" alt="20230514095635"></p>
<ol>
<li>加锁操作中包括了判断锁是否存在，为了实现原子性，可以使用SETNX命令，总体的加锁释放锁流程如下：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 加锁</span><br><span class="line">SETNX lock_key 1</span><br><span class="line">// 业务逻辑</span><br><span class="line">DO THINGS</span><br><span class="line">// 释放锁</span><br><span class="line">DEL lock_key</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>为了防止客户端出错退出，导致长期占用锁，加锁时可以设置过期时间，并且为了区分客户端，可以设置唯一标识：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 加锁, unique_value作为客户端唯一性的标识</span><br><span class="line">SET lock_key unique_value NX PX 10000</span><br></pre></td></tr></table></figure></li>
<li>释放锁也需要根据客户端唯一标识释放，防止误释放，下边通过lua脚本实现原子性：</li>
</ol>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//释放锁 比较unique_value是否相等，避免误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli  --<span class="built_in">eval</span>  unlock.script lock_key , unique_value </span><br></pre></td></tr></table></figure>

<h3 id="2-30-2-基于多个Redis节点实现高可靠的分布式锁"><a href="#2-30-2-基于多个Redis节点实现高可靠的分布式锁" class="headerlink" title="2.30.2 基于多个Redis节点实现高可靠的分布式锁"></a>2.30.2 基于多个Redis节点实现高可靠的分布式锁</h3><p>为了避免Redis实例故障而导致的锁无法工作的问题，Redis的开发者Antirez提出了分布式锁算法Redlock。<br>Redlock算法的基本思路，是让客户端和多个独立的Redis实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个Redis实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。</p>
<p>具体看下Redlock算法的执行步骤：</p>
<ol>
<li>第一步是，客户端获取当前时间。</li>
<li>第二步是，客户端按顺序依次向N个Redis实例执行加锁操作。<blockquote>
<p>这里的加锁操作和在单实例上执行的加锁操作一样，使用SET命令，带上NX，EX&#x2F;PX选项，以及带上客户端的唯一标识。当然，如果某个Redis实例发生故障了，为了保证在这种情况下，Redlock算法能够继续运行，我们需要给加锁操作设置一个超时时间。<br>如果客户端在和一个Redis实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个Redis实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。</p>
</blockquote>
</li>
<li>第三步是，一旦客户端完成了和所有Redis实例的加锁操作，客户端就要计算整个加锁过程的总耗时。</li>
</ol>
<p>客户端只有在满足下面的这两个条件时，才能认为是加锁成功：</p>
<ul>
<li>条件一：客户端从超过半数（大于等于 N&#x2F;2+1）的Redis实例上成功获取到了锁；</li>
<li>条件二：客户端获取锁的总耗时没有超过锁的有效时间。</li>
</ul>
<p>在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。</p>
<p>当然，如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有Redis节点发起释放锁的操作。</p>
<p>在Redlock算法中，释放锁的操作和在单实例上释放锁的操作一样，只要执行释放锁的Lua脚本就可以了。这样一来，只要N个Redis实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了。</p>
<h2 id="2-31-事务机制：Redis能实现ACID属性吗？"><a href="#2-31-事务机制：Redis能实现ACID属性吗？" class="headerlink" title="2.31 事务机制：Redis能实现ACID属性吗？"></a>2.31 事务机制：Redis能实现ACID属性吗？</h2><p>事务的ACID属性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。</p>
<h3 id="2-31-2-原子性"><a href="#2-31-2-原子性" class="headerlink" title="2.31.2 原子性"></a>2.31.2 原子性</h3><p>在Redis中使用MULTI和EXEC配合使用，完成事务的执行。<br>使用MULTI开启事务后，执行的命令都会暂存在队列中，知道执行EXEC指令，才会执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#开启事务</span><br><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">#发送事务中的第一个操作，但是Redis不支持该命令，返回报错信息</span><br><span class="line">127.0.0.1:6379&gt; PUT a:stock 5</span><br><span class="line">(error) ERR unknown command `PUT`, with args beginning with: `a:stock`, `5`, </span><br><span class="line">#发送事务中的第二个操作，这个操作是正确的命令，Redis把该命令入队</span><br><span class="line">127.0.0.1:6379&gt; DECR b:stock</span><br><span class="line">QUEUED</span><br><span class="line">#实际执行事务，但是之前命令有错误，所以Redis拒绝执行</span><br><span class="line">127.0.0.1:6379&gt; EXEC</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br></pre></td></tr></table></figure>
<ul>
<li>在执行EXEC命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被Redis实例判断出来了。</li>
<li>事务操作入队时，命令和操作的数据类型不匹配，但Redis实例没有检查出错误。</li>
</ul>
<p>Redis对事务原子性属性的保证情况如下：</p>
<ol>
<li>命令入队时就报错，会放弃事务执行，保证原子性；</li>
<li>命令入队时没报错，实际执行时报错，不保证原子性；</li>
<li>EXEC命令执行时实例故障，如果开启了AOF日志，可以保证原子性。</li>
</ol>
<h3 id="2-31-3-一致性"><a href="#2-31-3-一致性" class="headerlink" title="2.31.3 一致性"></a>2.31.3 一致性</h3><ul>
<li>命令入队时就报错</li>
</ul>
<p>事务本身就会被放弃执行，所以可以保证数据库的一致性。</p>
<ul>
<li>命令入队时没报错，实际执行时报错</li>
</ul>
<p>有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。</p>
<ul>
<li>EXEC命令执行时实例发生故障</li>
</ul>
<p>如果使用了RDB快照，因为RDB快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到RDB快照中，使用RDB快照进行恢复时，数据库里的数据也是一致的。<br>如果使用了AOF日志，而事务操作还没有被记录到AOF日志时，实例就发生了故障，那么，使用AOF日志恢复的数据库数据是一致的。如果只有部分操作被记录到了AOF日志，我们可以使用redis-check-aof清除事务中已经完成的操作，数据库恢复后也是一致的。</p>
<h3 id="2-31-4-隔离性"><a href="#2-31-4-隔离性" class="headerlink" title="2.31.4 隔离性"></a>2.31.4 隔离性</h3><ul>
<li>并发操作在EXEC命令前执行，此时，隔离性的保证要使用WATCH机制来实现，否则隔离性无法保证；</li>
<li>并发操作在EXEC命令后执行，此时，隔离性可以保证。</li>
</ul>
<p>WATCH机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC命令执行时，WATCH机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。</p>
<ul>
<li>并发操作在EXEC前执行</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230515165039.png" alt="20230515165039"></p>
<ul>
<li>并发操作在EXEC命令之后被服务器端接收并执行。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230515165123.png" alt="20230515165123"></p>
<h3 id="2-31-5-持久性"><a href="#2-31-5-持久性" class="headerlink" title="2.31.5 持久性"></a>2.31.5 持久性</h3><p>通过日志保证持久性，但是不管是RDB还是AOF都是会有一定的丢失，所以Redis事务的持久性得不到保证。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230515165344.png" alt="20230515165344"></p>
<h2 id="2-32-Redis主从同步与故障切换"><a href="#2-32-Redis主从同步与故障切换" class="headerlink" title="2.32 Redis主从同步与故障切换"></a>2.32 Redis主从同步与故障切换</h2><ul>
<li><strong>主从数据不一致</strong></li>
</ul>
<p>主从库间的命令复制是异步进行的，所以在网络延迟过高的情况下就会导致客户端读取从库数据时出现不一致情况。<br>解决方法可以监控程序对比主从库复制进度，不让客户端从落后的从库中读取数据。</p>
<ul>
<li><strong>读到过期数据</strong></li>
</ul>
<p>Redis同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。<br>惰性删除：就是只有客户端触发访问数据时，才会检查数据是否过期。<br>定期删除：Redis定期检查过期的数据，并进行删除。</p>
<p>惰性删除和定期删除可以同时存在的，惰性删除可以尽量减少CPU资源的使用，但可能会遗留大量过期数在内存中，占用内存资源。</p>
<blockquote>
<p>Redis 3.2之前的版本，那么，从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在3.2版本后，Redis做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，在应用主从集群时，尽量使用Redis 3.2及以上版本。</p>
</blockquote>
<p>Redis中设置过期时间的命令：</p>
<ul>
<li>EXPIRE和PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li>
<li>EXPIREAT和PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230515172414.png" alt="20230515172414"></p>
<p>在业务应用中可以尽量使用EXPIREAT&#x2F;PEXPIREAT命令，把数据的过期时间设置为具体的时间点，防止主从同步时在从库中执行命令延迟，导致EXPIRE命令设置的过期时间在从库中延后。</p>
<ul>
<li><strong>不合理配置项导致的服务挂掉</strong></li>
</ul>
<p><strong>protected-mode 配置项</strong>：这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为yes时，哨兵实例只能在部署的服务器本地进行访问。当设置为no时，其他服务器也可以访问这个哨兵实例。为了防止实例部署在不同的服务器上无法通信，此配置项建议设置为no。</p>
<p><strong>cluster-node-timeout配置项</strong>：配置项设置了Redis Cluster中实例响应心跳消息的超时时间。<br>当我们在Redis Cluster集群中为每个实例配置了“一主一从”模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超出cluster-node-timeout）。实例超时后，就会被Redis Cluster判断为异常。而Redis Cluster正常运行的条件就是，有半数以上的实例都能正常运行。<br>如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将cluster-node-timeout调大些（例如10到20秒）。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230515172911.png" alt="20230515172911"></p>
<h2 id="2-33-脑裂：一次奇怪的数据丢失"><a href="#2-33-脑裂：一次奇怪的数据丢失" class="headerlink" title="2.33 脑裂：一次奇怪的数据丢失"></a>2.33 脑裂：一次奇怪的数据丢失</h2><p>脑裂就是指在主从集群中同时出现了两个主节点，他们都能接收写请求。脑裂最直接的影响就是客户端不知道应该往那个主节点写入数据。</p>
<ul>
<li>是否数据同步出现问题</li>
</ul>
<p>在主从集群中发生数据丢失，最常见的原因就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。</p>
<ul>
<li>看客户端操作日志，发现脑裂现象</li>
</ul>
<p>在排查客户端操作日志时，发现有一个客户端在主从切换后的一段时间内，仍然和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有两个主库。</p>
<ul>
<li>原主库假故障导致的脑裂</li>
</ul>
<p>采用哨兵机制进行主从切换，在超过预设数量的哨兵实例和主库心跳超时，就会把主库判断为客观下线，然后开始执行切换操作，在主库发生某种问题时，无法响应哨兵的心跳，导致被判断为下线，然后就开始主从切换，后边主库问题恢复，又开始处理请求，就导致出现脑裂。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230516094333.png" alt="20230516094333"></p>
<ul>
<li>为什么脑裂导致了数据丢失</li>
</ul>
<p>在脑裂发生后，因为主从切换未完成时，旧主库在处理请求，当主从切换完成后，从库升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230516094521.png" alt="20230516094521"></p>
<ul>
<li>如何应对脑裂问题</li>
</ul>
<p>Redis提供了两个配置项来限制主库的请求处理，分别是min-slaves-to-write和min-slaves-max-lag。</p>
<ul>
<li>min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；</li>
<li>min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。</li>
</ul>
<p><strong>应对脑裂的方案：</strong> 可以把min-slaves-to-write和min-slaves-max-lag这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为N和T。这两个配置项组合后的要求是，主库连接的从库中至少有N个从库，和主库进行数据复制时的ACK消息延迟不能超过T秒，否则，主库就不会再接收客户端的请求了。<br>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行ACK确认了。这样一来，min-slaves-to-write和min-slaves-max-lag的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。<br>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</p>
<blockquote>
<p>就是通过配置限制，可以防止出现两个主库在处理写请求。</p>
</blockquote>
<p><strong>配置示例：</strong> 假设我们将min-slaves-to-write设置为1，把min-slaves-max-lag设置为12s，把哨兵的down-after-milliseconds设置为10s，主库因为某些原因卡住了15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了15s，没有一个从库能和原主库在12s内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p>
<p><strong>使用建议：</strong> 假设从库有K个，可以将min-slaves-to-write设置为K&#x2F;2+1（如果K等于1，就设为1），将min-slaves-max-lag设置为十几秒（例如10～20s），在这个配置下，如果有一半以上的从库和主库进行的ACK消息延迟超过十几秒，我们就禁止主库接收客户端写请求。</p>
<p><strong>出错示例：</strong> 假设将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？<br><strong>答：</strong> 主库卡住 12s，达到了哨兵设定的切换阈值，所以哨兵会触发主从切换。但哨兵切换的时间是 5s，也就是说哨兵还未切换完成，主库就会从阻塞状态中恢复回来，而且也没有触发 min-slaves-max-lag 阈值，所以主库在哨兵切换剩下的 3s 内，依旧可以接收客户端的写操作，如果这些写操作还未同步到从库，哨兵就把从库提升为主库了，那么此时也会出现脑裂的情况，之后旧主库降级为从库，重新同步新主库的数据，新主库也会发生数据丢失。</p>
<blockquote>
<p>但此方案也不是完全能保证数据不丢失，只能尽量减少数据的丢失。</p>
</blockquote>
<h2 id="2-35"><a href="#2-35" class="headerlink" title="2.35"></a>2.35</h2><h2 id="2-36-Redis支撑秒杀场景"><a href="#2-36-Redis支撑秒杀场景" class="headerlink" title="2.36 Redis支撑秒杀场景"></a>2.36 Redis支撑秒杀场景</h2><p>秒杀场景分为三个阶段：</p>
<ol>
<li>秒杀活动开始前</li>
</ol>
<p>用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。可以使用CDN或者浏览器缓存把静态化的元素缓存起来，这样大量的请求就不会到达服务器端。</p>
<ol start="2">
<li>秒杀开始</li>
</ol>
<p>会出现大量用户点击商品详情页，产生大量的并发请求查询库存，一旦某个请求查询到有库存，紧接着系统就会进行库存扣减。然后，系统会生成实际订单，并进行后续处理，例如订单支付和物流服务。如果请求查不到库存，就会返回。用户通常会继续点击秒杀按钮，继续查询库存。<br>因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上。<br>查验库存如果由剩余就会进行库存扣减，所以这两个操作是原子操作，否则会出现超售情况。后边的订单处理等一系列流程相对请求量就低很多，可以使用数据库。</p>
<ol start="3">
<li>秒杀结束</li>
</ol>
<p>可能还会有部分用户刷新商品详情页，尝试等待有其他用户退单。而已经成功下单的用户会刷新订单详情，跟踪订单的进展。不过，这个阶段中的用户请求量已经下降很多了，服务器端一般都能支撑。</p>
<p><img src="https://raw.githubusercontent.com/BaihlUp/Figurebed/master/2023/20230516103104.png" alt="20230516103104"></p>
<ul>
<li><strong>Redis的哪些方法可以支撑秒杀场景？</strong></li>
</ul>
<ol>
<li><strong>支持高并发：</strong> Redis本身高速处理请求的特性就可以支持高并发。而且，如果有多个秒杀商品，我们也可以使用切片集群，用不同的实例保存不同商品的库存，这样就避免，使用单个实例导致所有的秒杀请求都集中在一个实例上的问题了。不过，需要注意的是，当使用切片集群时，我们要先用CRC算法计算不同秒杀商品key对应的Slot，然后，我们在分配Slot和实例对应关系时，才能把不同秒杀商品对应的Slot分配到不同实例上保存。</li>
<li><strong>保证库存查验和库存扣减原子性执行</strong>：可以使用Redis的原子操作或是分布式锁这两个功能特性来支撑了。</li>
</ol>
<ul>
<li><strong>基于原子操作支撑秒杀场景</strong></li>
</ul>
<p>因为涉及库存查验和库存扣减两个操作，可以使用lua脚本实现原子操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#获取商品库存信息            </span><br><span class="line">local counts = redis.call(&quot;HMGET&quot;, KEYS[1], &quot;total&quot;, &quot;ordered&quot;);</span><br><span class="line">#将总库存转换为数值</span><br><span class="line">local total = tonumber(counts[1])</span><br><span class="line">#将已被秒杀的库存转换为数值</span><br><span class="line">local ordered = tonumber(counts[2])  </span><br><span class="line">#如果当前请求的库存量加上已被秒杀的库存量仍然小于总库存量，就可以更新库存         </span><br><span class="line">if ordered + k &lt;= total then</span><br><span class="line">    #更新已秒杀的库存量</span><br><span class="line">    redis.call(&quot;HINCRBY&quot;,KEYS[1],&quot;ordered&quot;,k)                              </span><br><span class="line">    return k;  </span><br><span class="line">end               </span><br><span class="line">return 0</span><br></pre></td></tr></table></figure>
<p>客户端会根据脚本的返回值，来确定秒杀是成功还是失败了。如果返回值是k，就是成功了；如果是0，就是失败。</p>
<ul>
<li><strong>基于分布式锁来支撑秒杀场景</strong></li>
</ul>
<p>使用分布式锁来支撑秒杀场景的具体做法是，先让客户端向Redis申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减。这样一来，大量的秒杀请求就会在争夺分布式锁时被过滤掉。而且，库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性。</p>
<p><strong>注意：</strong> 在使用分布式锁时，客户端需要先向Redis请求锁，只有请求到了锁，才能进行库存查验等操作，这样一来，客户端在争抢分布式锁时，大部分秒杀请求本身就会因为抢不到锁而被拦截。</p>
<p><strong>建议</strong>：可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例。如果客户端没有拿到锁，这些客户端就不会查询商品库存，这就可以减轻保存库存信息的实例的压力了。</p>
<ul>
<li><strong>秒杀场景的其他处理事项：</strong></li>
</ul>
<ol>
<li><strong>前端静态页面的设计</strong>。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用CDN或浏览器缓存服务秒杀开始前的请求。</li>
<li><strong>请求拦截和流控</strong>。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意IP进行访问。如果Redis实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。</li>
<li><strong>库存信息过期时间处理</strong>。Redis中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。</li>
<li><strong>数据库订单异常处理</strong>。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。</li>
</ol>
<h2 id="2-37"><a href="#2-37" class="headerlink" title="2.37"></a>2.37</h2>
      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 jaytp@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">💰</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 Yelog
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>Help us with donation</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">alipay</label></span><span><label><input type="radio" name="pay" value="weixin">weixin</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
